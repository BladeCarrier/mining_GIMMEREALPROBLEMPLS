{
 "metadata": {
  "name": "",
  "signature": "sha256:2edb500ea913ce5ee76586b7a195011a6571e4e84542a4d83aceed6f0f148948"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# I explore the cuts of the features\n",
      "%matplotlib inline\n",
      "#\u0442\u0430\u043a \u0442\u043e\u0436\u0435 \u043c\u043e\u0436\u043d\u043e \u0440\u0435\u0448\u0438\u0442\u044c \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u0443 \u0438\u043d\u043b\u0430\u0439\u043b\u0430 \u043f\u043b\u043e\u0442\u043e\u0432\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "\n",
      "import sklearn.metrics as metrics\n",
      "from sklearn.externals import joblib\n",
      "from sklearn import cross_validation as cv\n",
      "\n",
      "import _matrixnetapplier as mnet\n",
      "import copy\n",
      "import random\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Extracting the trained model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "itr,trees = mnet.get_trees(\"formula/formula.mx\")\n",
      "n_features = 30\n",
      "print itr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(6, 10000, <generator object _iterate_over_trees_with_fixed_depth at 0x0000000018395F78>)\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Loading dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#load training set\n",
      "def load_data(path):\n",
      "    print 'Loading training data...'\n",
      "    data = np.loadtxt(path, \\\n",
      "            delimiter=',', \\\n",
      "            skiprows=1, \\\n",
      "            converters={32: lambda x:int(x=='s'.encode('utf-8'))})\n",
      "\n",
      "    X = data[:,1:31]\n",
      "    Y = data[:,32]\n",
      "    W = data[:,31]\n",
      "    print \"Loaded.\"\n",
      "    return X,Y,W"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X,Y,W = load_data(\"data/training.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading training data...\n",
        "Loaded."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "Xtr,Xts,Ytr,Yts,Wtr,Wts = train_test_split(X, Y, W, train_size=0.51, random_state=42)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from factory import DataFactory\n",
      "trainFactory = DataFactory(Xtr,Ytr,Wtr)\n",
      "testFactory = DataFactory(Xts,Yts,Wts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#equalize classes, normalize weights\n",
      "trainFactory.equalizeWeights()\n",
      "print sum(trainFactory.weights[trainFactory.labels==1]),\n",
      "print sum(trainFactory.weights[trainFactory.labels==0]),\n",
      "print sum(trainFactory.weights),"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.5 0.5 0.999999999999\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#sanity check"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compute_ams_on_cuts(answers, predictions, sample_weight):\n",
      "    \"\"\" Predictions are probabilities\"\"\"\n",
      "    b, s, thresholds = metrics.roc_curve(answers, predictions, sample_weight=sample_weight)\n",
      "    # normalization constants\n",
      "    real_s = 691.988607712\n",
      "    real_b = 410999.847322\n",
      "    s *= real_s\n",
      "    b *= real_b\n",
      "    br = 10.\n",
      "    radicands = 2 * ((s + b + br) * np.log(1.0 + s/(b + br)) - s)\n",
      "    return thresholds, radicands\n",
      "\n",
      "def optimal_AMS(answers, predictions, sample_weight):\n",
      "    \"\"\" Predictions are probabilities \"\"\"\n",
      "    cuts, radicands = compute_ams_on_cuts(answers, predictions, sample_weight)\n",
      "    return np.sqrt(np.max(radicands))\n",
      "\n",
      "\n",
      "def precisionAt15(answers, predictions, sample_weight, percent=0.15):\n",
      "    n_passed = int(len(answers) * percent)\n",
      "    RATIO = 50\n",
      "    weight = sample_weight.copy()\n",
      "    weight[answers == 0] /= weight[answers == 0].mean() / RATIO\n",
      "    weight[answers == 1] /= weight[answers == 1].mean()\n",
      "    order = np.argsort(-predictions)\n",
      "    passed = order[:n_passed]    \n",
      "    return np.average(answers[passed], weights=weight[passed])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_control_metrics(proba_test, proba_train):\n",
      "    for name, metric in [('ROC', metrics.roc_auc_score), ('AMS', optimal_AMS), ('precision', precisionAt15)]:\n",
      "        print name,\n",
      "        print metric(Yts, proba_test, sample_weight=Wts), \n",
      "        print metric(Ytr, proba_train, sample_weight=Wtr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "print_control_metrics(testFactory.predict(trees),trainFactory.predict(trees))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# greedy pruning for the whole data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import greedy\n",
      "from loss_functions import LogLoss"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 50./trainFactory.n_events*sum(trainFactory.weights)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.000392156862745\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "res_greedy = greedy.greed_up_features_bfs(trees,trainFactory,LogLoss,.3,1,10,10,True,1.,0,regularizer=0.000392156862745)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration # 0  ntrees =  1 \n",
        "best loss =  0.624984679656\n",
        "learning_rate =  0.3\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1  ntrees =  2 \n",
        "best loss =  0.563829959222 \n",
        "last loss =  0.563829959222\n",
        "learning_rate =  0.3\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2  ntrees =  3 \n",
        "best loss =  0.521207759997 \n",
        "last loss =  0.521207759997\n",
        "learning_rate =  0.3\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3  ntrees =  4 \n",
        "best loss =  0.488134568491 \n",
        "last loss =  0.488134568491\n",
        "learning_rate =  0.3\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4  ntrees =  5 \n",
        "best loss =  0.449189341388 \n",
        "last loss =  0.449189341388\n",
        "learning_rate =  0.3\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5  ntrees =  6 \n",
        "best loss =  0.437382355441 \n",
        "last loss =  0.437382355441\n",
        "learning_rate =  0.3\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6  ntrees =  7 \n",
        "best loss =  0.413322315798 \n",
        "last loss =  0.413322315798\n",
        "learning_rate =  0.3\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7  ntrees =  8 \n",
        "best loss =  0.405701142671 \n",
        "last loss =  0.405701142671\n",
        "learning_rate =  0.3\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8  ntrees =  9 \n",
        "best loss =  0.396931038558 \n",
        "last loss =  0.396931038558\n",
        "learning_rate =  0.3\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9  ntrees =  10 \n",
        "best loss =  0.389739864623 \n",
        "last loss =  0.389739864623\n",
        "learning_rate =  0.3\n",
        "sample_size 10\n",
        "Wall time: 2.36 s\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res_greedy_wheel = greedy.wheel_up_features_bfs (copy.copy(res_greedy),\n",
      "                           trees,\n",
      "                           trainFactory,\n",
      "                           LogLoss,\n",
      "                           .301,\n",
      "                           30,\n",
      "                           10,\n",
      "                           verbose = True,\n",
      "                           learning_rate_decay = 1.,\n",
      "                           trees_sample_increase = 0,\n",
      "                           regularizer = 0.000392156862745,\n",
      "                           random_walk = True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration # 0  ntrees =  10 \n",
        "best loss =  0.389739864623\n",
        "learning_rate =  0.301\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1  ntrees =  10 \n",
        "best loss =  0.389739864623 \n",
        "last loss =  0.39434556692\n",
        "changed index 4\n",
        "learning_rate =  0.301\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2  ntrees =  10 \n",
        "best loss =  0.389739864623 \n",
        "last loss =  0.392999149175\n",
        "changed index 2\n",
        "learning_rate =  0.301\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3  ntrees =  10 \n",
        "best loss =  0.389739864623 \n",
        "last loss =  0.391628695399\n",
        "changed index 6\n",
        "learning_rate =  0.301\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4  ntrees =  10 \n",
        "best loss =  0.38971923781 \n",
        "last loss =  0.38971923781\n",
        "changed index 9\n",
        "learning_rate =  0.301\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5  ntrees =  10 \n",
        "best loss =  0.38971923781 \n",
        "last loss =  0.391608888234\n",
        "changed index 6\n",
        "learning_rate =  0.301\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6  ntrees =  10 \n",
        "best loss =  0.38971923781 \n",
        "last loss =  0.389868506154\n",
        "changed index 8\n",
        "learning_rate =  0.301\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7  ntrees =  10 \n",
        "best loss =  0.387322562227 \n",
        "last loss =  0.387322562227\n",
        "changed index 9\n",
        "learning_rate =  0.301\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8  ntrees =  10 \n",
        "best loss =  0.387322562227 \n",
        "last loss =  0.391920823176\n",
        "changed index 2\n",
        "learning_rate =  0.301\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9  ntrees =  10 \n",
        "best loss =  0.386565708958 \n",
        "last loss =  0.386565708958\n",
        "changed index 7\n",
        "learning_rate =  0.301\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10  ntrees =  10 \n",
        "best loss =  0.386565708958 \n",
        "last loss =  0.386959880198\n",
        "changed index 8\n",
        "learning_rate =  0.301\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11  ntrees =  10 \n",
        "best loss =  0.386565708958 \n",
        "last loss =  0.386959880198\n",
        "changed index 8\n",
        "learning_rate =  0.301\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12  ntrees =  10 \n",
        "best loss =  0.383032988362 \n",
        "last loss =  0.383032988362\n",
        "changed index 7\n",
        "learning_rate =  0.301\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13  ntrees =  10 \n",
        "best loss =  0.383032988362 \n",
        "last loss =  0.389306024765\n",
        "changed index 0\n",
        "learning_rate =  0.301\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14  ntrees =  10 \n",
        "best loss =  0.383032988362 \n",
        "last loss =  0.386611076362\n",
        "changed index 3\n",
        "learning_rate =  0.301\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 15  ntrees =  10 \n",
        "best loss =  0.383032988362 \n",
        "last loss =  0.383032988362\n",
        "changed index 7\n",
        "learning_rate =  0.301\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 16  ntrees =  10 \n",
        "best loss =  0.382455023024 \n",
        "last loss =  0.382455023024\n",
        "changed index 8\n",
        "learning_rate =  0.301\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 17  ntrees =  10 \n",
        "best loss =  0.382455023024 \n",
        "last loss =  0.386977584632\n",
        "changed index 0\n",
        "learning_rate =  0.301\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 18  ntrees =  10 \n",
        "best loss =  0.381911582207 \n",
        "last loss =  0.381911582207\n",
        "changed index 7\n",
        "learning_rate =  0.301\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 19  ntrees =  10 \n",
        "best loss =  0.380339819355 \n",
        "last loss =  0.380339819355\n",
        "changed index 8\n",
        "learning_rate =  0.301\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 20  ntrees =  10 \n",
        "best loss =  0.380339819355 \n",
        "last loss =  0.383852531449\n",
        "changed index 3\n",
        "learning_rate =  0.301\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 21  ntrees =  10 \n",
        "best loss =  0.380339819355 \n",
        "last loss =  0.385021696475\n",
        "changed index 4\n",
        "learning_rate =  0.301\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 22  ntrees =  10 \n",
        "best loss =  0.380339819355 \n",
        "last loss =  0.380847375609\n",
        "changed index 7\n",
        "learning_rate =  0.301\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 23  ntrees =  10 \n",
        "best loss =  0.380339819355 \n",
        "last loss =  0.383990502476\n",
        "changed index 1\n",
        "learning_rate =  0.301\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 24  ntrees =  10 \n",
        "best loss =  0.380339819355 \n",
        "last loss =  0.385269668943\n",
        "changed index 1\n",
        "learning_rate =  0.301\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 25  ntrees =  10 \n",
        "best loss =  0.380339819355 \n",
        "last loss =  0.380339819355\n",
        "changed index 8\n",
        "learning_rate =  0.301\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 26  ntrees =  10 \n",
        "best loss =  0.380339819355 \n",
        "last loss =  0.381071579813\n",
        "changed index 2\n",
        "learning_rate =  0.301\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 27  ntrees =  10 \n",
        "best loss =  0.380339819355 \n",
        "last loss =  0.380709945784\n",
        "changed index 9\n",
        "learning_rate =  0.301\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 28  ntrees =  10 \n",
        "best loss =  0.380339819355 \n",
        "last loss =  0.380339819355\n",
        "changed index 8\n",
        "learning_rate =  0.301\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 29  ntrees =  10 \n",
        "best loss =  0.380339819355 \n",
        "last loss =  0.383852531449\n",
        "changed index 3\n",
        "learning_rate =  0.301\n",
        "sample_size 10\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 30  ntrees =  10 \n",
        "best loss =  0.380339819355 \n",
        "last loss =  0.380339819355\n",
        "changed index 8\n",
        "learning_rate =  0.301\n",
        "sample_size 10\n"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_pred_stupid = greedy.predict(testFactory,trees[:100])\n",
      "y_pred_full = greedy.predict(testFactory,trees)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_pred_greedy = testFactory.predict(res_greedy[:100])\n",
      "y_pred_wheel = testFactory.predict(res_greedy_wheel[:100])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "w_test = testFactory.weights\n",
      "\n",
      "print metrics.roc_auc_score(Yts,y_pred_greedy,sample_weight=w_test),\n",
      "print metrics.roc_auc_score(Yts,y_pred_wheel,sample_weight=w_test),\n",
      "print metrics.roc_auc_score(Yts,y_pred_stupid,sample_weight=w_test),\n",
      "print metrics.roc_auc_score(Yts,y_pred_full,sample_weight=w_test)\n",
      "print \"well...\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.914814481037 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.916003794567 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.916904744001 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.935834322801\n",
        "well...\n"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "_ = joblib.dump(res_greedy,\"dumps/greedy 100 trees\")\n",
      "_ = joblib.dump(res_greedy,\"dumps/greedy 100 trees pod kol\u0451sami\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Upper level thresholds extraction"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#usability distribution\n",
      "thresholds = mnet.get_thresholds(trees,30,0.001)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.scatter(range(len(thresholds)),thresholds[:,2])\n",
      "print sum(thresholds[:,2] >150)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "96\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEACAYAAAC3adEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKEoMVQyKoihKjP8fJ1hkB2V48tkAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x2a90d080>"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Criteria selection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import hierarchy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get them...\n",
      "thresholds_active = thresholds[thresholds[:,2]>100]\n",
      "print len(thresholds_active)\n",
      "criteria = hierarchy.select_criteria(trainFactory,thresholds_active,3,True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "190\n",
        "s:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [81387L, 46113L]\n",
        "w: [0.4995172311764362, 0.50048276882352416]\n",
        "s:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [35853L, 45534L, 28287L, 17826L]\n",
        "w: [0.26914160839995621, 0.23037562277645596, 0.27439612166068927, 0.22608664716287472]\n",
        "s:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [6226L, 11600L, 18312L, 9975L, 18579L, 17274L, 28399L, 17135L]\n",
        "w: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0.10092029004556231, 0.12516635711728766, 0.16975948409694844, 0.10463663756370174, 0.12697836451232206, 0.14216324388758639, 0.13573214315325532, 0.094643479623169297]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "loss_functions.py:45: RuntimeWarning: divide by zero encountered in log\n",
        "  logs = np.array(map(np.log,distribution))\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "criteria"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "[array([  21.        ,  147.61599731,  136.        ]),\n",
        " array([   2.        ,   78.67050171,  131.        ]),\n",
        " array([   1.        ,   44.68050003,  153.        ])]"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "split = hierarchy.split_upper(trainFactory,criteria[:2],equalizeWeights=False,split_weights=.75,split_inclusion=0.5)\n",
      "print [split[i].events.shape[0] for i in split]\n",
      "print [sum(split[i].weights) for i in split]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[74617L, 82047L, 68962L, 61248L]\n",
        "[0.47844060626966423, 0.46565480792009306, 0.48439329044896512, 0.46401746189945459]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Hierarchical stuff"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "trees_splitted = hierarchy.train_splitted_boosts(trees, trainFactory,criteria[:2],LogLoss,0.29,1,\n",
      "                                                 10,10,regularizer =0.0004,\n",
      "                                                 verbose=False,use_joblib = True,n_jobs = 4,\n",
      "                                                 weights_outside_leaf = 0.75, inclusion_outside_leaf = 0.5,#0.375 weight\n",
      "                                                 wheel_up_times = 30,wheel_learning_rate = 0.3) \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fortune-wheeling the trees\n",
        "Wall time: 14 s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "trees_splitted = hierarchy.train_splitted_boosts(trees, trainFactory,criteria[:2],LogLoss,0.29,1,\n",
      "                                                 10,10,regularizer =0.0004,\n",
      "                                                 verbose=False,use_joblib = False,\n",
      "                                                 weights_outside_leaf = 0.75, inclusion_outside_leaf = 0.5,#0.375 weight\n",
      "                                                 wheel_up_times = 30,wheel_learning_rate = 0.3) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fortune-wheeling the trees\n",
        "fortune-wheeling the trees"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "fortune-wheeling the trees"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "fortune-wheeling the trees"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Wall time: 36.6 s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_pred_splitted= hierarchy.predict_splitted(testFactory,criteria[:2],trees_splitted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "_= joblib.dump([criteria,trees_splitted],\"dumps/splitted 100 trees\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "w_test = testFactory.weights\n",
      "Yts = testFactory.labels\n",
      "print 'spltd\\t',metrics.roc_auc_score(Yts,y_pred_splitted,sample_weight=w_test)\n",
      "print 'greedy\\t',metrics.roc_auc_score(Yts,y_pred_greedy,sample_weight=w_test)\n",
      "print 'stupid\\t',metrics.roc_auc_score(Yts,y_pred_stupid,sample_weight=w_test)\n",
      "print 'full\\t',metrics.roc_auc_score(Yts,y_pred_full,sample_weight=w_test)\n",
      "print \"well...\"\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "spltd\t0.919768406872"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "greedy\t0.914814481037"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stupid\t0.916904744001"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "full\t0.935834322801"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "well...\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#learning curves"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#I know it could have been done without quadratic complexity over trees, but...\n",
      "#btw equalizing 1-0 weights for the training set is not optimal in terms of AUC, but it is close to being so.\n",
      "n_trees =100\n",
      "auc_stupid_lcurve = [(0.5,)]\n",
      "auc_greedy_lcurve = [(0.5,)]\n",
      "auc_splitted_lcurve = [(0.5,)]\n",
      "for i in range(1,n_trees):\n",
      "    #stpd\n",
      "    pred = testFactory.predict(trees[:i])\n",
      "    auc = metrics.roc_auc_score(testFactory.labels,pred,sample_weight=testFactory.weights),\n",
      "    auc_stupid_lcurve.append( auc)    \n",
      "    #grdy\n",
      "    pred = testFactory.predict(res_greedy[:i])\n",
      "    auc = metrics.roc_auc_score(testFactory.labels,pred,sample_weight=testFactory.weights),\n",
      "    auc_greedy_lcurve.append( auc)\n",
      "    #split\n",
      "    trees_i = {code:trees_splitted[code][:i] for code in trees_splitted}\n",
      "    pred = predict_splitted(testFactory,criteria[:2],trees_i)\n",
      "\n",
      "    auc = metrics.roc_auc_score(testFactory.labels,pred,sample_weight=testFactory.weights),\n",
      "    auc_splitted_lcurve.append( auc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p = range(1,n_trees)\n",
      "plt.figure(figsize = [14,14])\n",
      "plt.plot(p,[0.935834322801 for i in range(1,n_trees)],label = \"full\")\n",
      "plt.plot(p,auc_stupid_lcurve[1:n_trees],label = \"stupid\")\n",
      "plt.plot(p,auc_greedy_lcurve[1:n_trees],label = \"greedy\")\n",
      "plt.plot(p,auc_splitted_lcurve[1:n_trees],label = \"splitted\")\n",
      "plt.title('learning curves')\n",
      "plt.legend(loc=\"lower right\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#ROC at 10"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_pred_greedy_10 = testFactory.predict(res_greedy[:10])\n",
      "y_pred_stupid_10 = testFactory.predict(trees[:10])\n",
      "y_pred_splitted_10 =  predict_splitted(testFactory,criteria[:2], {code:trees_splitted[code][:10] for code in trees_splitted})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot ROC curve\n",
      "plt.figure(figsize = [14,14])\n",
      "fpr, tpr, _ = metrics.roc_curve(Yts, y_pred_full,sample_weight=testFactory.weights)\n",
      "plt.plot(fpr, tpr,\n",
      "         label='Full boost classi 10k trees')\n",
      "fpr, tpr, _ = metrics.roc_curve(Yts, y_pred_stupid_10,sample_weight=testFactory.weights)\n",
      "plt.plot(fpr, tpr,\n",
      "         label='first N trees classi')\n",
      "fpr, tpr, _ = metrics.roc_curve(Yts, y_pred_greedy_10,sample_weight=testFactory.weights)\n",
      "plt.plot(fpr, tpr,\n",
      "         label='Greedy prune classi')\n",
      "fpr, tpr, _ = metrics.roc_curve(Yts, y_pred_splitted_10,sample_weight=testFactory.weights)\n",
      "plt.plot(fpr, tpr,\n",
      "         label='4-leaf split classi')\n",
      "\n",
      "\n",
      "plt.plot([0, 1], [0, 1], 'k--')\n",
      "plt.xlim([0.0, 1.0])\n",
      "plt.ylim([0.0, 1.05])\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.title('ROC curves at 10 trees')\n",
      "plt.legend(loc=\"lower right\")\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#ROC at 30"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_pred_greedy_30 = testFactory.predict(res_greedy[:30])\n",
      "y_pred_stupid_30 = testFactory.predict(trees[:30])\n",
      "y_pred_splitted_30 =  predict_splitted(testFactory,criteria[:2], {code:trees_splitted[code][:30] for code in trees_splitted})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot ROC curve\n",
      "plt.figure(figsize = [14,14])\n",
      "fpr, tpr, _ = metrics.roc_curve(Yts, y_pred_full,sample_weight=testFactory.weights)\n",
      "plt.plot(fpr, tpr,\n",
      "         label='Full boost classi 10k trees')\n",
      "fpr, tpr, _ = metrics.roc_curve(Yts, y_pred_stupid_30,sample_weight=testFactory.weights)\n",
      "plt.plot(fpr, tpr,\n",
      "         label='first N trees classi')\n",
      "fpr, tpr, _ = metrics.roc_curve(Yts, y_pred_greedy_30,sample_weight=testFactory.weights)\n",
      "plt.plot(fpr, tpr,\n",
      "         label='Greedy prune classi')\n",
      "fpr, tpr, _ = metrics.roc_curve(Yts, y_pred_splitted_30,sample_weight=testFactory.weights)\n",
      "plt.plot(fpr, tpr,\n",
      "         label='4-leaf split classi')\n",
      "\n",
      "\n",
      "plt.plot([0, 1], [0, 1], 'k--')\n",
      "plt.xlim([0.0, 1.0])\n",
      "plt.ylim([0.0, 1.05])\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.title('ROC curves at 10 trees')\n",
      "plt.legend(loc=\"lower right\")\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#ROC at 100"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_pred_greedy_100 = testFactory.predict(res_greedy[:100])\n",
      "y_pred_stupid_100 = testFactory.predict(trees[:100])\n",
      "y_pred_splitted_100 =  predict_splitted(testFactory,criteria[:2], {code:trees_splitted[code][:100] for code in trees_splitted})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot ROC curve\n",
      "plt.figure(figsize = [14,14])\n",
      "fpr, tpr, _ = metrics.roc_curve(Yts, y_pred_full,sample_weight=testFactory.weights)\n",
      "plt.plot(fpr, tpr,\n",
      "         label='Full boost classi 10k trees')\n",
      "fpr, tpr, _ = metrics.roc_curve(Yts, y_pred_stupid_100,sample_weight=testFactory.weights)\n",
      "plt.plot(fpr, tpr,\n",
      "         label='first N trees classi')\n",
      "fpr, tpr, _ = metrics.roc_curve(Yts, y_pred_greedy_100,sample_weight=testFactory.weights)\n",
      "plt.plot(fpr, tpr,\n",
      "         label='Greedy prune classi')\n",
      "fpr, tpr, _ = metrics.roc_curve(Yts, y_pred_splitted_100,sample_weight=testFactory.weights)\n",
      "plt.plot(fpr, tpr,\n",
      "         label='4-leaf split classi')\n",
      "\n",
      "\n",
      "plt.plot([0, 1], [0, 1], 'k--')\n",
      "plt.xlim([0.0, 1.0])\n",
      "plt.ylim([0.0, 1.05])\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.title('ROC curves at 100 trees')\n",
      "plt.legend(loc=\"lower right\")\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#kinda..."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}