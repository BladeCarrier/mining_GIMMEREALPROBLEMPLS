{
 "metadata": {
  "name": "",
  "signature": "sha256:affca72e94606958d85daf99fb456b5b5645a07767aac3bc28b983758d78a272"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# I explore the cuts of the features\n",
      "%matplotlib inline\n",
      "#\u0442\u0430\u043a \u0442\u043e\u0436\u0435 \u043c\u043e\u0436\u043d\u043e \u0440\u0435\u0448\u0438\u0442\u044c \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u0443 \u0438\u043d\u043b\u0430\u0439\u043b\u0430 \u043f\u043b\u043e\u0442\u043e\u0432\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "\n",
      "import sklearn.metrics as metrics\n",
      "from sklearn.externals import joblib\n",
      "from sklearn import cross_validation as cv\n",
      "\n",
      "import _matrixnetapplier as mnet\n",
      "import copy\n",
      "import random\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "@\u041c-\u0441\u044c\u0435 \u0412\u044f\u0447\u0435\u0441\u043b\u0430\u0432 \u0410\u043b\u0438\u043f\u043e\u0432\n",
      "\u0414\u043e\u0431\u0440\u044b\u0439 \u0451\u0436\u0438\u043a!\n",
      "\u041d\u0438\u0436\u0435 \u0441\u043b\u0435\u0434\u0443\u0435\u0442 \u0434\u0435\u043c\u043a\u0430 \u0442\u043e\u0433\u043e, \u043a\u0430\u043a \u043d\u0430\u0448 \u043f\u0440\u0443\u043d\u0435\u0440 \u0437\u0430\u0432\u043e\u0434\u0438\u0442\u044c \u0438 \u043d\u0430\u0444\u0438\u0433\u0430 \u043e\u043d \u043d\u0443\u0436\u0435\u043d. \n",
      "\u0421\u0430\u043c \u043f\u0440\u0443\u043d\u0435\u0440 \u0434\u043e\u043b\u0436\u0435\u043d \u043b\u0435\u0436\u0430\u0442\u044c \u0432 \u044d\u0442\u043e\u0439 \u0436\u0435 \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u0438\n",
      "\u0427\u0442\u043e \u0435\u043c\u0443 \u043d\u0443\u0436\u043d\u043e: python 2.7, sklearn(0.16.1), numpy, scipy, matplotlib, \n",
      "\u041e\u0442\u043a\u0443\u0434\u0430 \u0434\u0430\u0442\u0430:  training.csv \u0438\u0437 kaggle higgs challenge, formula.mx - mx\u043d\u044b\u0439 \u0444\u0430\u0439\u043b \u043c\u0430\u0442\u0440\u0438\u043a\u0441\u043d\u0435\u0442\u0430, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 10000 \u0434\u0435\u0435\u0432\u044c\u0435\u0432. \u0423\u0447\u0438\u043b\u0441\u044f \u043d\u0430 \u0442\u0435\u0445 \u0436\u0435 Xtr,Ytr,Wtr, \u0447\u0442\u043e \u0444\u0438\u0433\u0443\u0440\u0438\u0440\u0443\u044e\u0442  \u0434\u0430\u043b\u0435\u0435 \u0432 \u0442\u0435\u0442\u0440\u0430\u0434\u043a\u0435."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Extracting the trained model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "itr,trees = mnet.get_trees(\"formula/formula.mx\") #\u043d\u0430\u0443\u0447\u0435\u043d\u0430\u044f \u043f\u043e LogLoss\u0443 \u0444\u043e\u0440\u043c\u0443\u043b\u0430 \u043d\u0430 10k \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432 \u043d\u0430 \u0434\u0435\u0444\u043e\u043b\u0442\u043d\u044b\u0445 \u0444\u0438\u0447\u0430\u0445\n",
      "n_features = 30\n",
      "print itr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(6, 10000, <generator object _iterate_over_trees_with_fixed_depth at 0x000000000AC6EC18>)\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Loading dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#load training set\n",
      "def load_data(path):\n",
      "    print 'Loading training data...'\n",
      "    data = np.loadtxt(path, \\\n",
      "            delimiter=',', \\\n",
      "            skiprows=1, \\\n",
      "            converters={32: lambda x:int(x=='s'.encode('utf-8'))})\n",
      "\n",
      "    X = data[:,1:31]\n",
      "    Y = data[:,32]\n",
      "    W = data[:,31]\n",
      "    print \"Loaded.\"\n",
      "    return X,Y,W"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X,Y,W = load_data(\"data/training.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading training data...\n",
        "Loaded."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "Xtr,Xts,Ytr,Yts,Wtr,Wts = train_test_split(X, Y, W, train_size=0.51, random_state=42)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from factory import DataFactory\n",
      "#DataFactory is just a data wrapper that can handle splits, predictions, etc. \n",
      "#Used to avoid recomputing metadata at each predictions and passing large argument strings\n",
      "trainFactory = DataFactory(Xtr,Ytr,Wtr)\n",
      "testFactory = DataFactory(Xts,Yts,Wts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#equalize classes, normalize weights\n",
      "trainFactory.equalizeWeights()\n",
      "print sum(trainFactory.weights[trainFactory.labels==1]),\n",
      "print sum(trainFactory.weights[trainFactory.labels==0]),\n",
      "print sum(trainFactory.weights),"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.5 0.5 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.999999999999\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#sanity check"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compute_ams_on_cuts(answers, predictions, sample_weight):\n",
      "    \"\"\" Predictions are probabilities\"\"\"\n",
      "    b, s, thresholds = metrics.roc_curve(answers, predictions, sample_weight=sample_weight)\n",
      "    # normalization constants\n",
      "    real_s = 691.988607712\n",
      "    real_b = 410999.847322\n",
      "    s *= real_s\n",
      "    b *= real_b\n",
      "    br = 10.\n",
      "    radicands = 2 * ((s + b + br) * np.log(1.0 + s/(b + br)) - s)\n",
      "    return thresholds, radicands\n",
      "\n",
      "def optimal_AMS(answers, predictions, sample_weight):\n",
      "    \"\"\" Predictions are probabilities \"\"\"\n",
      "    cuts, radicands = compute_ams_on_cuts(answers, predictions, sample_weight)\n",
      "    return np.sqrt(np.max(radicands))\n",
      "\n",
      "\n",
      "def precisionAt15(answers, predictions, sample_weight, percent=0.15):\n",
      "    n_passed = int(len(answers) * percent)\n",
      "    RATIO = 50\n",
      "    weight = sample_weight.copy()\n",
      "    weight[answers == 0] /= weight[answers == 0].mean() / RATIO\n",
      "    weight[answers == 1] /= weight[answers == 1].mean()\n",
      "    order = np.argsort(-predictions)\n",
      "    passed = order[:n_passed]    \n",
      "    return np.average(answers[passed], weights=weight[passed])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_control_metrics(proba_test, proba_train):\n",
      "    for name, metric in [('ROC', metrics.roc_auc_score), ('AMS', optimal_AMS), ('precision', precisionAt15)]:\n",
      "        print name,\n",
      "        print metric(Yts, proba_test, sample_weight=Wts), \n",
      "        print metric(Ytr, proba_train, sample_weight=Wtr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "print_control_metrics(testFactory.predict(trees),trainFactory.predict(trees))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ROC "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.935834322801 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.961031805042\n",
        "AMS "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3.71746365006 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5.41899018232\n",
        "precision 0.266316147498 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.394846517557\n",
        "Wall time: 1min 10s\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# greedy pruning for the whole data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import greedy\n",
      "from loss_functions import LogLoss"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "res_greedy = greedy.greed_up_features_bfs(trees,trainFactory,\n",
      "                                          loss = LogLoss,\n",
      "                                          learning_rate = .25,\n",
      "                                          learning_rate_decay=1.,# no decay\n",
      "                                          nTrees =150,\n",
      "                                          trees_sample_size =100, #chosen from the ensemble at random each iteration\n",
      "                                          verbose = True,\n",
      "                                          regularizer=0.0004, #added to gradient walker's leaf denominator\n",
      "                                          use_joblib=True,\n",
      "                                          n_jobs=-1,\n",
      "                                          joblib_method=\"threads\" #every GIL-ly thing is copied anyways\n",
      "                                          )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration # 0  ntrees =  1 \n",
        "best loss =  0.588947804637\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1  ntrees =  2 \n",
        "best loss =  0.521734612549 \n",
        "last loss =  0.521734612549\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2  ntrees =  3 \n",
        "best loss =  0.476768530581 \n",
        "last loss =  0.476768530581\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3  ntrees =  4 \n",
        "best loss =  0.445608946392 \n",
        "last loss =  0.445608946392\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4  ntrees =  5 \n",
        "best loss =  0.423233394908 \n",
        "last loss =  0.423233394908\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5  ntrees =  6 \n",
        "best loss =  0.406764494162 \n",
        "last loss =  0.406764494162\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6  ntrees =  7 \n",
        "best loss =  0.394572055659 \n",
        "last loss =  0.394572055659\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7  ntrees =  8 \n",
        "best loss =  0.385152857867 \n",
        "last loss =  0.385152857867\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8  ntrees =  9 \n",
        "best loss =  0.377420826067 \n",
        "last loss =  0.377420826067\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9  ntrees =  10 \n",
        "best loss =  0.371579745949 \n",
        "last loss =  0.371579745949\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10  ntrees =  11 \n",
        "best loss =  0.366768061127 \n",
        "last loss =  0.366768061127\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11  ntrees =  12 \n",
        "best loss =  0.36253230826 \n",
        "last loss =  0.36253230826\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12  ntrees =  13 \n",
        "best loss =  0.359136335786 \n",
        "last loss =  0.359136335786\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13  ntrees =  14 \n",
        "best loss =  0.356098418107 \n",
        "last loss =  0.356098418107\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14  ntrees =  15 \n",
        "best loss =  0.353511694798 \n",
        "last loss =  0.353511694798\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 15  ntrees =  16 \n",
        "best loss =  0.351204895442 \n",
        "last loss =  0.351204895442\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 16  ntrees =  17 \n",
        "best loss =  0.348955825511 \n",
        "last loss =  0.348955825511\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 17  ntrees =  18 \n",
        "best loss =  0.347247589283 \n",
        "last loss =  0.347247589283\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 18  ntrees =  19 \n",
        "best loss =  0.345561308217 \n",
        "last loss =  0.345561308217\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 19  ntrees =  20 \n",
        "best loss =  0.343985680044 \n",
        "last loss =  0.343985680044\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 20  ntrees =  21 \n",
        "best loss =  0.342597398465 \n",
        "last loss =  0.342597398465\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 21  ntrees =  22 \n",
        "best loss =  0.341293917541 \n",
        "last loss =  0.341293917541\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 22  ntrees =  23 \n",
        "best loss =  0.340054212163 \n",
        "last loss =  0.340054212163\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 23  ntrees =  24 \n",
        "best loss =  0.338971758089 \n",
        "last loss =  0.338971758089\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 24  ntrees =  25 \n",
        "best loss =  0.33788814832 \n",
        "last loss =  0.33788814832\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 25  ntrees =  26 \n",
        "best loss =  0.336896869822 \n",
        "last loss =  0.336896869822\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 26  ntrees =  27 \n",
        "best loss =  0.336001518846 \n",
        "last loss =  0.336001518846\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 27  ntrees =  28 \n",
        "best loss =  0.33509519967 \n",
        "last loss =  0.33509519967\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 28  ntrees =  29 \n",
        "best loss =  0.334313272967 \n",
        "last loss =  0.334313272967\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 29  ntrees =  30 \n",
        "best loss =  0.333561202388 \n",
        "last loss =  0.333561202388\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 30  ntrees =  31 \n",
        "best loss =  0.332809655038 \n",
        "last loss =  0.332809655038\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 31  ntrees =  32 \n",
        "best loss =  0.332129107423 \n",
        "last loss =  0.332129107423\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 32  ntrees =  33 \n",
        "best loss =  0.331466025643 \n",
        "last loss =  0.331466025643\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33  ntrees =  34 \n",
        "best loss =  0.330874644589 \n",
        "last loss =  0.330874644589\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 34  ntrees =  35 \n",
        "best loss =  0.330272310915 \n",
        "last loss =  0.330272310915\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 35  ntrees =  36 \n",
        "best loss =  0.329731037398 \n",
        "last loss =  0.329731037398\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 36  ntrees =  37 \n",
        "best loss =  0.329205666199 \n",
        "last loss =  0.329205666199\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 37  ntrees =  38 \n",
        "best loss =  0.328706385918 \n",
        "last loss =  0.328706385918\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 38  ntrees =  39 \n",
        "best loss =  0.328213626008 \n",
        "last loss =  0.328213626008\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 39  ntrees =  40 \n",
        "best loss =  0.327746816387 \n",
        "last loss =  0.327746816387\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 40  ntrees =  41 \n",
        "best loss =  0.327282366709 \n",
        "last loss =  0.327282366709\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 41  ntrees =  42 \n",
        "best loss =  0.326853890173 \n",
        "last loss =  0.326853890173\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 42  ntrees =  43 \n",
        "best loss =  0.326405101295 \n",
        "last loss =  0.326405101295\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 43  ntrees =  44 \n",
        "best loss =  0.325965964564 \n",
        "last loss =  0.325965964564\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 44  ntrees =  45 \n",
        "best loss =  0.325537348693 \n",
        "last loss =  0.325537348693\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 45  ntrees =  46 \n",
        "best loss =  0.325114944467 \n",
        "last loss =  0.325114944467\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 46  ntrees =  47 \n",
        "best loss =  0.324708041144 \n",
        "last loss =  0.324708041144\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 47  ntrees =  48 \n",
        "best loss =  0.324349147591 \n",
        "last loss =  0.324349147591\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 48  ntrees =  49 \n",
        "best loss =  0.323960510028 \n",
        "last loss =  0.323960510028\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 49  ntrees =  50 \n",
        "best loss =  0.323564881918 \n",
        "last loss =  0.323564881918\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 50  ntrees =  51 \n",
        "best loss =  0.323222632337 \n",
        "last loss =  0.323222632337\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 51  ntrees =  52 \n",
        "best loss =  0.322867571582 \n",
        "last loss =  0.322867571582\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 52  ntrees =  53 \n",
        "best loss =  0.322538251131 \n",
        "last loss =  0.322538251131\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 53  ntrees =  54 \n",
        "best loss =  0.322199656002 \n",
        "last loss =  0.322199656002\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 54  ntrees =  55 \n",
        "best loss =  0.321871503305 \n",
        "last loss =  0.321871503305\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 55  ntrees =  56 \n",
        "best loss =  0.321590292357 \n",
        "last loss =  0.321590292357\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 56  ntrees =  57 \n",
        "best loss =  0.321278840116 \n",
        "last loss =  0.321278840116\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 57  ntrees =  58 \n",
        "best loss =  0.32098062676 \n",
        "last loss =  0.32098062676\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 58  ntrees =  59 \n",
        "best loss =  0.320688278277 \n",
        "last loss =  0.320688278277\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 59  ntrees =  60 \n",
        "best loss =  0.320362476334 \n",
        "last loss =  0.320362476334\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 60  ntrees =  61 \n",
        "best loss =  0.320062696818 \n",
        "last loss =  0.320062696818\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 61  ntrees =  62 \n",
        "best loss =  0.319783045613 \n",
        "last loss =  0.319783045613\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 62  ntrees =  63 \n",
        "best loss =  0.319510588524 \n",
        "last loss =  0.319510588524\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 63  ntrees =  64 \n",
        "best loss =  0.319239298441 \n",
        "last loss =  0.319239298441\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 64  ntrees =  65 \n",
        "best loss =  0.318964855519 \n",
        "last loss =  0.318964855519\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 65  ntrees =  66 \n",
        "best loss =  0.318703116638 \n",
        "last loss =  0.318703116638\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 66  ntrees =  67 \n",
        "best loss =  0.318424495914 \n",
        "last loss =  0.318424495914\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 67  ntrees =  68 \n",
        "best loss =  0.318168401017 \n",
        "last loss =  0.318168401017\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 68  ntrees =  69 \n",
        "best loss =  0.317899567422 \n",
        "last loss =  0.317899567422\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 69  ntrees =  70 \n",
        "best loss =  0.31764978013 \n",
        "last loss =  0.31764978013\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 70  ntrees =  71 \n",
        "best loss =  0.317394520652 \n",
        "last loss =  0.317394520652\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 71  ntrees =  72 \n",
        "best loss =  0.317121117603 \n",
        "last loss =  0.317121117603\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 72  ntrees =  73 \n",
        "best loss =  0.31684292874 \n",
        "last loss =  0.31684292874\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 73  ntrees =  74 \n",
        "best loss =  0.316596032998 \n",
        "last loss =  0.316596032998\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 74  ntrees =  75 \n",
        "best loss =  0.316354758734 \n",
        "last loss =  0.316354758734\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 75  ntrees =  76 \n",
        "best loss =  0.316121713079 \n",
        "last loss =  0.316121713079\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 76  ntrees =  77 \n",
        "best loss =  0.315894181906 \n",
        "last loss =  0.315894181906\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 77  ntrees =  78 \n",
        "best loss =  0.315644894103 \n",
        "last loss =  0.315644894103\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 78  ntrees =  79 \n",
        "best loss =  0.315410763674 \n",
        "last loss =  0.315410763674\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 79  ntrees =  80 \n",
        "best loss =  0.315182710911 \n",
        "last loss =  0.315182710911\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 80  ntrees =  81 \n",
        "best loss =  0.314951176742 \n",
        "last loss =  0.314951176742\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 81  ntrees =  82 \n",
        "best loss =  0.314720700572 \n",
        "last loss =  0.314720700572\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 82  ntrees =  83 \n",
        "best loss =  0.314489803059 \n",
        "last loss =  0.314489803059\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 83  ntrees =  84 \n",
        "best loss =  0.31426981991 \n",
        "last loss =  0.31426981991\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84  ntrees =  85 \n",
        "best loss =  0.314057989212 \n",
        "last loss =  0.314057989212\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85  ntrees =  86 \n",
        "best loss =  0.313817626259 \n",
        "last loss =  0.313817626259\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 86  ntrees =  87 \n",
        "best loss =  0.313574489793 \n",
        "last loss =  0.313574489793\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 87  ntrees =  88 \n",
        "best loss =  0.313350888851 \n",
        "last loss =  0.313350888851\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 88  ntrees =  89 \n",
        "best loss =  0.313121662466 \n",
        "last loss =  0.313121662466\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 89  ntrees =  90 \n",
        "best loss =  0.31291758476 \n",
        "last loss =  0.31291758476\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 90  ntrees =  91 \n",
        "best loss =  0.312697600355 \n",
        "last loss =  0.312697600355\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 91  ntrees =  92 \n",
        "best loss =  0.312477068298 \n",
        "last loss =  0.312477068298\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 92  ntrees =  93 \n",
        "best loss =  0.312267503876 \n",
        "last loss =  0.312267503876\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 93  ntrees =  94 \n",
        "best loss =  0.312043809042 \n",
        "last loss =  0.312043809042\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 94  ntrees =  95 \n",
        "best loss =  0.311806064191 \n",
        "last loss =  0.311806064191\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 95  ntrees =  96 \n",
        "best loss =  0.311569916971 \n",
        "last loss =  0.311569916971\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 96  ntrees =  97 \n",
        "best loss =  0.311364328125 \n",
        "last loss =  0.311364328125\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 97  ntrees =  98 \n",
        "best loss =  0.311167874732 \n",
        "last loss =  0.311167874732\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 98  ntrees =  99 \n",
        "best loss =  0.310971929141 \n",
        "last loss =  0.310971929141\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 99  ntrees =  100 \n",
        "best loss =  0.310769285479 \n",
        "last loss =  0.310769285479\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100  ntrees =  101 \n",
        "best loss =  0.310541948559 \n",
        "last loss =  0.310541948559\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101  ntrees =  102 \n",
        "best loss =  0.310342566235 \n",
        "last loss =  0.310342566235\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102  ntrees =  103 \n",
        "best loss =  0.310159092667 \n",
        "last loss =  0.310159092667\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 103  ntrees =  104 \n",
        "best loss =  0.309965488347 \n",
        "last loss =  0.309965488347\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 104  ntrees =  105 \n",
        "best loss =  0.309775823048 \n",
        "last loss =  0.309775823048\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 105  ntrees =  106 \n",
        "best loss =  0.309579518502 \n",
        "last loss =  0.309579518502\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 106  ntrees =  107 \n",
        "best loss =  0.309380513048 \n",
        "last loss =  0.309380513048\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107  ntrees =  108 \n",
        "best loss =  0.30916484111 \n",
        "last loss =  0.30916484111\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108  ntrees =  109 \n",
        "best loss =  0.308981887055 \n",
        "last loss =  0.308981887055\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109  ntrees =  110 \n",
        "best loss =  0.308788459132 \n",
        "last loss =  0.308788459132\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 110  ntrees =  111 \n",
        "best loss =  0.308595521755 \n",
        "last loss =  0.308595521755\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 111  ntrees =  112 \n",
        "best loss =  0.308407625611 \n",
        "last loss =  0.308407625611\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 112  ntrees =  113 \n",
        "best loss =  0.308223913086 \n",
        "last loss =  0.308223913086\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 113  ntrees =  114 \n",
        "best loss =  0.308035141528 \n",
        "last loss =  0.308035141528\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 114  ntrees =  115 \n",
        "best loss =  0.307854527129 \n",
        "last loss =  0.307854527129\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 115  ntrees =  116 \n",
        "best loss =  0.30767237475 \n",
        "last loss =  0.30767237475\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 116  ntrees =  117 \n",
        "best loss =  0.307488816551 \n",
        "last loss =  0.307488816551\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 117  ntrees =  118 \n",
        "best loss =  0.307293630553 \n",
        "last loss =  0.307293630553\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118  ntrees =  119 \n",
        "best loss =  0.307099663992 \n",
        "last loss =  0.307099663992\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119  ntrees =  120 \n",
        "best loss =  0.306928232761 \n",
        "last loss =  0.306928232761\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 120  ntrees =  121 \n",
        "best loss =  0.306751225079 \n",
        "last loss =  0.306751225079\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 121  ntrees =  122 \n",
        "best loss =  0.306573745652 \n",
        "last loss =  0.306573745652\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 122  ntrees =  123 \n",
        "best loss =  0.30640623473 \n",
        "last loss =  0.30640623473\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 123  ntrees =  124 \n",
        "best loss =  0.306232087989 \n",
        "last loss =  0.306232087989\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 124  ntrees =  125 \n",
        "best loss =  0.306062084739 \n",
        "last loss =  0.306062084739\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 125  ntrees =  126 \n",
        "best loss =  0.305889410474 \n",
        "last loss =  0.305889410474\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 126  ntrees =  127 \n",
        "best loss =  0.305718570814 \n",
        "last loss =  0.305718570814\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 127  ntrees =  128 \n",
        "best loss =  0.305558236277 \n",
        "last loss =  0.305558236277\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 128  ntrees =  129 \n",
        "best loss =  0.30538447291 \n",
        "last loss =  0.30538447291\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 129  ntrees =  130 \n",
        "best loss =  0.305218147569 \n",
        "last loss =  0.305218147569\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 130  ntrees =  131 \n",
        "best loss =  0.305034834744 \n",
        "last loss =  0.305034834744\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 131  ntrees =  132 \n",
        "best loss =  0.304868997964 \n",
        "last loss =  0.304868997964\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 132  ntrees =  133 \n",
        "best loss =  0.304705201838 \n",
        "last loss =  0.304705201838\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 133  ntrees =  134 \n",
        "best loss =  0.304539711588 \n",
        "last loss =  0.304539711588\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 134  ntrees =  135 \n",
        "best loss =  0.304357468997 \n",
        "last loss =  0.304357468997\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 135  ntrees =  136 \n",
        "best loss =  0.30418689345 \n",
        "last loss =  0.30418689345\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 136  ntrees =  137 \n",
        "best loss =  0.304020110649 \n",
        "last loss =  0.304020110649\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 137  ntrees =  138 \n",
        "best loss =  0.303856892962 \n",
        "last loss =  0.303856892962\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 138  ntrees =  139 \n",
        "best loss =  0.303697324969 \n",
        "last loss =  0.303697324969\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 139  ntrees =  140 \n",
        "best loss =  0.303537043558 \n",
        "last loss =  0.303537043558\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 140  ntrees =  141 \n",
        "best loss =  0.303366278453 \n",
        "last loss =  0.303366278453\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 141  ntrees =  142 \n",
        "best loss =  0.3031978625 \n",
        "last loss =  0.3031978625\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 142  ntrees =  143 \n",
        "best loss =  0.30304108037 \n",
        "last loss =  0.30304108037\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 143  ntrees =  144 \n",
        "best loss =  0.30288450717 \n",
        "last loss =  0.30288450717\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 144  ntrees =  145 \n",
        "best loss =  0.302735065535 \n",
        "last loss =  0.302735065535\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 145  ntrees =  146 \n",
        "best loss =  0.302563171498 \n",
        "last loss =  0.302563171498\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 146  ntrees =  147 \n",
        "best loss =  0.302402929907 \n",
        "last loss =  0.302402929907\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 147  ntrees =  148 \n",
        "best loss =  0.302235567465 \n",
        "last loss =  0.302235567465\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 148  ntrees =  149 \n",
        "best loss =  0.302083338437 \n",
        "last loss =  0.302083338437\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 149  ntrees =  150 \n",
        "best loss =  0.301932413424 \n",
        "last loss =  0.301932413424\n",
        "learning_rate =  0.25\n",
        "sample_size 500\n",
        "Wall time: 19min 48s\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_pred_stupid = greedy.predict(testFactory,trees[:100])\n",
      "y_pred_full = greedy.predict(testFactory,trees)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_pred_greedy = testFactory.predict(res_greedy)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'res_greedy' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-37-d745b605f912>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred_greedy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestFactory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_greedy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mNameError\u001b[0m: name 'res_greedy' is not defined"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "w_test = testFactory.weights\n",
      "\n",
      "print metrics.roc_auc_score(Yts,y_pred_greedy,sample_weight=w_test),\n",
      "print metrics.roc_auc_score(Yts,y_pred_stupid,sample_weight=w_test),\n",
      "print metrics.roc_auc_score(Yts,y_pred_full,sample_weight=w_test)\n",
      "print \"well...\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.934411773641 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.916904744001 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.935834322801\n",
        "well...\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print LogLoss.score(testFactory, y_pred_stupid),\n",
      "print LogLoss.score(testFactory, y_pred_greedy),\n",
      "print LogLoss.score(testFactory, y_pred_full),\n",
      "print \"well...\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "66795.3422741 61551.9719398 43270.885932 well...\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "gbc = GradientBoostingClassifier(n_estimators = 150,learning_rate = 0.25,max_depth = 6)#with lr .25 it has AUC 0.855 and overfits immensely\n",
      "gbc.fit(Xtr,Ytr,sample_weight=Wtr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Wall time: 8min 37s\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "y_pred_sklearn = gbc.predict(Xts)\n",
      "print metrics.roc_auc_score(Yts,y_pred_sklearn,sample_weight=testFactory.weights)\n",
      "print LogLoss.score(testFactory, y_pred_sklearn),\n",
      "\n",
      "# Upper level thresholds extraction"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.856264997764\n",
        "158805.888392\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#hierarchy"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#usability distribution\n",
      "thresholds = mnet.get_thresholds(trees,30,0.001)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.scatter(range(len(thresholds)),thresholds[:,2])\n",
      "print sum(thresholds[:,2] >150)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "96\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEACAYAAAC3adEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztvXt4XMWV6PsrSW5LtuSHLD9kjI1pHsbBGYvMTZzrzJWT\nIAsyM56A50yYDDk6hIkvk5yBgEyM40ngI3J4DM5rJgmBEPAkIY8zHDjKTFDj5GLPhW8SLsGAA+MB\n8zpxDAZjSCCRkW2t+0dVedfu3i21pG61ur1+39efWrv3rl21H2tVrbVqlRERFEVRFMVTU+4KKIqi\nKBMLVQyKoihKDFUMiqIoSgxVDIqiKEoMVQyKoihKDFUMiqIoSowxKwZjzPPGmMeNMTuNMQ+5bc3G\nmG3GmKeMMfcZY2YE+280xjxtjNltjFk91vMriqIoxaUYIwYBVolIm4i80227CtgmIqcBP3X/Y4xZ\nCnwIWAqcA3zNGKOjFkVRlAlEsYSyyfp/DbDVfd8KfNB9/zPgeyJyWESeB/YA70RRFEWZMBRrxPAT\nY8zDxpiPuW1zRWS/+74fmOu+zwf2BsfuBU4oQh0URVGUIlFXhDJWisiLxpjZwDZjzO7wRxERY8xQ\neTc0J4eiKMoEYsyKQURedH9fMcbcjTUN7TfGzBORl4wxrcDLbvdfAycGhy9w22IMo0gURVGUPIhI\ntml/xIzJlGSMmWKMaXLfpwKrgV1AL9DldusC7nHfe4ELjDEpY8xi4FTgoaSyRaRqP1dffXXZ66Bt\n0/Zp+6rvUyzGOmKYC9xtjPFlfVdE7jPGPAz80BhzMfA88BcAIvKkMeaHwJPAEeDjUszWKIqiKGNm\nTIpBRJ4DlidsPwicneeYzwOfH8t5FUVRlNKhcwjKwKpVq8pdhZJRzW0DbV+lU+3tKxZmIlpyjDFq\nYVIURRkhxhik3M5nRVEUpfpQxVBGMpkMq1evZfXqtWQymXJXR1EUBVBTUtnIZDKcd14X/f03ANDQ\nsIG7795KZ2dnmWumKEqlUixTkiqGMrF69Vq2bVtDNN1jKx0dvdx3313lrJaiKBWM+hgURVGUklCM\nXEnKKOjuXscDD3TR32//b2jYQHf31qEPUhRFGQfUlFRGMpkMW7bcAlhFof4FRVHGQrFMSTpiKBOZ\nTIaNGz/HCy+8xKJFC8pdHUVRlGPoiKEMZDIZ1qy5gIGBOuAmAFKpK+nt/baOGhRFGTUalVTB2Iik\nfcAlaFSSoijFQqOSFEVRlJKgPoYy0N29jh07LmBgYP2xbanUlXR3f7uMtVIURbGoKalMZDIZPvGJ\nK3jhhQM0NNSzYcM6Nm3aVO5qKYpSwagpqQrYt+9Vjhy5kTfeuJbNm/9B8yUpijIhUFNSGchkMnz4\nw59weZKs87m/H7ZsuUWjkhRFKTuqGMaZKHne7JzfDhx4tQw1UhRFiaOKYZzZsuUWN1K4FVgf/LIe\nOL08lVIURQlQxTCOZDIZfvGLx4A1wFxgBdDrfu2ipeW5stVNURTFo87nccKbkA4e/CB2dLAY2IpV\nEmtoaPgO3d3rylpHRVEU0HDVccPOdl4MPAfsB35DY+OrnHrqabS0zNIkeoqijBlNoldhHDiwH/g3\nfG4kWM+pp57OI49sL1+lFEVRElDFMG74hHldwbbby1QXRVGU/KiPYZxoaZlV0DZFUZRyoyOGcUJX\nbFMUpVJQ5/M4oiu2KYpSSnQ9BkVRFCXGhEqiZ4ypNcbsNMb8yP3fbIzZZox5yhhznzFmRrDvRmPM\n08aY3caY1cU4v6IoilI8iuV8vgx4EvDd/KuAbSJyGvBT9z/GmKXAh4ClwDnA14wx6gBXFEWZQIxZ\nKBtjFgAfAL4J+CHMGuy0XtzfD7rvfwZ8T0QOi8jzwB7gnWOtg6IoilI8itFb/yJwJTAYbJsrIvvd\n9/3YxEAA84G9wX57gROKUAdFURSlSIxJMRhj/gR4WUR2Eo0WYjgv8lCe5OPSy5zJZFi9ei2rV6/V\nBXoURZlQjHUew/8JrDHGfACoB6YZY74N7DfGzBORl4wxrcDLbv9fAycGxy9w23K45pprjn1ftWoV\nq1atGmNVJw7Rmgw3APDAA13cffdWDV9VFGVEbN++ne3btxe93KKFqxpj2oH1IvKnxpgbgVdF5AZj\nzFXADBG5yjmf78T6FU4AfgKckh2bWs3hqn71toMHP0OUHmMrbW230tJiLW46x0FRlNEwUZPoeWl+\nPfBDY8zFwPPAXwCIyJPGmB9iI5iOAB+vWg2QQDRSWJz1yy4effQxRM4EYMeOC+jt/b4qB0VRyoJO\ncBtHbOrtNcA87GjBmpKM+VtEJgFfcHteQVvbGTzyyAPlqaiiKBXJRB0xKAXRiY3ivYbm5lfo72+k\nv/86wsyre/Z8plyVUxTlOEcnl40j7e1nUVNzOVYpvERDw3PceedXSQ7oGrPSVxRFGRU6YhgnMpkM\nmzf/A4ODHwVupqbmaTZtuhyAQ4fewC736VnPKaecXo5qKoqiqI9hvIj8C1EkUkdHL4Bb8vM2YAkA\nxvySe+/9Z3U+K4oyIiZUEj1lJGSAtcDNbrlPgGXYEcMrwF5OPnmhKgVFUcqGKoZxort7HanUJ4EL\nsamkLuGJJ56ivf0st/0LwGeAHl54Yb/OhlYUpWyoKWkcOeusVezceRHZ5qRnn32WZ575JPEJb7fz\nyCPby1JPRVEqEzUlVSC//e1vEre/9tobOdteeGFvwp6KoiilR6OSxonNmzfzzDNPYX0Ju4AHgado\nb7+CAwf2c/BgPCpp0SKNSlIUpTyoKWmcmDXrFJcfaS+wBZutHBoaNrBp099y7bU3MTBgo5JSqd2a\nEkNRlBGjpqSK5RGsUugCbIbVHTseobf3+3R0zKejY37JlIKm+lYUpRDUlDROXHHFRfzd310KLMz6\nZRc/+9nDbNlS2qyqmupbUZRCUVPSOLJ582Y++9m/Z3BwEnAT1tdwK/AVwJqVSiWs802wu+++u4p+\nLkVRyoOakiqQTZs28f73vx8rnHuBe7BKITIrbdlySzmrqCiKoqak8Wb+/Cbgm8CXgX3jdt7u7nU8\n8EAX/f32/4aGDXR3bx238yuKUjmoKWkc2bx5M3/3dzcCH8OGq+6itjbF0aNRhFIp7f6ZTObYiERX\niVOU6qNYpiRVDONIFLIa2fkbGzfy7ne/G1BhrSjK2NCFeiqQw4cP52xLpaaoA1hRlAmFKoZxIpPJ\n0N//KnBpsPVSrrjiU+WqkqIoSiJqShononDRvcDtwFuk09PYs+eJMtdMUZRqQcNVK5ZNwB6gh5NP\nXlLuyiiKouSgimGc6O5eR0PDBux6z1tJpT7JgQOvliw9haa/UBRltKgpaRzZvHkzX/jC7QwM/J5D\nhwY4cmQLUPww1ez0F6UOg1UUZWKg4aoVRlxY3wxcQhS2up7m5nt4xzv+oCghq5r+QlGOT9THUGFs\n2XKLUwpdwPzglwywlYMHP8O2bWs477wuNf0oilJWNFy1LKzDrv0MdvRwE753399vlchYRg2a/kJR\nlLGgimGcyBbWqdQR3va223nhhVc4eLC45+rs7OTuu7cG6S/Uv6AoSuGoj2EcScpVZFNxb2FwcHzy\nJSmKUr2o87kKiBzSFwIPUlPzNNdeezmbNm0qd9UURalAJoTz2RhTb4z5uTHmUWPMk8aY69z2ZmPM\nNmPMU8aY+4wxM4JjNhpjnjbG7DbGrB5rAyoRP8fgwx/+hHNI3wT8O4ODW9ix45Gilb969Vo2b96s\n8xkURRkRY/IxiMghY8x7ReT3xpg64AFjzHuANcA2EbnRGLMBuAq4yhizFPgQsBQ4AfiJMeY0ERkc\nYzsqhnjYavHXY4iXv4tt227ErxCny3kqilIIY3Y+i8jv3dcUUAu8hlUM7W77VmA7Vjn8GfA9ETkM\nPG+M2QO8E/jZWOtRKcTDVucRRScVJ3ooXv5aohXiihPxpChK9TPmeQzGmBpjzKPAfuB+EXkCmCsi\n+90u+4G57vt8bBY5z17syOG44cCBV4P/OoEumps/R0dHr/bmFUWZEBRjxDAILDfGTAcyxpj3Zv0u\nxpihPMmJv11zzTXHvq9atYpVq1aNtaplJ5PJ8MQTjwHrj21Lpf6JO+/8dtEUQnf3OnbsuICBgZuB\n14GfHPtN5zMoSnWxfft2tm/fXvRyixqVZIz5DNAP/DWwSkReMsa0YkcSS4wxVwGIyPVu/z7gahH5\neVY5VRmVFKWqmAfcAjxJQ8MBamsnYcwkTjllMdddt3FMSiKTybBmzUcYGPh7AOrqLmPZsuW0tMzS\nFeIUpcqZKFFJLT7iyBjTAHQAO4FeokQ9XcA97nsvcIExJmWMWQycCjw0ljpULvuBX9HfP8Cbbx7m\njTeuZefOi1iz5iNjih7asuUWpxS6gC6OHPkyLS2zuO++u1QpKIpSEGM1JbUCW40xNVgl820R+akx\nZifwQ2PMxcDzwF8AiMiTxpgfAk8CR4CPV+XQIA+RmacOOAVY5n6JEuoNDKiDWFGU8jLWcNVdwFkJ\n2w8CZ+c55vPA58dy3kqls7OTt73tD9i58yLs4Kn44aqaJ0lRlLGiuZLGmZaWWe7bOuACYJC4M/pK\nuru/PeryNU+SoihjRVNijDPZE9CMuYX6+nrq6hqK4nxWFOX4RXMlVTBJyfQURVHGiioGRVEUJcaE\nCFdVFEVRqg9VDIqiKEoMVQyKoihKDFUMiqIoSgydxzABKEWUUlhme/tZxxYA0igoRVGGQ6OSykx8\nXkNx1nzOnisBt+IX69E1pRWletFw1Sohyrjqcw5upaOjl/vuu6tIZa7FrptUvPIVRZmYaLiqoiiK\nUhLUx1BmSpH0Ll7mYuDSY79pUj1FUYZDTUkTAHU+K4pSDNTHoIwYzdGkKNWNKgZlRJQi+klRhiPf\nyFVHsaVBFYMyIkoR/VQIOko5fskfNq0h1KWiWIpBnc9KycgepTzwQJcKgOOILVtucfe+C1iFVQQ+\nhNp/h/5+Xc52oqHhqscJ3d3raGjYAGwFtrropHUlPacVDBdilzHtpb//wmOjB+V4YjPweLkroYwA\nHTEcJ5Rjyc8DB/YD/wbc5Las58CB00t6TmXi0N5+Ftu2fRyoBz4KbHC/aAj1REcVw3FEZ2fnOA/X\n67BKoSvYdvuYS1W/RekpxjW2zuWTgUZgGXa0eguwj3R6ASef3OvKV/PiREMVg1IyWlpmFbRtJKjf\novQU9xo3Aiuxo4UbgDXU1FzOV7/6Pb1nExkRmXAfWy2l0unr65OGhrkCdwjcIQ0Nc6Wvr29MZXZ0\nnO/KE/e5Qzo6zi9SjRWR4l3jvr4+SaVmCLQIdAusEGOapaenpwS1VkREnOwcswxW5/M4k8lkWL16\nLatXryWTyZS7OiXF+zU6Onrp6OjVnv1xRmdnJ72936et7XSam++hrW0y9957J5s2bSp31ZThKIZ2\nKfaHKh0xlKIHPZHo6+uTjo7zpaPj/JK1q9qv4URAr3HlQpFGDGVXAomVqlLFMF5mkPEQ0EnnHC9h\nUo72HW+U4hrrfSs9qhgqkPFQDOXq7antXxmK+HPZLTU1s6StrV0VRJEplmJQH8M4Mh6TzOKzTW1k\niU4qU8pN9FzuBb7F4OAWdu68iPPO66p6X1slMibFYIw50RhzvzHmCWPML40xl7rtzcaYbcaYp4wx\n9xljZgTHbDTGPG2M2W2MWT3WBlQS1eyMLcfMaqXS2AV80X204zKhGctwA5gHLHffG4H/BM4AbgQ+\n5bZvAK5335cCjwKTgJOAPUBNQrmlG2tVOeV0HKoNWclHX1+f1NTMElihJscSQpFMSUXNrmqMuQf4\nR/dpF5H9xph5wHYRWWKM2QgMisgNbv8+4BoR+VlWOVLMeh1v6MxgZSJy1lmr2LnzD4HvYCe7QU3N\n5fz4xzrZrVhMuOyqxpiTgDbg58BcEdnvftoPzHXf5wOhEtgLnFCsOiiW8U99oSjDc911G92M6vcA\n64FB5s6dXe5qKQkURTEYYxqBu4DLROQNYyKFJSJijBmq+5/42zXXXHPs+6pVq1i1alUxqqooSpno\n7Oxk06a/5TOfuR6ReuALvPgirFnzEXp7v62dmVGwfft2tm/fXvRyx2xKMsZMAv4FuFdEvuS27QZW\nichLxphW4H5nSroKQESud/v1AVeLyM+zylRTUgWhpiulUOyCUfuASxjvRaOOB4plShprVJIBbgOe\n9ErB0Ut017uAe4LtFxhjUsaYxcCpwENjqYNSXnzCtW3b1rBt2xoNP1SUKmCs8xhWAhcC7zXG7HSf\nc4DrgQ5jzFPA+9z/iMiTwA+BJ4F7gY/r0KCy0XkTlc945u/q7l5HKrUb62Owoc2p1JUa2jzBGJOP\nQUQeIL9yOTvPMZ8HPj+W8yoThwMHXi13FZQxMN5pzH1ivY0bP8cLL3yORYsWcN116l+YaBQ1XLVY\nqI+hMshkMqxZcwEDA35BHkilrlRHYgVhbf5rsFOS7CI6bW21PPLIA2WumTIaJoSPQRk91ZB+e8uW\nWxgY+BI2Lr0XuJm3ve20YZVCNbS9utiFNQWuAS7hscee1PtyvFOMWXLF/lDlM5/LMTu5FLOSR5M4\nT1M6TyyiGcmlT+6os+JLD5pdtXIZ70ykpRLGoyk3anufwPkCK6StbeWY66KMnra29pI+j9FzYldx\nq6mZpau4lYhiKQY1JU0gSmViKVXkUJgUMJ2+kbq6yXz4w59g8+bNwxyppouJxHXXbSxpAkT7/F2I\nNTlewuDgFj772S16zycyxdAuxf5Q5SOGpJ52T09PyUwsw41QxjrM7+npEZh2rO4wLW+PsNimCzVR\nFIdSXkf7/GnyvPEANSVVNj09PdLcnJbm5rT09PSU1Lw0lMmnGGam5uZ0Vt27pa5uTl4hk04vL0pb\n1V9RGSR3BrqluTk9rCJSxT8yVDFUMEkCbSR23tG8LPmOKYZCampaGJTRJ9CSV1j39fVJKjUjtk8q\nNXtUL72uGlc5dHV1CUwXv4JbOMLMp9BV8Y8cVQwVTJJAa2tbWdBLUOyXJUkhtbW1F3y8NSPVBy96\nfpNBX19fMLoYu/NZFUNlkO18huaC7pve35FTLMVQtLTbythoaZnL3Xd/JkhGlzz7NO5Ihv5+u230\nE8qOYNMTeNYDpxd0ZCaT4bOf/SJwMzaD+ueA3+Td186wXey2+PpewwsvvEQmkxlxG7q71/HAA130\n99v/rdN064jKUEpP9jML7y7ouKRZ9TrTfnxQxVAGkgTa/Pnn8OEPfwKAK664qEAhmQFu5he/eGVU\nghWsQoIV2AlqAF20tDxX0LFbttzC4OCp7r9N7rOemprLGRy0W72wjoTDPKyA+BHwU+BLHDwI5503\n8lQMPipqOGWqlI9MJsMvfvEYNgLNszLxGcll9J0WZYwUY9hR7A9Vbkrq6emRxsZWqaubI+n0cmd/\nLTyqJxqW57flF0pk818hsEJSqRkFl2OH+t0CkWmrpmbmMWd66M+ImwV6BGaqmaDKGepZTXpGsome\nr/Pdp1ufkWFAfQyVSVJoZ0PD/Bwh2dyczltG3FY/NsFqFcPsUTmCs23HxjRJOr088WWP+0ZWDOmL\nUKqDeGegT2CFNDenR/F8qfO5UFQxVChJAh1y4/qHUgwixXPMjbUcH+3U1rZS6uqmHxP6dXVTpa2t\nPaYk/L72GuSONPSlry6K8YxquOrIUMVQoSRF5Uya1FiwKclTrN6UnVMw9uF6W9vKwFwwdDiipkiY\nmBRbCOt9Hn9UMVQo1pQ0JWZzraubJV1dXbEJb4WQ9CKP5OW2dZk8YqWURHwkNHxPUXuCE4tSmW16\nenrEmBk5pkq9/6VBFUOFYl/AeTmjhmIkkhvpy22FeXFs/fH5EIWZEFQ4TBxKNWcg/lz0CSyRmprp\nMWWhvoPiUSzFoEn0xpEolv8kRpNIbrgke+VcZvO66zaSSl2JTcS2GLiUfEnZMpkMZ531Hj7wgb/U\ntaKrnBde2Ou+ZYALgAMMDp6BXSJ+/J9TpUCKoV2K/aFKRwzxlNMjSyQ3XL6jyKlbeLK8fGatkfbe\n+vr6pK1tpTQ2tkpT00Jpa2vPG44YtUOjkiYSpTIlpdNLnakyjETTGc2lAp35XMl0AmeO6Ih8M56B\nYM1e31O3hBOH8q3t29Pzaa6//qscOvQpFi2az1e/+l3ALvkIdjLeUJPGkpb33LXrMgBaWmblHB+1\nozehtOKQyWSCSW9D11+xDDVZcCzXc9q02cC5wD3AbOxIeT9w+bF9hpux7s9/4MB+oC7xuVKKTDG0\nS7E/VOmIId4rKyyRmCefDTh3e3LWykJtyCPtOeamVB46iV581DQ+iwdlj17Ut1E4Yx1JRD6GPoGp\nwTPfLTBD0unlw2ZXtedfK6B+ieFAnc+VSSiUCpn9GR6X9IIWWzGM1AmZqxiGX/shVI41NbOkra29\nhGtPdEtNzcxj1y2VmhGb0KcCZmhG65T25kVjGoOOwpkjLiua/RyaXkc+We54oViKQU1J40xnZ2ds\nCLxpU+HH5RvqR3mXdgFf5+DBt7Nt2z527LiA3t7vA3DgwP4C89P4cta674vz7IOrxzp27LiAgYEr\n3JZ9ifuF5ohNm/6WHTt63fHfLbFJ4EEGB7+IN8ENDNwMXILN2XQL/f2L2bjxc2qWKCLxhIn/iL/W\n8PooS3wQ8Dm5Mth7ecOoc2wpBVAM7VLsD1U8YkginD2cPVt4JMc3NrbGzDjQIun00hH10IdbjS3J\nDGNj1RvdyGFBzvFdXV2x0U4qNWNE7RyJ6Sd7ZJW7QMwKKfas62oxTeWbFzP6db2HH70N9xxEi/z4\nezbyUcfxBGpKqg5GmhTPD9Gbm9M5Aj4pKqmubs4oTEP511MY3pyVm/gsXq+hfRD5r0/hginbXJet\nlApdD6AQqiWfTyFRb4UqvqH8SN582ta2smCTXrTIT+hniO7dSNYPqXZUMVQo2S9Z/t5V8mzhoVY/\nS1p0J7662mgUQ+SzyLfKXFwQ5Cqnkc6KHro+I8/lFCpSO7opXmbXallMppjtKMSPVOiKhXGl0CKw\nRLJHxcWYHFotFEsxqI9hHEkKGV2yZEnBx2/ZcgsDA0uwNvIuAAYGCCYHHcGYT2J1K6RSV7Jhw2Vs\n3ryh4MVs4mtF7AJu5eDBr7BtG9TUdOc9xvoZ6ly9ohz6DQ0b+NM/PYetW30YbbIPYiQcOLC/oHDa\n7Ovd37+Bu+4CkY8CG47tV1NzOd3d3xtzvRRLrj8s7kfKZDI89tgv8x7v/VHPPrubZ57ZB5yNXbtj\nAdAI/DGjWT9EGQHF0C7F/lClI4akXlm0pOfwpqTcCKDsMpJ7aCM1BeSfMBe3EYd1TEp9UFc3R9ra\n2t1v3ry0UiJTzshNSSOJKkq63sVcWjSpftVoSio2UaRRrp8nXo8FboQww+0/VYoxIbOaYaKYkoBv\nYWes7Aq2NQPbgKeA+4AZwW8bgaeB3cDqPGWW6LKVl3zD9Z6eHmluTktjY2ve9QxE8puSCh2WF6O+\nbW0rE5VMbu79qI65DuDkkNp8hIrNZoMtrK1DK+LiCMAkU1WlOqJL6UQPy47PbYgr5/g9WyjW2bzA\n/fWBAyvFmizPVDNSFhNJMfwR0JalGG4EPuW+bwCud9+XAo8Ck4CTgD1ATUKZpbpuZSWp95tOL8vb\nC88+1jvt0ullMedzqezcPT09BdUtt23Zo5r8I42REEWoFNbWfL1gr4hHksm2kPKrcY5EMZRFts/B\nmKa8SfTi/qopbrTQItbPoGlUhmPCKAZbF07KUgy7gbnu+zxgt0SjhQ3Bfn3AioTySnLRJgKhgLdC\nZPjwu+GG+aUwA8SjpQrLpT9UzqZ8I42RMJQJYrg6hbOei3WtchVydQmuYl2r5CilZKd0dE7/XnQ5\npbBEbBh0NBI1pvBlaI8XJrpieC34bvz/wD8AfxX89k1gbUJ5pbhmE4rkGZ3JQjT+Yq0UWCBNTSfm\nvFBjmQuRXL/RCbl8I6NwlDOanmj8OozOPzCS1CDD1W+kimEsI5XxnivR19dXNH/MSCPv7KJPzcG5\nm52iWOlGEc0Cs6W1dWHFmu1KRcUoBvf/QcmvGM5PKE+uvvrqY5/777+/+FewzESO5HgP2JjGHHNE\n5LzNH6oqUrweXl9fnzQ1nTim3m+oqOySn6HDcPqoTC7FaF8hiqHQ84zElDTcxMFitbsQBTLcPtH5\nwuez2/0/c9gJj0OXl1/RxNs53V2vaWIXk5okccfz8KsEHg9K4/7774/JyomuGHYD89z31sCUdBVw\nVbBfH/CuhPJKchEnAqHANKY550VJEshtbSudbT3Xdl9f3yx1dXOkoWG2NDTML0joDScUrIM7PmzP\nVkLDtdE7ZO08iuwkewtkNMuJZjt6R6v0hhOy0Whu+PolmaqSrm+SeW24db3j9SlslDNc2woxS0Z1\n7RGYmdN5SY4gGl5h5eZOij9X8RFho+sInenOvUAKzclVLZFio2GiK4YbvS/BKYNs53MKm4TnGcAk\nlFeiy1Zesh/YurqpOU64aHSwUqBVYKbU1s6WhobWBAE7xQlwH+o6tCmjkBfGnn/ont1Q7ct9+Vdk\nlTdXRjNJqZgv+3DKMb5+dXEmUY2HYihkv6H2SR4p+Gig3GMKHX2F1zo3rDlKhhf9tlTsiMFHJM2T\nKDJpeMVQLZMOR8OEUQzA97CzlgaAXwEXYcNVf0JyuOqnXTTSbqAzT5klu3DlJClML51eGntxosVz\npkkUleGHzuFQ2r80oe3W9/CShedwL0wU9TNyJ2pcqGQrMD/68Nvbc8oP0xokCe7xetnzmdHGmnYh\nMiV1O8U4U1pbTyuqCW2siiHeY5+V8H1kiiGp3lG4cW66jHR6mXtOWtx1mi5QL4Wakvy66SNNA1NN\nTBjFUIpPNSqGSOjmj6qJhvFnCiyS3Jw+3dLY2OqS5c3IUgxD24JFhhcckQkl7hMoxIwUdzDmmrwa\nG1uDFzZXMQxnBkiqezq9tChhp+E9KuXqcja9w5QRX1tft8Jt+SMzJfm5F3GFGN6jHklaC2G48+Xe\ns7USdXoW5Fxj++x3C3g/TVcg/JcLzJG4iW+lwCxpbk7L2WefHey7Vkbrz6l0VDFUGENFIfmX3b5k\ni8TaV33N966jAAAgAElEQVQkRlzA+olw0YjC90KHTwxX2IvsndxL3Ms7o6CXKt7bTHaS5/Nf1NVN\nPxZJlW+yXpIZrtgvf3JYZfFs1FHAQbIppRgUqkDS6aXHfFN1dbOcMJ0q+Xrk+TKhDnW+3Gg676+Y\nLUnKN5p8uFLsKCFUIMslClldEXz39z98/gv3EVUbqhgqjOglSRZ80e+tEo0YvAD15ocp7qXwL2+f\n2NmhzRLPOplf4Az1IkejmpH3luOC205i8us/h+fJNactiflZhjp/WPek5IBJNvuRRKfEe7jxa1iM\nKJe4Yogrn5GmIh8L8Qgp70+YlXVfIjPnWNLBRzP1V0jczJhs9oxMefPcbyvFdpQaJeoI3SG5iiUc\ngaiPYayfsiuBxEpVoWKIBGdyTqSot+5HCn604IfxS4Jekf8tPmEo7ogeXW83qccezqvo6emRtraV\n0tjYmiP4CxGew8f+J8+Szi47nzM3jFxKp5eNKCw234iqWI7vXEEZKqFwhFWYkhitssrNdpvtF4qE\n6VjbHj1P4YjZmz3XOoE+U7q6uo4dYwMtvKDvkWjW81DO59B8NLJlc6sJVQwVSBiqmv3iW/vzDNdD\nmhooAf9ihfZf/7Jkr3OwRPKZqkZSx/yx+d4BnhzKOho7eNIIIXuCX5Jwstcrd0GgeC6p0TnRS+n4\n9oor7iDNn2eq0DkUI5kLEj+3n0CWbJcfLoqp8I6A78SslXgIbNwn1tfn14b2z1mYI2mmDHWdvPO5\nuTktXV1dx8U8hmxUMVQZkdN5hRP4/gXyPSdvOulzSmGyROYj/zItkLiZKXmW9HCEM3TjSeuye5dx\ns8NoJmHFF9JJTpMQCZced20WSDq9NGcmcTzUNhS4/lq0SG3t7JzZ18OZSkoRERUX7Pni8/ObBEdT\np+ic2UpgciCs43b5fOcpVDHZUVLYsWh062Ekr6Rn7+E899tSp7T8ftkrFE6ThobWEfk9qh1VDFVG\nFJHRKFGP3NtXmyWK/ffKY0HwwsyRyIy0QIbq1Q9HZO6wCiC+qE2oGOIvdbw3FxcghTpDrcKL6ut7\nrPbaDB1pkhxq60Nlw2saObytwBre9FYsU1J2md7k1dw8V3Jt576HnZyrqpBQ0aFHPj0CC6Subk6g\nVAtXAIUqJjtC8aYg7yeb5p7p3BGdvdfhPBf/vTv4GymvbL9SKe5VJaGKocqI5i944djlXiAf4rdE\noqgRrxhCJ54X1N4WO7qQy9zJXdMC57A3JXllFZYf2n9tT7ehYXZBNv6+vr6EVdW6s86bq3hCoRCP\nqArr74VS9vXw/xcm4IqVkdW3NxwlResNhOtVDL029VCZb0cjzLM7BKnUjFh52aa9JB9P0nWLK5zQ\n+R46n6MybAfBKw+vFMKgi6EnHkbPwfEXkSSiiqEqsWYb/+J401G2acGHe/qXZ4XYoXco6PI7E4cj\nivaJzET19c3HeretrSeJVVBzs8rP7tkVbuO3L/O8rH2zQ3Wzf09SDHETWkODNR3lOi7zKYZk0008\ncMD23kMbdtIaDIWFcWYLS18H7ytKzrxrOxFTJQopnlnQaGKoOQzp9FIxZvqxNhrTnKgAhwuiyCbZ\n0R2OWvLN/A9HkNbEmE4vC0YfceXliSfgu0Og+bhas0EVQ5VhXzhvWw0XrM8WXD6xmI/jniHxRdJD\n5TEyB7F1/GXnxvF2YV/+mRKl7Ih6rNHkvTAjZ6G9Sm8yC2Posxd9z29K8mYZ24P2gq3Jxed784Uv\n30fC1Et8Dkh+QRf1QpMiwOLx9F7Y5jNn5Pa2sycn+jpk39PIl2OVgu8UrBCYJun0smPXs1CHcVRP\nPyLz192bfWYM4e+JK9J8CxTFR6DZs/fjc1jio5rcNlhf0NC5spIWckqnl4/2taw4VDFUEdYOG0Zi\nhA7CpZJsfz5f4uallRL2sIxpkoaG2dLUtFDS6WXS1tbueoXJC6SISNBb80rJD/fD82YL8GZpajox\nEDIrJHKch8ItV0B6QWJf5lAoLQjKiMwoYdRJqBQiIRwqD1/nLomiW1YGAj17fkj+xH65E9NCYZ7P\nTj5Ujz1UAKGSyY7Fz+4k3CFRTH/cpFJTMz32PGVHliU51yMh7EeqSaO+fAvpxAX2UIowNFHV1U2V\n1taTpK5ujjQ1LcwZlUR1zw1jDp/dfD6z+LXvc+ecc9z4GVQxVDihYLQC2QumcFZoWyA0VkhuuJ4/\nZqlYB3Sj6ynPkXR6eVao5/Czo6OUCF5BZI8C2iVpNnYqNf3YLNr6ep8VM384YtS7ty955F/wZqDs\niX3N0tAwLzHyJLf3nS1Ym4Oys0OAJfie61tpajpROjrOd6GxSU74sGcbKWtrvsq9zsP1tpPbsjyr\n/BbJDUm27Qyjq3yZ0YJQuUI7sv/PkbgiLiTRXrb5J1dZJJnahhpNhfc2/zMSnqM9572KRihjm89T\nqahiqGCSY/nDtMJ+Zmp26GmLxHu8i7KEaK75KD7BaGibv0214csKI6F8zz/0Zfg6TZZ4jzfqHWab\nQVpbF7qXPdtR7UdK/jwnBsdGQi00hxUW6jk961wLJa7wQnNYaIIIbd/+uq6VcESWa7rLjpzJN4kx\nLtAbG1tj60XHndI+JUSoZOdK3ETn6xqeO4piSvK9+BFeNOejxd1vX27yqCCfTyV+jtzZ7EOPOPKv\n/93T03Msx1ZNTUtOnfLNdLd+iNxcTMeDE1oVQwWT9HJYm7cXPNmzRMNIm7US2cRDM09yHp5oMlO2\nnTx3WczIlOSdwWcGx6yVKOzTKyCf4dXv45VbaLdPir7xPV7vhwjNT2Ev3yu1UEC1Z/VQk4S47/XP\nlHjo40qJfDLTss7rBUnoZzlf4krKzxVZIMZMyvK7ZAvUXEd2rikpni3UmGZpbT1JmpoWHpukZZV1\neC19SHP2tUq+v3EzXbgsZjiS8o5eP2KNmwBTqRnOXxPVM3vGe3xiYThrP5p3kutfSZ7M50cM8fTt\nhaVqj+qiimEsn7IrgcRKHXeK4Q435J8p8fjusyXqgfuXOMyRH/bMz5fCUmUkx8WLhJOR/DFhXdol\nCp31ZZ8o8ZHOiYEQmiLJ5pcVEhdUvi1hm7wQCF/uPlfv6YFQC0N1bZvOPvvsY36Iujpvnw+FvFdE\ndwj4NM9eUbRI3G8TCt7QRLFCoFFSqZnBYkRJPe3c3rA1S02SaBGa8H6F54vmckQTwkJl6Hv5+ToG\n9vxWuCbNGcguz6e1XiCRkrBmvFTKdy7C5yopv5HfZ5YkTaKLop6Sotbs/W1sbHXPYHZknQ+8yB+R\nFH+3kuta7ahiqGDyxZlb+6jvRXozSCjIvLnDh+T5XnxL8D2MgfeO1LXOXJE7wzc7Sqmnp0dqa33v\nsEsiJ/JMV5duiXrRrRJfM8IL2tAn4V/sdkkeDXifQrNEDvRuiSJvkkJgs52yobAM8+X4XP4+tHNq\ncI3Cc/kR0WTx6wlH1ztUYv77EomblXzUVpJTObrHVsg3STSS8dfN9/ZD4WoVUU3NLDcBzu8bxv9n\nj+iy7fChUg+FbJdEI79wpOYFsjezNbr/syPk4lFScWdxtm/HC/Xs/8PRbCjEh1Z0+cxOnnx+nONB\nKYioYqh4wpmvPmqoocHbe31vywubyRJPgXG+RNFKvhc/TeI+B99Tti+2H8pnT1SKRgi2F1xT0yRx\n08VSiXI4eTOMV0ZpifwMfmQTCqjQzOPDOqdIfBTkBYlv7xyJFnz3ZpPQzBMqnWyfTNLIyiuAUJif\nLfGJb17gz5RISXlTnReYZwZtmBucx9uzp4lVRE1uxb35EgUGTBfw13We5PqHWiWuBP2IKzRVrcza\nJhKNYrzpJ24CivJQ9UhcIXqF5e9p2Dv3yj30L/n7HSqi0FwXKixfTpj91gt5r3BaBeZJKuWVU5Kf\nKPTdRCOo4QS8znxWxVDRxPPW+JfZh2lOk7jA8jbltRLF38+Q3J7z8uBvKKDvEJiSE50S2Z/D3pp/\n+WcFf8MQ0rDnOkkiYdsjfinSqF5eWHpFFZpOvFDyvWxvSponcRv1VImHr/rrc6bk+gfCGPhuVzd/\nbdLBfumgzOzMnX4kFo4ufJ29gPTlLJO44zw0nfjwYz9i8W30vhh/b84OyvD3cpHkClyfij1UDP7+\nhQkW49FO0foXPlVK2B5/b0O/jy8rTNESprzOjmzzx3tTmFee4fVYIZFiCwMk/LHZzvRwjkijpFJz\nE+ct5JuTo7mSVDFULNGkqVnBS9EuUQIx/7Isdy9S+HJm+xjOzCordFh6c1JumGmu7fl8iYTeaUH5\nXgCHPUtvzgrDbO8IztMuuVFToVCy0SsNDS3S2NgqNTVeIHsTmu+xZ488zpfcaKgweit7pvNpwd/Q\nd+HTmC/Kaoc/5xyJRmX+Ovrr63vqoZLIdqo2u9/D0dEyiQStLzecl7BIrBLxysrXx/fyw/Wyu4Ny\nsu/1SqmpmS41NdODsn0dwmCEUKh7pe/vY7v7PfQX+ESP3RLdh0USdQ6iZ8uOhJdKQ8NsiY8o840O\nws5JvFOTHSQhMvTIoJjpSyoNVQwVTjRpKnxRzpa4z2Cqe6FmSW6P1ysC30MLzT9+JTg/Q9qHkWY7\n8rJzHvle8RSJm3NmSW5Ej3c6hyYaX4bvHfseadgbTFolrFui0YcX+tkjAS/EvNI7M6vcaUF5SyQa\nXXjh6Wc/++vrzTJ+5OGjwnz7vFD1I7Q7JErL0SWRsMvOftsjkdIKHfheefpz+fbOkqgzME1sj92P\n1mZK1Cmol0i4hv6AEyXeO/emRb+/r3N7UPcwImuaRIquXiIfl1c8oYnQlxsqZK/Ms3099WKMv+6h\n2S7boRw9CzU1s9xaDMPPmM83uzspHfvxpByKpRhqUMpCd/c6amqeBlYCG4A/Bx4G5gJdwAPAPKAR\nGAQagqOnAFuBVcBLwFeAhcAyt/0ocMDtewD4kCtjvft0AUuB/xt4C/ikO+4lamoGgcnA14ArgG8B\nrcAKoB/4f4CPueNWAr+CnMeoHvhP4EjW9k3AYuAmV4fnXFnfde1OueMmu/oCfBx4CDgBuBWYBZwG\nvO5+zwCPANOA29y1+A93/E+Bk1x9jNt22NXrXNeep4E+d+46t/9bgLjjWlyZe4E3gUuA/+HK+x2w\n39XxZff374EmV4YBLgIeB77uzrfNnasBe58Ou3NsdfX6nTvuVlcHsM9Ao/v9SeB2d+wJrk6/dnXs\nAh4FpmOfkYtdPXYBj2Hv55uunF+667PM/X4TsBx4O9DuzlELvN9dz58Df+Pq/RV377qwz0Mr9rl6\nD/B54PdACpGl2OeyFvus7Hb1X49/3urqDtPWdjsdHc9x7bWX89ZbB4FXGQ0HDuxn69YfBdeiC/gK\nX/jC7aMq73hGFUOZ6Ozs5NprL6em5lvAhcAOYAkwG3jQbXvD7T0VeJZICL0ADGAFQh32xX4e+8K9\nhFUoM7HC/ybsS/wVrAL4BlYYgRUKG7Ev+3oaGq7ixz/+nzQ1NbkyH3FlvIEVut/ACg6AQ9iXex5W\nqHul8xfut8nuPDuBy9y+67GKxLMf+Ees8AIrCAfdOWcAr2GF84eA+10bTsMKmdeB/+6u02Ks4AyZ\n5q7nEfdZDJwMtGEF5kvu2k12+w9ihfJt7h5MwgrYGe5abHHnmOHKaQHegRV8rcDNrm6TXHsmEb1e\nKXfd/sDVpc4dNxd7n57FCvqvufJ/j1UOjW67uGMWECmPAXdNBrECF6yS3O+u/2nY5+ijWCF/MfY+\n3gs0u+sK8AyRIJ2MFeK97jxnAH+KVca/c+WdEFzjf3X1rANOxwr9Vlf+x7DP5JvAHOz9vxiYDxyi\npqabdHoLy5Ytp6VlFt3d67jrrm0MDs52+21wx2wFLqO7ex0h3d3raGjw+6ynpqab3bufxSpEZayo\nYigjmzZt4tpru2luvgf7gq8EnsD25rZiBfabWGHxN1hBMQv7Iv8Q+xJ7of0l4DvYl/p1IoEHUQ/s\nEeBM7Au/EztiuAm4DriJo0eP8vDDD9PYCLbHugb7gr8SlNWBHUW8DduzPAj8MVaQbCVSRilX5xRW\nuF2PVQKHiXqM/+HaWOvOcRirBHHHNAFfwApPP4JY59p7xB3X5f5/E9u7vdyVnXLX8xWs4DoC7HPX\nZqu7JgYrxGuxI4UmrPD1vf1XgD1YoX/YHfOWK8OPhmZjhSZYReIF/2TXlpuJev7PYAXnTFf2m66d\nrdhXcRdW2R8Njql1+/W765zCCt7D2Ht/GKskLgX+zO0vru3/iVX+C7FC3D8Tv8Xeu34ipQy2A/Go\nuw5fAf7ElTvHXY/dWIW63v3/EvBe7KhrJ1ahHXD1/bo7z5tEz8eD2GdZuPbay9m372V27vxDtm3b\nx7nn/hd27tzl6uFHvr3AzTQ2TqGzs/NYLTOZDFu23MKSJafQ2noN8E0GB7fQ338EeJers++IfJKZ\nM5vIZDIoI6AY9qhifzgOfAwi2TNhfQRLaOOdIdFkKG/PD30C50s8Ht7bbcPFepJmKmevqRA5g208\nfnb8uHc4hpPSvO8htFN7W/JaseGZ2U7gMOzU+yzOFOsQ9Xbz0BcwPTiPP7+/Bn5dbO+MDZ2yYQTO\nWoFaifwX3v680J23WSJfyDyJbOnhvWiWyLcxTayfZFLWftMkCiueLlG47Ez3+ySJbPZL3PepEvkq\nVgbHT3J1TgXbfF38xMF5EndwnyiRQ9yH3frj6oP77R3NvpzQP+Gd6aFvx4fcznDt8nUNAyHODM7r\nQ3fD9UJ89FmUzjs3Y6339UySuI9girS2nhYLsc5dy8I/U97/sVbic1oKX6iq0kF9DJXPli230N9/\nA7an9jXsaOBrwP+F7V1djO11vh/b+6vD2qyvxPaIfA/YD73/HFiLNSVMw/b2pxCZkf4T27t9O3bk\ncBq2l7oWa8d/GZEvYYf7nv+Gta8vw5pC2t15v47tNf7anedpbM/3SayJo9mdb787x4GgzE7Xlloi\nUw/YXvPfYM0c3hdwuyv3ebftZVe/191nP3aEMogdPdyL7Ul/DbgT23ue4a7DY+6cvj6+pz/o6v0m\n8BNX91Oxo4g3XD0G3PWaAizCjt7Odf8vxPbyJ7n7dYKr2/922+rc31p3rpexvfKUu08XY3vqU7Cj\njumunKlY09cct197cMzrRKa3+cH/h9226djRTKtrRy12pDIA/JvbPtX9ZohGNjOIet37sPd9CXaE\nWIN9Fne5OgwSPYPGfXDt9fyhO/YH1NY+zb333smmTZvcbxngBuxI91fYZ+l07Kh0I9YEOYkXX/w0\n27at4bzzuti48Tr3znRh35slrqxbXN0/hh3JCKGvYWDg79m48TqUwlDFUAYymQyrV6/lF794zG3x\nph7vYF6HFbT/ir1Ffwp0Y18csC//zdgX8hD25T0H6whchhWUs7HmoEPumB9ghdFkrBnj11gB9o9Y\nofEuIvPFOqzyeQ9wD1YYXIo1/dyLFS417u9T7pz12Bezw5XRCrwPa664DStEXnHlrMcKl6PAi+7v\nbVgh0eH2/QZWOE921+KnWD/BRViB8BrWdNHsytrn2vtr106wCugud11nYQXhR7FKo9aVd9Rdx7dc\nXb1t/3msL6fe1cc7e19z9TniztXo7oe/tvPdPrhj3iIyLZ3hrtshrFI66sp53l3Lw0SmnTpXl72u\nvNexTnLjznWK20fcPofcPjVEJsbJwG/ctTFYf9Bh93kNq+BuA74M/DtWCT2LfY46sGa0S7FK85eu\njIddXd9y5ddglaxX1L9xddqH9YddiBXWPQwORsEI7e1nuXrf6MqcgX2WGrHKatBdry/jhXt//w3s\n2fMsUWfmMaLgjaewfh9cvWvd94zb92aefvoplMIwdvQxsTDGyESsVzHIZDKcd14X/f0XYgX//8a+\n4Clsj3AbtqdzK/aFfF+w7UdYAfkl7MsC9iV61R1/mtu2EvvCDxD13urc77XY0YEXIJOxwvJb7u93\nsC/z191vk7Ev7XPYHq13PjZiI3T2Yv0HR7ACYTJWqNzr9jfBeX6D7R3fA3wQ28sTV7dZwGewI4RX\nscrjVqzPpRFr+9/r/uLqcR+w2l2TSa6Ml115h7AC6UGs/bsBK+Svx/ZEa4lGRvuwvenfuWt3b9Z1\nq3V/+922GtfeUIgPuHMsw943P2p43R1vXNtvc39vd3U+xe1vXB1edmV5f0At9t7Odr81uOs4DyuQ\nD7ly/PG/wSqco66+k93vR129Z2FHWbhyZ7p78Rw2Eu5Ud73ejh/1GDMZkSPuXKGT//eu7TWuvc8F\n16LRbfNRcABbaWu7FYDHH9/N0aNLXNtPxyrHlVhBnsL6lnqxfq7o+Pr6Kzh06Aj2fdiFfU4XYu/h\nEXfs+4nuYQrbUQJjLuPee38Q81dUG8YYRMQMv+fQ6IhhnLHmowuxAvgqbITLV9z/AkyjtvZK6uqe\nxvaGvanmVqy5YVJQ2masMKvFCv0T3D5e+Ex2ZZ+MFYIrsb3+JiIzw2Si6BLv9LvH/VaLFdJ7iUwb\nB4jMQj5yqRE7gjnDne+fgU+7fd7E9l7fcOf1Jqll2J7eJKyw/6D734e5/nf3vRbbw/WRSE+5Ml9y\n23+CNZscdr9PwQqwDuyoA+zI4HfuuPVEwmyPaxuuHofc9f4bIoFa58o96O5Prdsu7lwzXFuaiMJJ\np7lyjwTlDmCVwQKssrrIbfsY0UhxtrvGf4JVOjXuM9tdY8GaC4+49ne5+3bUHf8bdy1OcOdtIHpe\nUu64F10bjrp67SUKNIAoOupP3DnOdX6/WqwAF/eZStRxqMM+EzPd/6cTjbx8734tcCs7d+5k585d\nHD36Flbp1xI5qXdgR3medVgT6LuBd5NKfZJJkxrdNesFfubadRU26KHVXd9t7vw1RKHRXYh8mS1b\nbkEZHlUMZeFBrNmki6iX780ePbzvfX/Ee9/7Hqyw9MPfPdge9X/FDu//HDsMvwk4ESsMtmF7oLOw\nwl6wL+azrvyvE0W8HMIKuzS2B3kGNkrpr7ECxguZWVgBOB9rbnrTfR4nEii+d31yVjvrqalJYYXc\nb7BK5lLsiOVS7Evc6uq31dX9TSJ/whtEiuVWV85rWIXxBNH8hCZXPx/m2RD8vtKVcSlW0fpInna3\n3/td3V507d2NFfSnYQXpHGxY6qlEwt8LysnufL9127wgbsIKxbeIBOjfEPlNfLRQN5Hg+527pq9j\nld03sFFGb7rr86hr3+3unoB9jt7m6nIIO0J4DSuY/Qih1tXjDff97dhnZcCVMRUraD/rrsNuonkN\nF2NHZQNY086RoA0HiIsP7yvyymYeduThn5HF7p68HSvEfRumuGs/ydXxX1y5lxHN5bgEuITBwVoa\nG+vctXnI1fNLWJ/WTlenTtdOr6yV0VAWU5Ix5hzsHa0FvikiN2T9XtWmpA984K8YHPxv2KH3bmwv\n9csApFJX0tv7bR5++GE++9ktDA6+D2vz/ajbH6wgfxL4IvYFvAL7cn0RG2//DFYYLcUKFN+7rSOy\nqU/Cvuw1RLZubzYZJBqGp7C2Wx/uCZGj9Uvu/BcRCdtt2N66N39dj31hDVap/RNWGa1033/n6jDD\nffftlaBug1ihvh8r7FNYgf2iO68Q9Yhrg+O8aWwmVljVu/p2Ane4a/I5t+3DWGXwoqtHF5E57XTX\n7r1EE9C8w/c1opHFgDuHN6Usctc/FdyrW7BC7SDWBHIAOEp9/WEOHfLzH+rdNfVmvR9gFcTF2JHZ\nZPf7HdjggG8RV1KTXR0mYZWAn9vSjx194Mp73dVzn6v/F7BC9i5X5/lY89XJWH9LP9bZ+5S7zt50\n5/0m3pSzDCuo64gcwKuIh8b6kdpvs7b7Ue6PsArS+xgAtlJXdxlHjhzGKsmZWOH/IlYpp/CT62zd\nn3d1WAqAMbu499671JRUAOM+YjDG1GI9nudg79hfGmPOGO96lIvOzk4+8pE/wfaGDFaIH8G+8Dcz\nODjAww8/zLXXftkphZ9jX/Kt2J6XdwBCNEzfh32hdhH5ApqxL7O3+3dhe4RHsIKuHttDf7vb3ysK\niOzIb2B7+U9jfSG12N5lv9v3R8AFWKE6gDUFAGwnEgi/xyoMH8f+X7Ev7P/ACoRW7OPwTqwJZhvR\nY3mR22fA1aMB+6L/nmhSmDc1+dnhR129jxJFvdRjo7Bucscvw862bsKOJF4imqH8BlHES5u7Lo8T\nRS3NdWV3unosd/eky12Xw9he/BvuWp3g6ugnHy4mmrV9wB03l0OHUtTVTcOacc7AjgxucHX+FVH0\nzRSsAluGnbPxLawyfdNdq3PctZji/t+HHRXsc215ksjJO4Nosl3KlX+H27/GXWMvtBdhR3gnEEVq\n/TH2mep3+/+xuxYfA/4PvEC29+FxbGdgp/v8lkipT8Eqej9/Yh7RfIo4R474+z3D1c0rJj9/42Ts\n87KPyCRoRxwitTnlKXkoRszrSD7YcXNf8P9VwFVZ+xQlpneiEsVwZ+cqsjlf7KIn2THePla7yR3n\ns3b6fEb+exg/PlNsjH5DsL+fO+Azdvp8+z4mPkxidqLYmPswX5BPEDdHcnMk+fkG4fwIn856SvCZ\n5MqcGux7vkTzJMKkfXNcm/ycg0USzZfwcyF8ffy8AB9P7+sXrmkRLl8aX7ioq6tL0umlwXHROgpt\nbSulvr45aIPPqxQujxnO9Qgzt/p5A37OSXa67+yFa/okd22FMMFfmHTO5hhqbT1JojkRPs/WpOC+\n10uU+XZpVjv8/AifA2m6+/hjw5X7fO6nOcH+fj5HeE3CXExhynJ/D30uJ3///HwS/9z7eTvxdbjj\n2YbDj//N58lKWpyo+ldxo4LnMZxAPC/CXuLz7I8THsT2ZE/L+aW//y2S/RC3EKVpaMP27Hzqgwbs\n8HmG2/cRbE9KsL3DmW6fQWyPvR/bK34S2/P1owWwo5S5RA7bFqIe5S2u3EHiPTo/N+FB7GzYS4Fr\nsL0/g+0JN2JHMnOxvcTF2J7ievfdOwv/2f3+lDvvDLffFGzIq7hzfsz9brA9xeVuH98z9Dl8fE95\nPRufL68AAApBSURBVNFs6XvcuW4C/p3BwS3s2/cGe/Y8QV/fD+jo6KWjo5e7797Kpk2beOSRB+jv\nf5W+vv9JW1sbjY1TaGr6/0inTySdbnXX8EHX3t9jzYOtwC8x5qfYOQ8HsOY3Hw31IHYk4B2k1xCN\nLN5HNIN3Kw0N3yGdXhRc663AzTQ338OPf/xd9u17jr6+/0Vb29tobn6UdPpk0uklNDY209AwhYaG\nJlKpQeCbwKeIZqXPwPb+v+a2f5tozsVUbG+7ztU5RfScfAQ7cvqBu6eDpNML3blPJJ3+HVFerZfd\neRZin9ejRCMtcf8PYM1Rt2Of+2vcdRjAj6ZtnRpd/Q4TzZvAbWvEmpWmuuN2o4yOuuF3KToy/C7V\nTXf3On76079icLCOKA7bcxmLFi3kmWfCmOt1WFvzKUSCH6ywXIkd/jdizT1gfQ6nYRXBK1gF1IR9\nYXwEzOlYG+5fY4XFb7CPw+NE+Ym+gRUEje7Y9a4OpxOFka4P6vM7rDC/BKu4fESUT6nhk8tB9JL7\n0NoHs67SbVjn+++w9vjsPszj7twtWEX3OJEJbR427n4B1rzxM2z/o4VovsNS8tHZ2ZnXDp3vN5+m\nAebT3n4hO3Y8Asynu/tLgI1G+8UvpnPwINj7eYFrU9gx6AS6aG7+HO94xx/Q3v4pduzoBaC7eyuA\nC3W2ezc0PMedd249Vp+h6p1bTzhw4A/YudPPswCb5PAR7D180W1bBnwf2yHYhzGPM2nSbgYG9mDv\n84MY8xSf+9zVwcQ1y1lnrWLnzmVYx/0uogma33J7zMV2TrwZqJ5IaXa6836SurpnWbbsDODt7Nz5\nh9jnchZWcXjlMgV7v1/BKp1/wT5rlx2rT11dN93d3x3y+iiOYgw7RvLBpukMTUkbgQ1Z+8jVV199\n7HP//fcXd7w1Aejp6ZF4CuMVAjOkq6tL+vr6pK7Om33sMLqubrqk08vcGr5hTv/shWX88Nunz/Yp\nFnx6hDD1dLjwzlKxaRgmSZSWYK3EUzL48meITSnhzQ/WNGJMg9TUhKuMeTPDlITystN/+BXkwhXI\nmiSdXib19c3H1hdIpZqlqWmhpNPLJJ1eJo2NrRIt5uNTiU+XyFwSpXX2i9h3dXW54+Imo1KnTMhN\n59CQVcfhUzcUcxEau4KfX8inWeL3zKcGj6ew9s+nX30waQGd3Pb6lOLevOdNaz4tt09TPinnetTV\nzYotQxstbuVNkrUCNe4TLgTkzViNYswsSaeXV2VKjPvvvz8mK6nU9Riw3YZnsDOzUlgv0xlZ+xT9\nAk5E+vr6JJ1eKnV1c6SpaWEsb3y+l89vb2xslYaG2dLQMDsmKMP9s/dNpaYnCtjsdaBFosVOGhtb\npbX15GPCubZ2trS2nixtbe3HFmKpq5tz7MXLrndon6+ttXWoq2t0QrHeKYOW2PEjFXxJS5Z2dJwv\nbW0rc67JUMeNB0l1LUTIlrI+/hlpalqYc8/8Otg1NS3S1dU1qvL9vWhra4/99Yo9fIZbW0869pwl\nCfPse1tf3yzGeCXh81HlX/Wt2imWYihXuOq5ROGqt4nIdVm/SznqpSiKUskUK1xVU2IoiqJUCRU7\nj0FRFEWZ2KhiUBRFUWKoYlAURVFiqGJQFEVRYqhiUBRFUWKoYlAURVFiqGJQFEVRYqhiUBRFUWKo\nYlAURVFiqGJQFEVRYqhiUBRFUWKoYlAURVFiqGJQFEVRYqhiUBRFUWKoYlAURVFiqGJQFEVRYqhi\nUBRFUWKoYlAURVFiqGJQFEVRYqhiUBRFUWKoYlAURVFiqGJQFEVRYqhiUBRFUWKoYlAURVFiqGJQ\nFEVRYqhiUBRFUWKoYlAURVFiqGJQFEVRYoxaMRhj/osx5gljzFFjzFlZv200xjxtjNltjFkdbH+H\nMWaX++3LY6m4oiiKUhrGMmLYBZwH/Fu40RizFPgQsBQ4B/iaMca4n78OXCwipwKnGmPOGcP5K5bt\n27eXuwolo5rbBtq+Sqfa21csRq0YRGS3iDyV8NOfAd8TkcMi8jywB3iXMaYVaBKRh9x+/wR8cLTn\nr2Sq+eGs5raBtq/Sqfb2FYtS+BjmA3uD//cCJyRs/7XbriiKokwg6ob60RizDZiX8NOnReRHpamS\noiiKUk6MiIytAGPuB7pF5BH3/1UAInK9+78PuBp4AbhfRM5w2/8SaBeRSxLKHFulFEVRjlNExAy/\n19AMOWIYAWFFeoE7jTFfwJqKTgUeEhExxvzWGPMu4CHgI8BXkgorRsMURVGU0TGWcNXzjDG/AlYA\n/2qMuRdARJ4Efgg8CdwLfFyiYcnHgW8CTwN7RKRvLJVXFEVRis+YTUmKoihKdVHWmc/GmGuMMXuN\nMTvd59zgt6qbJGeMOce152ljzIZy12e0GGOeN8Y87u7ZQ25bszFmmzHmKWPMfcaYGcH+ifdyImCM\n+ZYxZr8xZlewbcRtmajPZZ72Vc17Z4w50Rhzv5ts+0tjzKVue1XcwyHaV9p7KCJl+2Cd0lckbF8K\nPApMAk7CzoXwo5uHgHe67z8GzilnG0bQ1lrXjpNcux4Fzih3vUbZlueA5qxtNwKfct83ANcPcS9r\nyt2GoN5/BLQBu0bZlgn9XOZpX9W8d9ioyeXueyPwn8AZ1XIPh2hfSe/hRMiVlORorsZJcu/E+lWe\nF5HDwPex7axUsu/bGmCr+76V6L4k3ct3jksNC0BE/l/gtazNI2nLhH4u87QPquS9E5GXRORR9/1N\n4D+wQS9VcQ+HaB+U8B5OBMXwt8aYx4wxtwXDvWqcJHcC8Kvgf9+mSkSAnxhjHjbGfMxtmysi+933\n/cBc9z3fvZzIjLQtlfhcVt17Z4w5CTs6+jlVeA+D9v3MbSrZPSy5YnB2vl0JnzXY3EmLgeXAi8CW\nUtenjFSTl3+liLQB5wKfMMb8Ufij2LHqUO2tmGtRQFsqkap774wxjcBdwGUi8kb4WzXcQ9e+f8a2\n701KfA+LNY8hLyLSUch+xphvAn429a+BE4OfF2C13a/d93D7r4tQzfEgu00nEtfgFYOIvOj+vmKM\nuRtrGtpvjJknIi+5YevLbvekeznR79lI2lJxz6WI+PZUxXtnjJmEVQrfFpF73OaquYdB+77j21fq\ne1juqKTW4N/zsBlbwU6Su8AYkzLGLCaaJPcS8FtjzLuMMQY7Se4eKoOHsRllTzLGpLAZaHvLXKcR\nY4yZYoxpct+nAqux960X6HK7dRHdl8R7Ob61HjEjakulPZfV9N65+twGPCkiXwp+qop7mK99Jb+H\nZfa4/xPwOPCYq+Tc4LdPYx0nu4HOYPs73EXYA3ylnPUfRXvPxUYV7AE2lrs+o2zDYmzUw6PAL307\ngGbgJ8BTwH3AjOHu5UT4AN8D9gEDWB/QRaNpy0R9LhPa99Fqeu+A9wCD7nnc6T7nVMs9zNO+c0t9\nD3WCm6IoihJjIkQlKYqiKBMIVQyKoihKDFUMiqIoSgxVDIqiKEoMVQyKoihKDFUMiqIoSgxVDIqi\nKEoMVQyKoihKjP8fJ1hkB2V48tkAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x2cb94978>"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Criteria selection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import hierarchy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get them...\n",
      "thresholds_active = thresholds[thresholds[:,2]>100] #at least 100 times used in the original ensemble\n",
      "print len(thresholds_active)\n",
      "criteria = hierarchy.select_criteria(trainFactory,thresholds_active,4,True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "190\n",
        "s:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [81387L, 46113L]\n",
        "w: [0.4995172311764362, 0.50048276882352416]\n",
        "s:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [35853L, 45534L, 28287L, 17826L]\n",
        "w: [0.26914160839995621, 0.23037562277645596, 0.27439612166068927, 0.22608664716287472]\n",
        "s:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [6226L, 11600L, 18312L, 9975L, 18579L, 17274L, 28399L, 17135L]\n",
        "w: [0.10092029004556231, 0.12516635711728766, 0.16975948409694844, 0.10463663756370174, 0.12697836451232206, 0.14216324388758639, 0.13573214315325532, 0.094643479623169297]\n",
        "s:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [6743L, 4857L, 5235L, 4740L, 7762L, 10550L, 2457L, 3769L, 14352L, 4227L, 4995L, 12279L, 3303L, 13832L, 21436L, 6963L]\n",
        "w: [0.076709325032408099, 0.048457032084882036, 0.060456537835231458, 0.044180099728481512, 0.066781816430453847, 0.1029776676664932, 0.036453532684558393, 0.064466757361011193, 0.096045454684958106, 0.030932909827366763, 0.037357215324124261, 0.10480602856346442, 0.018859704487969042, 0.075783775135201667, 0.10305246577535299, 0.032679677377911803]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "loss_functions.py:162: RuntimeWarning: divide by zero encountered in log\n",
        "  logs = np.array(map(np.log,distribution))\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "criteria"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "[array([  21.        ,  147.61599731,  136.        ]),\n",
        " array([   2.        ,   78.67050171,  131.        ]),\n",
        " array([   1.        ,   44.68050003,  153.        ]),\n",
        " array([   8.        ,    4.71249962,  158.        ])]"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "split = hierarchy.split_upper(trainFactory,criteria,equalizeWeights=False,split_weights=1.,split_inclusion=.7) \n",
      "#\u043f\u0440\u0438 \u043a\u0430\u0436\u0434\u043e\u043c \u0440\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u0438\u0438 \u0432 \u043f\u043e\u0434\u0432\u044b\u0431\u043e\u0440\u043a\u0443  \u043f\u043e\u043f\u0430\u0434\u0430\u0435\u0442 split_inclusion \u043f\u0440\u0438\u043c\u0435\u0440\u043e\u0432 \u0438\u0437 \u0434\u0440\u0443\u0433\u043e\u0439 \u043f\u043e\u043b\u043e\u0432\u0438\u043d\u044b \u0432\u044b\u0431\u043e\u0440\u043a\u0438 \u0441 \u0432\u0435\u0441\u043e\u043c split_weights\n",
      "print [split[i].events.shape[0] for i in split]\n",
      "print [sum(split[i].weights) for i in split]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[59942L, 64599L, 61878L, 67270L, 68279L, 63296L, 63022L, 58156L, 72023L, 64238L, 63801L, 71745L, 67270L, 75607L, 76190L, 67555L]\n",
        "[0.51827029586357942, 0.53280892370635458, 0.50959784009922371, 0.52841259718309053, 0.5373340761308365, 0.5214192753093706, 0.52388530015908208, 0.50723664269740409, 0.54244790828137002, 0.50347235224577436, 0.50011143296858729, 0.54097720934379312, 0.50358989589473246, 0.5398648368553185, 0.53969479097038353, 0.49730402184937267]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Hierarchical stuff"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%time\n",
      "trees_splitted = hierarchy.train_splitted_boosts(trees, trainFactory,criteria,\n",
      "                                                 loss = LogLoss,\n",
      "                                                 learning_rate = 0.25, \n",
      "                                                 nTrees_leaf= 150,\n",
      "                                                 trees_sample_size=200,\n",
      "                                                 regularizer =0.0004,\n",
      "                                                 verbose=True,use_joblib = True,n_jobs = -1,\n",
      "                                                 weights_outside_leaf = 0.75**.25, inclusion_outside_leaf = .5**.25) \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=-1)]: Done   1 out of  16 | elapsed: 34.2min remaining: 513.2min\n",
        "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed: 184.0min finished\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Wall time: 0 ns\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_pred_splitted= hierarchy.predict_splitted(testFactory,criteria,trees_splitted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "w_test = testFactory.weights\n",
      "Yts = testFactory.labels\n",
      "print 'spltd\\t',metrics.roc_auc_score(Yts,y_pred_splitted,sample_weight=w_test)\n",
      "#print 'greedy\\t',metrics.roc_auc_score(Yts,y_pred_greedy,sample_weight=w_test)\n",
      "print 'stupid\\t',metrics.roc_auc_score(Yts,y_pred_stupid,sample_weight=w_test)\n",
      "print 'full\\t',metrics.roc_auc_score(Yts,y_pred_full,sample_weight=w_test)\n",
      "print 'new \\t',metrics.roc_auc_score(Yts,y_pred_sklearn,sample_weight=w_test)\n",
      "print \"well...\"\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "spltd\t0.934255399402"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stupid\t0.916904744001"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "full\t0.935834322801"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "new \t0.856264997764\n",
        "well...\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'spltd\\t', LogLoss.score(testFactory, y_pred_splitted)\n",
      "print 'greedy\\t',LogLoss.score(testFactory, y_pred_greedy)\n",
      "print 'stupid\\t',LogLoss.score(testFactory, y_pred_stupid)\n",
      "print 'full\\t',LogLoss.score(testFactory, y_pred_full)\n",
      "print 'new \\t',LogLoss.score(testFactory, y_pred_sklearn)\n",
      "print \"well...\"\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "spltd\t65677.4334464\n",
        "greedy\t"
       ]
      },
      {
       "ename": "NameError",
       "evalue": "name 'y_pred_greedy' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-53-d5abf254b651>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'spltd\\t'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLogLoss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestFactory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_splitted\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[1;34m'greedy\\t'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLogLoss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestFactory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_greedy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'stupid\\t'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLogLoss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestFactory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_stupid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'full\\t'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLogLoss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestFactory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_full\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'new \\t'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLogLoss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestFactory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_sklearn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'y_pred_greedy' is not defined"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#AUC learning curves"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#I know it could have been done without quadratic complexity over trees, but...\n",
      "#btw equalizing 1-0 weights for the training set is not optimal in terms of AUC, but it is close to being so.\n",
      "n_trees =150\n",
      "auc_stupid_lcurve = [(0.5,)]\n",
      "auc_greedy_lcurve = [(0.5,)]\n",
      "auc_splitted_lcurve = [(0.5,)]\n",
      "for i in range(1,n_trees):\n",
      "    #stpd\n",
      "    pred = testFactory.predict(trees[:i])\n",
      "    auc = metrics.roc_auc_score(testFactory.labels,pred,sample_weight=testFactory.weights),\n",
      "    auc_stupid_lcurve.append( auc)    \n",
      "    #grdy\n",
      "    pred = testFactory.predict(res_greedy[:i])#res_greedy_wheel is not optimized for this dissection \n",
      "    auc = metrics.roc_auc_score(testFactory.labels,pred,sample_weight=testFactory.weights),\n",
      "    auc_greedy_lcurve.append( auc)\n",
      "    #split\n",
      "    trees_i = {code:trees_splitted[code][:i] for code in trees_splitted}\n",
      "    pred = hierarchy.predict_splitted(testFactory,criteria,trees_i)\n",
      "\n",
      "    auc = metrics.roc_auc_score(testFactory.labels,pred,sample_weight=testFactory.weights),\n",
      "    auc_splitted_lcurve.append( auc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p = range(1,n_trees)\n",
      "plt.figure(figsize = [14,14])\n",
      "plt.plot(p,[0.935834322801 for i in range(1,n_trees)],label = \"full\")\n",
      "plt.plot(p,auc_stupid_lcurve[1:n_trees],label = \"stupid\")\n",
      "plt.plot(p,auc_greedy_lcurve[1:n_trees],label = \"greedy\")\n",
      "plt.plot(p,auc_splitted_lcurve[1:n_trees],label = \"splitted\")\n",
      "plt.title('learning curves(AUC)')\n",
      "plt.legend(loc=\"lower right\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#LogLoss learning curves"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#I know it could have been done without quadratic complexity over trees, but...\n",
      "#btw equalizing 1-0 weights for the training set is not optimal in terms of AUC, but it is close to being so.\n",
      "n_trees =150\n",
      "logloss_stupid_lcurve = [(0.5,)]\n",
      "logloss_greedy_lcurve = [(0.5,)]\n",
      "logloss_splitted_lcurve = [(0.5,)]\n",
      "for i in range(1,n_trees):\n",
      "    #stpd\n",
      "    pred = testFactory.predict(trees[:i])\n",
      "    logloss = LogLoss.score(testFactory,pred),\n",
      "    logloss_stupid_lcurve.append( logloss)    \n",
      "    #grdy\n",
      "    pred = testFactory.predict(res_greedy[:i])#res_greedy_wheel is not optimized for this dissection \n",
      "    logloss = LogLoss.score(testFactory,pred),\n",
      "    logloss_greedy_lcurve.append(logloss)\n",
      "    #split\n",
      "    trees_i = {code:trees_splitted[code][:i] for code in trees_splitted}\n",
      "    pred = hierarchy.predict_splitted(testFactory,criteria,trees_i)\n",
      "\n",
      "    logloss = LogLoss.score(testFactory,pred),\n",
      "    logloss_splitted_lcurve.append(logloss)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p = range(1,n_trees)\n",
      "plt.figure(figsize = [14,14])\n",
      "plt.plot(p,[0.935834322801 for i in range(1,n_trees)],label = \"full\")\n",
      "plt.plot(p,logloss_stupid_lcurve[1:n_trees],label = \"stupid\")\n",
      "plt.plot(p,logloss_lcurve[1:n_trees],label = \"greedy\")\n",
      "plt.plot(p,logloss_splitted_lcurve[1:n_trees],label = \"splitted\")\n",
      "plt.title('learning curves(LogLoss)')\n",
      "plt.legend(loc=\"lower right\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}