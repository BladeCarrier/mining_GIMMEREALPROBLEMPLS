{
 "metadata": {
  "name": "",
  "signature": "sha256:57cde94593e7519b1e524dc055f60c6a20fbbfd12d3fdb8f8a10a9a1facf1748"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# I explore the cuts of the features\n",
      "%matplotlib inline\n",
      "#\u0442\u0430\u043a \u0442\u043e\u0436\u0435 \u043c\u043e\u0436\u043d\u043e \u0440\u0435\u0448\u0438\u0442\u044c \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u0443 \u0438\u043d\u043b\u0430\u0439\u043b\u0430 \u043f\u043b\u043e\u0442\u043e\u0432\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.patches as mpatches\n",
      "\n",
      "import numpy as np\n",
      "import scipy as sp\n",
      "import pandas as pd\n",
      "\n",
      "import sklearn.metrics as metrics\n",
      "from sklearn.externals import joblib\n",
      "from sklearn import cross_validation as cv\n",
      "from sklearn.utils import check_arrays\n",
      "\n",
      "import _matrixnetapplier as mnet\n",
      "\n",
      "import copy\n",
      "import random\n",
      "import math\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Extracting the trained model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#extract ODT\n",
      "fstream = open('formula.mx','rb')\n",
      "classi = mnet.MatrixnetClassifier(fstream)\n",
      "fstream.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Get all the trees from .mx\n",
      "def get_trees(classi):\n",
      "    itr = classi.iterate_trees().next()\n",
      "    return itr, [tree for tree in itr[2]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "itr,trees = get_trees(classi)\n",
      "n_features = len(classi.features)\n",
      "print itr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(6, 10000, <generator object _iterate_over_trees_with_fixed_depth at 0x000000000C743090>)\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Loading dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#load training set\n",
      "def load_data(path):\n",
      "    print 'Loading training data.'\n",
      "    data = np.loadtxt(path, \\\n",
      "            delimiter=',', \\\n",
      "            skiprows=1, \\\n",
      "            converters={32: lambda x:int(x=='s'.encode('utf-8'))})\n",
      "\n",
      "    X = data[:,1:31]\n",
      "    Y = data[:,32]\n",
      "    W = data[:,31]\n",
      "    return X,Y,W"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X,Y,W = load_data(\"../data/training.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading training data.\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "Xtr,Xts,Ytr,Yts,Wtr,Wts = train_test_split(X, Y, W, train_size=0.51, random_state=42)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#sanity check"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#predict with the trees boost\n",
      "class DataFactory:\n",
      "    def __init__(self,events,labels,weights):\n",
      "        self.events = events\n",
      "        self.labels = labels\n",
      "        self.weights = weights\n",
      "        \n",
      "        # extending the data so the number of events is divisible by 8\n",
      "        self.n_events = len(events)\n",
      "        self.n_extended64 = (self.n_events + 7) // 8\n",
      "        self.n_extended = self.n_extended64 * 8\n",
      "\n",
      "        # using Fortran order (surprisingly doesn't seem to influence speed much)\n",
      "        self.features = np.zeros([self.n_extended, self.events.shape[1]], dtype='float32', order='F')\n",
      "        self.features[:self.n_events, :] = self.events\n",
      "    def predict(self,trees,bias = 0):\n",
      "        '''\n",
      "        make real-value predictions using sklearn gradient_boosting.predict_stages\n",
      "        '''\n",
      "        if len(trees) ==0:\n",
      "            return np.zeros(self.events.shape[0])\n",
      "        result = np.zeros(len(self.events), dtype=float)\n",
      "        for stage_predictions in self.apply_separately(trees,bias):\n",
      "            result += stage_predictions\n",
      "        return result\n",
      "    def apply_separately(self,trees,bias=0):\n",
      "        \"\"\"\n",
      "        :param events: numpy.array (or DataFrame) of shape [n_samples, n_features]\n",
      "        :return: each time yields numpy.array predictions of shape [n_samples]\n",
      "            which is output of a particular tree\n",
      "        \"\"\"\n",
      "        # result of first iteration\n",
      "        yield np.zeros(len(self.events), dtype=float)+ bias\n",
      "\n",
      "        tree_depth = len(trees[0][0])\n",
      "        nf_count = len(trees)\n",
      "        \n",
      "        for tree in trees:\n",
      "            leaf_indices = self.getLeafIndices(tree)        \n",
      "            leaf_values = tree[2]\n",
      "            yield leaf_values[leaf_indices]\n",
      "            \n",
      "    def getLeafIndices(self,tree):\n",
      "        \"\"\"\n",
      "        get the tree active leaf indices on the data\n",
      "        \"\"\"\n",
      "        tree_features, tree_cuts, _ = tree\n",
      "        leaf_indices = np.zeros(self.n_extended64, dtype='int64')\n",
      "            \n",
      "        for tree_level, (feature, cut) in enumerate(zip(tree_features, tree_cuts)):\n",
      "            leaf_indices |= (self.features[:, feature] > cut).view('int64') << tree_level\n",
      "        return leaf_indices.view('int8')[:self.n_events]\n",
      "    def split_by(self,boolean):\n",
      "        inverse = boolean == False\n",
      "        return (\n",
      "                DataFactory(self.events[boolean],self.labels[boolean],self.weights[boolean]),\n",
      "                DataFactory(self.events[inverse],self.labels[inverse],self.weights[inverse]),\n",
      "                )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 159
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trainFactory = DataFactory(Xtr,Ytr,Wtr)\n",
      "testFactory = DataFactory(Xts,Yts,Wts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 160
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compute_ams_on_cuts(answers, predictions, sample_weight):\n",
      "    \"\"\" Predictions are probabilities\"\"\"\n",
      "    b, s, thresholds = metrics.roc_curve(answers, predictions, sample_weight=sample_weight)\n",
      "    # normalization constants\n",
      "    real_s = 691.988607712\n",
      "    real_b = 410999.847322\n",
      "    s *= real_s\n",
      "    b *= real_b\n",
      "    br = 10.\n",
      "    radicands = 2 * ((s + b + br) * np.log(1.0 + s/(b + br)) - s)\n",
      "    return thresholds, radicands\n",
      "\n",
      "def optimal_AMS(answers, predictions, sample_weight):\n",
      "    \"\"\" Predictions are probabilities \"\"\"\n",
      "    cuts, radicands = compute_ams_on_cuts(answers, predictions, sample_weight)\n",
      "    return np.sqrt(np.max(radicands))\n",
      "\n",
      "\n",
      "def precisionAt15(answers, predictions, sample_weight, percent=0.15):\n",
      "    n_passed = int(len(answers) * percent)\n",
      "    RATIO = 50\n",
      "    weight = sample_weight.copy()\n",
      "    weight[answers == 0] /= weight[answers == 0].mean() / RATIO\n",
      "    weight[answers == 1] /= weight[answers == 1].mean()\n",
      "    order = np.argsort(-predictions)\n",
      "    passed = order[:n_passed]    \n",
      "    return np.average(answers[passed], weights=weight[passed])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_control_metrics(proba_test, proba_train):\n",
      "    for name, metric in [('ROC', metrics.roc_auc_score), ('AMS', optimal_AMS), ('precision', precisionAt15)]:\n",
      "        print name,\n",
      "        print metric(Yts, proba_test, sample_weight=Wts), \n",
      "        print metric(Ytr, proba_train, sample_weight=Wtr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_control_metrics(testFactory.predict(trees),trainFactory.predict(trees))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ROC "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.935834322801 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.961031841221\n",
        "AMS 3.71746365006 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5.41899018231\n",
        "precision 0.266316147498 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.394846517557\n"
       ]
      }
     ],
     "prompt_number": 105
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# greedy pruning for the whole data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class LogLoss:\n",
      "    def __call__(self,actual, pred):\n",
      "        \"\"\"\n",
      "        i know it isn't\n",
      "        \"\"\"\n",
      "        return actual - sp.special.expit(pred.reshape(pred.shape[0]))\n",
      "    def update_leaves(self,factory,residual,tree,lrate):\n",
      "        '''\n",
      "        update leaf values via... Newton guy...\n",
      "        '''\n",
      "\n",
      "        leaf_indices = factory.getLeafIndices(tree)\n",
      "        leaf_values = tree[2]*0\n",
      "        normalizers = np.zeros(leaf_indices.shape[0])\n",
      "\n",
      "        prec_value = residual*factory.weights\n",
      "        prec_norm = (factory.labels - residual) * (1 - factory.labels + residual)*factory.weights\n",
      "        \n",
      "        for i in xrange(leaf_indices.shape[0]):\n",
      "            #still faster than multiple selections\n",
      "            leaf_ind = leaf_indices[i]\n",
      "            leaf_values[leaf_ind] += prec_value[i]\n",
      "            normalizers[leaf_ind] += prec_norm[i]\n",
      "\n",
      "        #alarma! i aint entirely mathematical\n",
      "        leaf_values[normalizers != 0] /= normalizers[normalizers !=0]\n",
      "\n",
      "        newtree = tuple([copy.copy(i) for i in tree[:2]] + [leaf_values*lrate])\n",
      "\n",
      "        return newtree\n",
      "LogLoss = LogLoss()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def inthread_try_add(bunch,tree,factory,loss,residual,y_pred,learning_rate):\n",
      "        \n",
      "        newTree = loss.update_leaves(factory,residual,tree,learning_rate)\n",
      "        newPred = y_pred + factory.predict([newTree])\n",
      "        newLoss = np.average(abs(loss(factory.labels,newPred)),weights=factory.weights)\n",
      "        return newLoss,newTree\n",
      "\n",
      "def try_add1_bfs(bunch, allTrees,factory,learning_rate,loss,breadth):\n",
      "    '''\n",
      "    select best tree to add (1 step)\n",
      "    '''\n",
      "    y = factory.labels\n",
      "    y_pred = factory.predict(bunch)\n",
      "    residual = loss(y,y_pred)\n",
      "    \n",
      "    pairs = [inthread_try_add(bunch,tree,factory,loss,residual,y_pred,learning_rate) for tree in allTrees]   \n",
      "    pairs.sort(key = lambda el: el[0])\n",
      "    \n",
      "    bunches = []\n",
      "    for pair in pairs[:breadth]:\n",
      "        tree = pair[1]\n",
      "        bunch = bunch+[tree]\n",
      "        bunches.append(bunch)\n",
      "\n",
      "    return bunches,[pair[1] for pair in pairs[:breadth]],[pair[0] for pair in pairs[:breadth]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def greed_up_features_bfs (trees,\n",
      "                           factory,\n",
      "                           loss,\n",
      "                           learning_rate,\n",
      "                           breadth,\n",
      "                           nTrees,\n",
      "                           trees_sample_size,\n",
      "                           verbose = True,\n",
      "                           learning_rate_decay = 1.,\n",
      "                           trees_sample_increase = 0):\n",
      "    \"\"\"\n",
      "    Iterative BFS over best ADD-1 results for [nTrees] iterations\n",
      "    \"\"\"\n",
      "    allTrees = copy.copy(trees)\n",
      "    \n",
      "    trees_sample = np.array(random.sample(allTrees,trees_sample_size))\n",
      "    \n",
      "    bunches,additions,losses = try_add1_bfs([],trees_sample,factory,learning_rate,loss,breadth)\n",
      "    bestScore = min(losses)\n",
      "\n",
      "    if verbose:\n",
      "        print \"\\niteration #\",0,\" ntrees = \", len(bunches[0]),\"\\nbest loss = \",bestScore\n",
      "        print \"learning_rate = \", learning_rate\n",
      "        print \"sample_size\", trees_sample_size\n",
      "\n",
      "    \n",
      "    itr = 0\n",
      "    while len(bunches[0]) <nTrees:\n",
      "        itr+=1\n",
      "        newBunches = []    \n",
      "        newScores = []\n",
      "        for bunch in bunches:\n",
      "            trees_sample = np.array(random.sample(allTrees,trees_sample_size))\n",
      "            bunches,additions,losses = try_add1_bfs(bunch,trees_sample,factory,learning_rate,loss,breadth)\n",
      "            newBunches+=bunches\n",
      "            newScores += losses\n",
      "            \n",
      "        learning_rate *= learning_rate_decay\n",
      "        trees_sample_size = min(len(allTrees),trees_sample_size + trees_sample_increase)\n",
      "            \n",
      "        pairs = [(newScores[i],newBunches[i]) for i in xrange(len(newBunches))]\n",
      "        pairs.sort(key = lambda el: el[0])\n",
      "        \n",
      "        bunches = [pair[1] for pair in pairs[:breadth]]       \n",
      "        newBestScore = min(newScores)\n",
      "        \n",
      "        if newBestScore > bestScore:\n",
      "            bunches = [bnch[:-1] for bnch in bunches]\n",
      "            learning_rate /=2.\n",
      "            if learning_rate < 0.00001:\n",
      "                break\n",
      "        else: bestScore = newBestScore\n",
      "        \n",
      "        \n",
      "        if verbose:\n",
      "            print \"\\niteration #\",itr,\" ntrees = \", len(bunches[0]),\"\\nbest loss = \", bestScore,\"\\nlast loss = \",newBestScore\n",
      "            print \"learning_rate = \", learning_rate\n",
      "            print \"sample_size\", trees_sample_size           \n",
      "    return bunches[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res_greedy = greed_up_features_bfs(trees,trainFactory,LogLoss,0.1,1,100,500,True,0.99,0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration # 0  ntrees =  1 \n",
        "best loss =  0.450498005718\n",
        "learning_rate =  0.1\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1  ntrees =  2 \n",
        "best loss =  0.406301401817 \n",
        "last loss =  0.406301401817\n",
        "learning_rate =  0.099\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2  ntrees =  3 \n",
        "best loss =  0.367110052765 \n",
        "last loss =  0.367110052765\n",
        "learning_rate =  0.09801\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3  ntrees =  4 \n",
        "best loss =  0.332242605067 \n",
        "last loss =  0.332242605067\n",
        "learning_rate =  0.0970299\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4  ntrees =  5 \n",
        "best loss =  0.301139960808 \n",
        "last loss =  0.301139960808\n",
        "learning_rate =  0.096059601\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5  ntrees =  6 \n",
        "best loss =  0.273334906925 \n",
        "last loss =  0.273334906925\n",
        "learning_rate =  0.09509900499\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6  ntrees =  7 \n",
        "best loss =  0.248430066692 \n",
        "last loss =  0.248430066692\n",
        "learning_rate =  0.0941480149401\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7  ntrees =  8 \n",
        "best loss =  0.226085312389 \n",
        "last loss =  0.226085312389\n",
        "learning_rate =  0.0932065347907\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8  ntrees =  9 \n",
        "best loss =  0.206007264714 \n",
        "last loss =  0.206007264714\n",
        "learning_rate =  0.0922744694428\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9  ntrees =  10 \n",
        "best loss =  0.187940064605 \n",
        "last loss =  0.187940064605\n",
        "learning_rate =  0.0913517247484\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10  ntrees =  11 \n",
        "best loss =  0.171661315151 \n",
        "last loss =  0.171661315151\n",
        "learning_rate =  0.0904382075009\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11  ntrees =  12 \n",
        "best loss =  0.156975970192 \n",
        "last loss =  0.156975970192\n",
        "learning_rate =  0.0895338254259\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12  ntrees =  13 \n",
        "best loss =  0.143712071874 \n",
        "last loss =  0.143712071874\n",
        "learning_rate =  0.0886384871716\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13  ntrees =  14 \n",
        "best loss =  0.13171864859 \n",
        "last loss =  0.13171864859\n",
        "learning_rate =  0.0877521022999\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14  ntrees =  15 \n",
        "best loss =  0.120862476362 \n",
        "last loss =  0.120862476362\n",
        "learning_rate =  0.0868745812769\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 15  ntrees =  16 \n",
        "best loss =  0.11102523534 \n",
        "last loss =  0.11102523534\n",
        "learning_rate =  0.0860058354641\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 16  ntrees =  17 \n",
        "best loss =  0.10210244946 \n",
        "last loss =  0.10210244946\n",
        "learning_rate =  0.0851457771095\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 17  ntrees =  18 \n",
        "best loss =  0.0940010966319 \n",
        "last loss =  0.0940010966319\n",
        "learning_rate =  0.0842943193384\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 18  ntrees =  19 \n",
        "best loss =  0.0866382093786 \n",
        "last loss =  0.0866382093786\n",
        "learning_rate =  0.083451376145\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 19  ntrees =  20 \n",
        "best loss =  0.0799407556042 \n",
        "last loss =  0.0799407556042\n",
        "learning_rate =  0.0826168623836\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 20  ntrees =  21 \n",
        "best loss =  0.07384244386 \n",
        "last loss =  0.07384244386\n",
        "learning_rate =  0.0817906937597\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 21  ntrees =  22 \n",
        "best loss =  0.0682847590833 \n",
        "last loss =  0.0682847590833\n",
        "learning_rate =  0.0809727868221\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 22  ntrees =  23 \n",
        "best loss =  0.0632158305647 \n",
        "last loss =  0.0632158305647\n",
        "learning_rate =  0.0801630589539\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 23  ntrees =  24 \n",
        "best loss =  0.0585879057449 \n",
        "last loss =  0.0585879057449\n",
        "learning_rate =  0.0793614283644\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 24  ntrees =  25 \n",
        "best loss =  0.0543595957041 \n",
        "last loss =  0.0543595957041\n",
        "learning_rate =  0.0785678140807\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 25  ntrees =  26 \n",
        "best loss =  0.0504928060971 \n",
        "last loss =  0.0504928060971\n",
        "learning_rate =  0.0777821359399\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 26  ntrees =  27 \n",
        "best loss =  0.0469539132041 \n",
        "last loss =  0.0469539132041\n",
        "learning_rate =  0.0770043145805\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 27  ntrees =  28 \n",
        "best loss =  0.0437123879613 \n",
        "last loss =  0.0437123879613\n",
        "learning_rate =  0.0762342714347\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 28  ntrees =  29 \n",
        "best loss =  0.0407410347923 \n",
        "last loss =  0.0407410347923\n",
        "learning_rate =  0.0754719287204\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 29  ntrees =  30 \n",
        "best loss =  0.0380149047524 \n",
        "last loss =  0.0380149047524\n",
        "learning_rate =  0.0747172094332\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 30  ntrees =  31 \n",
        "best loss =  0.0355120150369 \n",
        "last loss =  0.0355120150369\n",
        "learning_rate =  0.0739700373388\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 31  ntrees =  32 \n",
        "best loss =  0.0332121470427 \n",
        "last loss =  0.0332121470427\n",
        "learning_rate =  0.0732303369654\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 32  ntrees =  33 \n",
        "best loss =  0.0310973383842 \n",
        "last loss =  0.0310973383842\n",
        "learning_rate =  0.0724980335958\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33  ntrees =  34 \n",
        "best loss =  0.02915098963 \n",
        "last loss =  0.02915098963\n",
        "learning_rate =  0.0717730532598\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 34  ntrees =  35 \n",
        "best loss =  0.0273585027199 \n",
        "last loss =  0.0273585027199\n",
        "learning_rate =  0.0710553227272\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 35  ntrees =  36 \n",
        "best loss =  0.0257065457308 \n",
        "last loss =  0.0257065457308\n",
        "learning_rate =  0.0703447695\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 36  ntrees =  37 \n",
        "best loss =  0.0241829748498 \n",
        "last loss =  0.0241829748498\n",
        "learning_rate =  0.069641321805\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 37  ntrees =  38 \n",
        "best loss =  0.0227767931627 \n",
        "last loss =  0.0227767931627\n",
        "learning_rate =  0.0689449085869\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 38  ntrees =  39 \n",
        "best loss =  0.0214784716644 \n",
        "last loss =  0.0214784716644\n",
        "learning_rate =  0.068255459501\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 39  ntrees =  40 \n",
        "best loss =  0.0202781810555 \n",
        "last loss =  0.0202781810555\n",
        "learning_rate =  0.067572904906\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 40  ntrees =  41 \n",
        "best loss =  0.01916807611 \n",
        "last loss =  0.01916807611\n",
        "learning_rate =  0.066897175857\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 41  ntrees =  42 \n",
        "best loss =  0.0181407021059 \n",
        "last loss =  0.0181407021059\n",
        "learning_rate =  0.0662282040984\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 42  ntrees =  43 \n",
        "best loss =  0.017189191774 \n",
        "last loss =  0.017189191774\n",
        "learning_rate =  0.0655659220574\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 43  ntrees =  44 \n",
        "best loss =  0.0163074233444 \n",
        "last loss =  0.0163074233444\n",
        "learning_rate =  0.0649102628368\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 44  ntrees =  45 \n",
        "best loss =  0.0154896327136 \n",
        "last loss =  0.0154896327136\n",
        "learning_rate =  0.0642611602085\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 45  ntrees =  46 \n",
        "best loss =  0.014730798452 \n",
        "last loss =  0.014730798452\n",
        "learning_rate =  0.0636185486064\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 46  ntrees =  47 \n",
        "best loss =  0.0140262034106 \n",
        "last loss =  0.0140262034106\n",
        "learning_rate =  0.0629823631203\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 47  ntrees =  48 \n",
        "best loss =  0.0133712856384 \n",
        "last loss =  0.0133712856384\n",
        "learning_rate =  0.0623525394891\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 48  ntrees =  49 \n",
        "best loss =  0.0127623533665 \n",
        "last loss =  0.0127623533665\n",
        "learning_rate =  0.0617290140942\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 49  ntrees =  50 \n",
        "best loss =  0.0121957712808 \n",
        "last loss =  0.0121957712808\n",
        "learning_rate =  0.0611117239533\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 50  ntrees =  51 \n",
        "best loss =  0.011668547508 \n",
        "last loss =  0.011668547508\n",
        "learning_rate =  0.0605006067138\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 51  ntrees =  52 \n",
        "best loss =  0.0111772005423 \n",
        "last loss =  0.0111772005423\n",
        "learning_rate =  0.0598956006466\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 52  ntrees =  53 \n",
        "best loss =  0.0107194523819 \n",
        "last loss =  0.0107194523819\n",
        "learning_rate =  0.0592966446401\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 53  ntrees =  54 \n",
        "best loss =  0.0102922400472 \n",
        "last loss =  0.0102922400472\n",
        "learning_rate =  0.0587036781937\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 54  ntrees =  55 \n",
        "best loss =  0.00989385885734 \n",
        "last loss =  0.00989385885734\n",
        "learning_rate =  0.0581166414118\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 55  ntrees =  56 \n",
        "best loss =  0.00952177903384 \n",
        "last loss =  0.00952177903384\n",
        "learning_rate =  0.0575354749977\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 56  ntrees =  57 \n",
        "best loss =  0.00917400974181 \n",
        "last loss =  0.00917400974181\n",
        "learning_rate =  0.0569601202477\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 57  ntrees =  58 \n",
        "best loss =  0.00884898938232 \n",
        "last loss =  0.00884898938232\n",
        "learning_rate =  0.0563905190452\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 58  ntrees =  59 \n",
        "best loss =  0.00854490609941 \n",
        "last loss =  0.00854490609941\n",
        "learning_rate =  0.0558266138548\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 59  ntrees =  60 \n",
        "best loss =  0.00826039057599 \n",
        "last loss =  0.00826039057599\n",
        "learning_rate =  0.0552683477162\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 60  ntrees =  61 \n",
        "best loss =  0.00799368781574 \n",
        "last loss =  0.00799368781574\n",
        "learning_rate =  0.0547156642391\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 61  ntrees =  62 \n",
        "best loss =  0.00774384276419 \n",
        "last loss =  0.00774384276419\n",
        "learning_rate =  0.0541685075967\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 62  ntrees =  63 \n",
        "best loss =  0.00750960101041 \n",
        "last loss =  0.00750960101041\n",
        "learning_rate =  0.0536268225207\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 63  ntrees =  64 \n",
        "best loss =  0.00728976890606 \n",
        "last loss =  0.00728976890606\n",
        "learning_rate =  0.0530905542955\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 64  ntrees =  65 \n",
        "best loss =  0.00708345914478 \n",
        "last loss =  0.00708345914478\n",
        "learning_rate =  0.0525596487526\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 65  ntrees =  66 \n",
        "best loss =  0.00688981471965 \n",
        "last loss =  0.00688981471965\n",
        "learning_rate =  0.052034052265\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 66  ntrees =  67 \n",
        "best loss =  0.00670773217198 \n",
        "last loss =  0.00670773217198\n",
        "learning_rate =  0.0515137117424\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 67  ntrees =  68 \n",
        "best loss =  0.00653665125494 \n",
        "last loss =  0.00653665125494\n",
        "learning_rate =  0.050998574625\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 68  ntrees =  69 \n",
        "best loss =  0.00637567305018 \n",
        "last loss =  0.00637567305018\n",
        "learning_rate =  0.0504885888787\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 69  ntrees =  70 \n",
        "best loss =  0.00622418126838 \n",
        "last loss =  0.00622418126838\n",
        "learning_rate =  0.0499837029899\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 70  ntrees =  71 \n",
        "best loss =  0.0060816367526 \n",
        "last loss =  0.0060816367526\n",
        "learning_rate =  0.04948386596\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 71  ntrees =  72 \n",
        "best loss =  0.00594721632556 \n",
        "last loss =  0.00594721632556\n",
        "learning_rate =  0.0489890273004\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 72  ntrees =  73 \n",
        "best loss =  0.00582065431801 \n",
        "last loss =  0.00582065431801\n",
        "learning_rate =  0.0484991370274\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 73  ntrees =  74 \n",
        "best loss =  0.00570119879642 \n",
        "last loss =  0.00570119879642\n",
        "learning_rate =  0.0480141456571\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 74  ntrees =  75 \n",
        "best loss =  0.00558850901301 \n",
        "last loss =  0.00558850901301\n",
        "learning_rate =  0.0475340042006\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 75  ntrees =  76 \n",
        "best loss =  0.00548209122412 \n",
        "last loss =  0.00548209122412\n",
        "learning_rate =  0.0470586641586\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 76  ntrees =  77 \n",
        "best loss =  0.005381680489 \n",
        "last loss =  0.005381680489\n",
        "learning_rate =  0.046588077517\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 77  ntrees =  78 \n",
        "best loss =  0.00528668741838 \n",
        "last loss =  0.00528668741838\n",
        "learning_rate =  0.0461221967418\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 78  ntrees =  79 \n",
        "best loss =  0.00519692265392 \n",
        "last loss =  0.00519692265392\n",
        "learning_rate =  0.0456609747744\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 79  ntrees =  80 \n",
        "best loss =  0.00511206360773 \n",
        "last loss =  0.00511206360773\n",
        "learning_rate =  0.0452043650266\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 80  ntrees =  81 \n",
        "best loss =  0.00503179112627 \n",
        "last loss =  0.00503179112627\n",
        "learning_rate =  0.0447523213764\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 81  ntrees =  82 \n",
        "best loss =  0.00495581330534 \n",
        "last loss =  0.00495581330534\n",
        "learning_rate =  0.0443047981626\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 82  ntrees =  83 \n",
        "best loss =  0.00488384170244 \n",
        "last loss =  0.00488384170244\n",
        "learning_rate =  0.043861750181\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 83  ntrees =  84 \n",
        "best loss =  0.00481567381209 \n",
        "last loss =  0.00481567381209\n",
        "learning_rate =  0.0434231326792\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84  ntrees =  85 \n",
        "best loss =  0.00475108058976 \n",
        "last loss =  0.00475108058976\n",
        "learning_rate =  0.0429889013524\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85  ntrees =  86 \n",
        "best loss =  0.00468973140522 \n",
        "last loss =  0.00468973140522\n",
        "learning_rate =  0.0425590123389\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 86  ntrees =  87 \n",
        "best loss =  0.00463158370983 \n",
        "last loss =  0.00463158370983\n",
        "learning_rate =  0.0421334222155\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 87  ntrees =  88 \n",
        "best loss =  0.0045762814455 \n",
        "last loss =  0.0045762814455\n",
        "learning_rate =  0.0417120879933\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 88  ntrees =  89 \n",
        "best loss =  0.00452381173969 \n",
        "last loss =  0.00452381173969\n",
        "learning_rate =  0.0412949671134\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 89  ntrees =  90 \n",
        "best loss =  0.00447404581979 \n",
        "last loss =  0.00447404581979\n",
        "learning_rate =  0.0408820174423\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 90  ntrees =  91 \n",
        "best loss =  0.00442676628509 \n",
        "last loss =  0.00442676628509\n",
        "learning_rate =  0.0404731972678\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 91  ntrees =  92 \n",
        "best loss =  0.00438164730809 \n",
        "last loss =  0.00438164730809\n",
        "learning_rate =  0.0400684652952\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 92  ntrees =  93 \n",
        "best loss =  0.0043388345673 \n",
        "last loss =  0.0043388345673\n",
        "learning_rate =  0.0396677806422\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 93  ntrees =  94 \n",
        "best loss =  0.00429810202455 \n",
        "last loss =  0.00429810202455\n",
        "learning_rate =  0.0392711028358\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 94  ntrees =  95 \n",
        "best loss =  0.00425927687739 \n",
        "last loss =  0.00425927687739\n",
        "learning_rate =  0.0388783918074\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 95  ntrees =  96 \n",
        "best loss =  0.0042223265988 \n",
        "last loss =  0.0042223265988\n",
        "learning_rate =  0.0384896078893\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 96  ntrees =  97 \n",
        "best loss =  0.00418709481142 \n",
        "last loss =  0.00418709481142\n",
        "learning_rate =  0.0381047118105\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 97  ntrees =  98 \n",
        "best loss =  0.0041534779078 \n",
        "last loss =  0.0041534779078\n",
        "learning_rate =  0.0377236646924\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 98  ntrees =  99 \n",
        "best loss =  0.00412143527114 \n",
        "last loss =  0.00412143527114\n",
        "learning_rate =  0.0373464280454\n",
        "sample_size 500\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 99  ntrees =  100 \n",
        "best loss =  0.00409090246871 \n",
        "last loss =  0.00409090246871\n",
        "learning_rate =  0.036972963765\n",
        "sample_size 500\n"
       ]
      }
     ],
     "prompt_number": 188
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_pred_greedy = testFactory.predict(res_greedy)\n",
      "y_pred_stupid = testFactory.predict(trees[:100])\n",
      "y_pred_full = testFactory.predict(trees)\n",
      "w_test = testFactory.weights"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 202
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print metrics.roc_auc_score(Yts,y_pred_greedy,sample_weight=w_test),\n",
      "print metrics.roc_auc_score(Yts,y_pred_stupid,sample_weight=w_test),\n",
      "print metrics.roc_auc_score(Yts,y_pred_full,sample_weight=w_test)\n",
      "print \"well...\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.920822258087 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.916904744001 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.935834322801\n",
        "well...\n"
       ]
      }
     ],
     "prompt_number": 203
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "joblib.dump(res_greedy,\"greedy 100 trees\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 191,
       "text": [
        "['greedy 100 trees',\n",
        " 'greedy 100 trees_01.npy',\n",
        " 'greedy 100 trees_02.npy',\n",
        " 'greedy 100 trees_03.npy',\n",
        " 'greedy 100 trees_04.npy',\n",
        " 'greedy 100 trees_05.npy',\n",
        " 'greedy 100 trees_06.npy',\n",
        " 'greedy 100 trees_07.npy',\n",
        " 'greedy 100 trees_08.npy',\n",
        " 'greedy 100 trees_09.npy',\n",
        " 'greedy 100 trees_10.npy',\n",
        " 'greedy 100 trees_11.npy',\n",
        " 'greedy 100 trees_12.npy',\n",
        " 'greedy 100 trees_13.npy',\n",
        " 'greedy 100 trees_14.npy',\n",
        " 'greedy 100 trees_15.npy',\n",
        " 'greedy 100 trees_16.npy',\n",
        " 'greedy 100 trees_17.npy',\n",
        " 'greedy 100 trees_18.npy',\n",
        " 'greedy 100 trees_19.npy',\n",
        " 'greedy 100 trees_20.npy',\n",
        " 'greedy 100 trees_21.npy',\n",
        " 'greedy 100 trees_22.npy',\n",
        " 'greedy 100 trees_23.npy',\n",
        " 'greedy 100 trees_24.npy',\n",
        " 'greedy 100 trees_25.npy',\n",
        " 'greedy 100 trees_26.npy',\n",
        " 'greedy 100 trees_27.npy',\n",
        " 'greedy 100 trees_28.npy',\n",
        " 'greedy 100 trees_29.npy',\n",
        " 'greedy 100 trees_30.npy',\n",
        " 'greedy 100 trees_31.npy',\n",
        " 'greedy 100 trees_32.npy',\n",
        " 'greedy 100 trees_33.npy',\n",
        " 'greedy 100 trees_34.npy',\n",
        " 'greedy 100 trees_35.npy',\n",
        " 'greedy 100 trees_36.npy',\n",
        " 'greedy 100 trees_37.npy',\n",
        " 'greedy 100 trees_38.npy',\n",
        " 'greedy 100 trees_39.npy',\n",
        " 'greedy 100 trees_40.npy',\n",
        " 'greedy 100 trees_41.npy',\n",
        " 'greedy 100 trees_42.npy',\n",
        " 'greedy 100 trees_43.npy',\n",
        " 'greedy 100 trees_44.npy',\n",
        " 'greedy 100 trees_45.npy',\n",
        " 'greedy 100 trees_46.npy',\n",
        " 'greedy 100 trees_47.npy',\n",
        " 'greedy 100 trees_48.npy',\n",
        " 'greedy 100 trees_49.npy',\n",
        " 'greedy 100 trees_50.npy',\n",
        " 'greedy 100 trees_51.npy',\n",
        " 'greedy 100 trees_52.npy',\n",
        " 'greedy 100 trees_53.npy',\n",
        " 'greedy 100 trees_54.npy',\n",
        " 'greedy 100 trees_55.npy',\n",
        " 'greedy 100 trees_56.npy',\n",
        " 'greedy 100 trees_57.npy',\n",
        " 'greedy 100 trees_58.npy',\n",
        " 'greedy 100 trees_59.npy',\n",
        " 'greedy 100 trees_60.npy',\n",
        " 'greedy 100 trees_61.npy',\n",
        " 'greedy 100 trees_62.npy',\n",
        " 'greedy 100 trees_63.npy',\n",
        " 'greedy 100 trees_64.npy',\n",
        " 'greedy 100 trees_65.npy',\n",
        " 'greedy 100 trees_66.npy',\n",
        " 'greedy 100 trees_67.npy',\n",
        " 'greedy 100 trees_68.npy',\n",
        " 'greedy 100 trees_69.npy',\n",
        " 'greedy 100 trees_70.npy',\n",
        " 'greedy 100 trees_71.npy',\n",
        " 'greedy 100 trees_72.npy',\n",
        " 'greedy 100 trees_73.npy',\n",
        " 'greedy 100 trees_74.npy',\n",
        " 'greedy 100 trees_75.npy',\n",
        " 'greedy 100 trees_76.npy',\n",
        " 'greedy 100 trees_77.npy',\n",
        " 'greedy 100 trees_78.npy',\n",
        " 'greedy 100 trees_79.npy',\n",
        " 'greedy 100 trees_80.npy',\n",
        " 'greedy 100 trees_81.npy',\n",
        " 'greedy 100 trees_82.npy',\n",
        " 'greedy 100 trees_83.npy',\n",
        " 'greedy 100 trees_84.npy',\n",
        " 'greedy 100 trees_85.npy',\n",
        " 'greedy 100 trees_86.npy',\n",
        " 'greedy 100 trees_87.npy',\n",
        " 'greedy 100 trees_88.npy',\n",
        " 'greedy 100 trees_89.npy',\n",
        " 'greedy 100 trees_90.npy',\n",
        " 'greedy 100 trees_91.npy',\n",
        " 'greedy 100 trees_92.npy',\n",
        " 'greedy 100 trees_93.npy',\n",
        " 'greedy 100 trees_94.npy',\n",
        " 'greedy 100 trees_95.npy',\n",
        " 'greedy 100 trees_96.npy',\n",
        " 'greedy 100 trees_97.npy',\n",
        " 'greedy 100 trees_98.npy',\n",
        " 'greedy 100 trees_99.npy',\n",
        " 'greedy 100 trees_100.npy',\n",
        " 'greedy 100 trees_101.npy',\n",
        " 'greedy 100 trees_102.npy',\n",
        " 'greedy 100 trees_103.npy',\n",
        " 'greedy 100 trees_104.npy',\n",
        " 'greedy 100 trees_105.npy',\n",
        " 'greedy 100 trees_106.npy',\n",
        " 'greedy 100 trees_107.npy',\n",
        " 'greedy 100 trees_108.npy',\n",
        " 'greedy 100 trees_109.npy',\n",
        " 'greedy 100 trees_110.npy',\n",
        " 'greedy 100 trees_111.npy',\n",
        " 'greedy 100 trees_112.npy',\n",
        " 'greedy 100 trees_113.npy',\n",
        " 'greedy 100 trees_114.npy',\n",
        " 'greedy 100 trees_115.npy',\n",
        " 'greedy 100 trees_116.npy',\n",
        " 'greedy 100 trees_117.npy',\n",
        " 'greedy 100 trees_118.npy',\n",
        " 'greedy 100 trees_119.npy',\n",
        " 'greedy 100 trees_120.npy',\n",
        " 'greedy 100 trees_121.npy',\n",
        " 'greedy 100 trees_122.npy',\n",
        " 'greedy 100 trees_123.npy',\n",
        " 'greedy 100 trees_124.npy',\n",
        " 'greedy 100 trees_125.npy',\n",
        " 'greedy 100 trees_126.npy',\n",
        " 'greedy 100 trees_127.npy',\n",
        " 'greedy 100 trees_128.npy',\n",
        " 'greedy 100 trees_129.npy',\n",
        " 'greedy 100 trees_130.npy',\n",
        " 'greedy 100 trees_131.npy',\n",
        " 'greedy 100 trees_132.npy',\n",
        " 'greedy 100 trees_133.npy',\n",
        " 'greedy 100 trees_134.npy',\n",
        " 'greedy 100 trees_135.npy',\n",
        " 'greedy 100 trees_136.npy',\n",
        " 'greedy 100 trees_137.npy',\n",
        " 'greedy 100 trees_138.npy',\n",
        " 'greedy 100 trees_139.npy',\n",
        " 'greedy 100 trees_140.npy',\n",
        " 'greedy 100 trees_141.npy',\n",
        " 'greedy 100 trees_142.npy',\n",
        " 'greedy 100 trees_143.npy',\n",
        " 'greedy 100 trees_144.npy',\n",
        " 'greedy 100 trees_145.npy',\n",
        " 'greedy 100 trees_146.npy',\n",
        " 'greedy 100 trees_147.npy',\n",
        " 'greedy 100 trees_148.npy',\n",
        " 'greedy 100 trees_149.npy',\n",
        " 'greedy 100 trees_150.npy',\n",
        " 'greedy 100 trees_151.npy',\n",
        " 'greedy 100 trees_152.npy',\n",
        " 'greedy 100 trees_153.npy',\n",
        " 'greedy 100 trees_154.npy',\n",
        " 'greedy 100 trees_155.npy',\n",
        " 'greedy 100 trees_156.npy',\n",
        " 'greedy 100 trees_157.npy',\n",
        " 'greedy 100 trees_158.npy',\n",
        " 'greedy 100 trees_159.npy',\n",
        " 'greedy 100 trees_160.npy',\n",
        " 'greedy 100 trees_161.npy',\n",
        " 'greedy 100 trees_162.npy',\n",
        " 'greedy 100 trees_163.npy',\n",
        " 'greedy 100 trees_164.npy',\n",
        " 'greedy 100 trees_165.npy',\n",
        " 'greedy 100 trees_166.npy',\n",
        " 'greedy 100 trees_167.npy',\n",
        " 'greedy 100 trees_168.npy',\n",
        " 'greedy 100 trees_169.npy',\n",
        " 'greedy 100 trees_170.npy',\n",
        " 'greedy 100 trees_171.npy',\n",
        " 'greedy 100 trees_172.npy',\n",
        " 'greedy 100 trees_173.npy',\n",
        " 'greedy 100 trees_174.npy',\n",
        " 'greedy 100 trees_175.npy',\n",
        " 'greedy 100 trees_176.npy',\n",
        " 'greedy 100 trees_177.npy',\n",
        " 'greedy 100 trees_178.npy',\n",
        " 'greedy 100 trees_179.npy',\n",
        " 'greedy 100 trees_180.npy',\n",
        " 'greedy 100 trees_181.npy',\n",
        " 'greedy 100 trees_182.npy',\n",
        " 'greedy 100 trees_183.npy',\n",
        " 'greedy 100 trees_184.npy',\n",
        " 'greedy 100 trees_185.npy',\n",
        " 'greedy 100 trees_186.npy',\n",
        " 'greedy 100 trees_187.npy',\n",
        " 'greedy 100 trees_188.npy',\n",
        " 'greedy 100 trees_189.npy',\n",
        " 'greedy 100 trees_190.npy',\n",
        " 'greedy 100 trees_191.npy',\n",
        " 'greedy 100 trees_192.npy',\n",
        " 'greedy 100 trees_193.npy',\n",
        " 'greedy 100 trees_194.npy',\n",
        " 'greedy 100 trees_195.npy',\n",
        " 'greedy 100 trees_196.npy',\n",
        " 'greedy 100 trees_197.npy',\n",
        " 'greedy 100 trees_198.npy',\n",
        " 'greedy 100 trees_199.npy',\n",
        " 'greedy 100 trees_200.npy',\n",
        " 'greedy 100 trees_201.npy',\n",
        " 'greedy 100 trees_202.npy',\n",
        " 'greedy 100 trees_203.npy',\n",
        " 'greedy 100 trees_204.npy',\n",
        " 'greedy 100 trees_205.npy',\n",
        " 'greedy 100 trees_206.npy',\n",
        " 'greedy 100 trees_207.npy',\n",
        " 'greedy 100 trees_208.npy',\n",
        " 'greedy 100 trees_209.npy',\n",
        " 'greedy 100 trees_210.npy',\n",
        " 'greedy 100 trees_211.npy',\n",
        " 'greedy 100 trees_212.npy',\n",
        " 'greedy 100 trees_213.npy',\n",
        " 'greedy 100 trees_214.npy',\n",
        " 'greedy 100 trees_215.npy',\n",
        " 'greedy 100 trees_216.npy',\n",
        " 'greedy 100 trees_217.npy',\n",
        " 'greedy 100 trees_218.npy',\n",
        " 'greedy 100 trees_219.npy',\n",
        " 'greedy 100 trees_220.npy',\n",
        " 'greedy 100 trees_221.npy',\n",
        " 'greedy 100 trees_222.npy',\n",
        " 'greedy 100 trees_223.npy',\n",
        " 'greedy 100 trees_224.npy',\n",
        " 'greedy 100 trees_225.npy',\n",
        " 'greedy 100 trees_226.npy',\n",
        " 'greedy 100 trees_227.npy',\n",
        " 'greedy 100 trees_228.npy',\n",
        " 'greedy 100 trees_229.npy',\n",
        " 'greedy 100 trees_230.npy',\n",
        " 'greedy 100 trees_231.npy',\n",
        " 'greedy 100 trees_232.npy',\n",
        " 'greedy 100 trees_233.npy',\n",
        " 'greedy 100 trees_234.npy',\n",
        " 'greedy 100 trees_235.npy',\n",
        " 'greedy 100 trees_236.npy',\n",
        " 'greedy 100 trees_237.npy',\n",
        " 'greedy 100 trees_238.npy',\n",
        " 'greedy 100 trees_239.npy',\n",
        " 'greedy 100 trees_240.npy',\n",
        " 'greedy 100 trees_241.npy',\n",
        " 'greedy 100 trees_242.npy',\n",
        " 'greedy 100 trees_243.npy',\n",
        " 'greedy 100 trees_244.npy',\n",
        " 'greedy 100 trees_245.npy',\n",
        " 'greedy 100 trees_246.npy',\n",
        " 'greedy 100 trees_247.npy',\n",
        " 'greedy 100 trees_248.npy',\n",
        " 'greedy 100 trees_249.npy',\n",
        " 'greedy 100 trees_250.npy',\n",
        " 'greedy 100 trees_251.npy',\n",
        " 'greedy 100 trees_252.npy',\n",
        " 'greedy 100 trees_253.npy',\n",
        " 'greedy 100 trees_254.npy',\n",
        " 'greedy 100 trees_255.npy',\n",
        " 'greedy 100 trees_256.npy',\n",
        " 'greedy 100 trees_257.npy',\n",
        " 'greedy 100 trees_258.npy',\n",
        " 'greedy 100 trees_259.npy',\n",
        " 'greedy 100 trees_260.npy',\n",
        " 'greedy 100 trees_261.npy',\n",
        " 'greedy 100 trees_262.npy',\n",
        " 'greedy 100 trees_263.npy',\n",
        " 'greedy 100 trees_264.npy',\n",
        " 'greedy 100 trees_265.npy',\n",
        " 'greedy 100 trees_266.npy',\n",
        " 'greedy 100 trees_267.npy',\n",
        " 'greedy 100 trees_268.npy',\n",
        " 'greedy 100 trees_269.npy',\n",
        " 'greedy 100 trees_270.npy',\n",
        " 'greedy 100 trees_271.npy',\n",
        " 'greedy 100 trees_272.npy',\n",
        " 'greedy 100 trees_273.npy',\n",
        " 'greedy 100 trees_274.npy',\n",
        " 'greedy 100 trees_275.npy',\n",
        " 'greedy 100 trees_276.npy',\n",
        " 'greedy 100 trees_277.npy',\n",
        " 'greedy 100 trees_278.npy',\n",
        " 'greedy 100 trees_279.npy',\n",
        " 'greedy 100 trees_280.npy',\n",
        " 'greedy 100 trees_281.npy',\n",
        " 'greedy 100 trees_282.npy',\n",
        " 'greedy 100 trees_283.npy',\n",
        " 'greedy 100 trees_284.npy',\n",
        " 'greedy 100 trees_285.npy',\n",
        " 'greedy 100 trees_286.npy',\n",
        " 'greedy 100 trees_287.npy',\n",
        " 'greedy 100 trees_288.npy',\n",
        " 'greedy 100 trees_289.npy',\n",
        " 'greedy 100 trees_290.npy',\n",
        " 'greedy 100 trees_291.npy',\n",
        " 'greedy 100 trees_292.npy',\n",
        " 'greedy 100 trees_293.npy',\n",
        " 'greedy 100 trees_294.npy',\n",
        " 'greedy 100 trees_295.npy',\n",
        " 'greedy 100 trees_296.npy',\n",
        " 'greedy 100 trees_297.npy',\n",
        " 'greedy 100 trees_298.npy',\n",
        " 'greedy 100 trees_299.npy',\n",
        " 'greedy 100 trees_300.npy']"
       ]
      }
     ],
     "prompt_number": 191
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The roc curves are at the bottom"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Upper level thresholds extraction"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#thresholds extraction\n",
      "cuts = lambda feature: reduce(np.append,[tree[1][tree[0] == feature] for tree in  trees])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 204
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_inclusion(feature,tolerance=0.):\n",
      "    \"\"\"\n",
      "    Get the inclusion counts of thresholds\n",
      "    \"\"\"\n",
      "    thresholds = cuts(feature)\n",
      "    tolerance *= np.var(thresholds)\n",
      "    thrs = { threshold: len(filter(\n",
      "                                lambda thr: abs(thr - threshold) <= tolerance,\n",
      "                                thresholds)\n",
      "                           )\n",
      "            for threshold in set(thresholds)}\n",
      "    return thrs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 205
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "best = {i:get_inclusion(i,0.001) for i in range(30)}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 194
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#usability distribution\n",
      "thresholds = reduce(np.append,[zip(np.repeat(i,len(best[i])),best[i].keys(),best[i].values()) for i in best])\n",
      "thresholds = thresholds.reshape(thresholds.shape[0]/3,3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 195
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.scatter(range(len(thresholds)),thresholds[:,2])\n",
      "print sum(thresholds[:,2] >150)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "96\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEACAYAAAC3adEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKEoMVQyKoihKjP8fJ1hkB2V48tkAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x1947d0b8>"
       ]
      }
     ],
     "prompt_number": 196
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Criteria selection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def entropy(distribution):\n",
      "    \"\"\"just some entropy\"\"\"\n",
      "    logs = np.array(map(np.log,distribution))\n",
      "    logs[distribution ==0] = 0\n",
      "    return -sum(distribution*logs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 197
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def select_criteria(factory, thresholds_active,depth,verbose = True):\n",
      "    \"\"\"\n",
      "    I find the most _even_ dichotomies of a given depth among the given thresholds... greedily\n",
      "    \"\"\"\n",
      "    leaves = {\"\":factory}\n",
      "    criteria = []\n",
      "\n",
      "    for i in range(depth):\n",
      "        entropies = []\n",
      "        for feature,cut,_ in thresholds_active:\n",
      "            split_distribution = []\n",
      "            for leaf in leaves:\n",
      "                subFactory = leaves[leaf]\n",
      "                predicate = (subFactory.events[:,feature] > cut)\n",
      "                trues = sum(subFactory.weights[predicate])\n",
      "                \n",
      "                split_distribution.append(trues)\n",
      "                split_distribution.append(sum(subFactory.weights) - trues)\n",
      "                \n",
      "            split_distribution = np.array(split_distribution)/sum(factory.weights)\n",
      "            entropies.append( entropy(split_distribution))\n",
      "\n",
      "        feature,cut,_ = criterion = thresholds_active[entropies.index(max(entropies))]\n",
      "        new_leaves = {}\n",
      "        for leaf in leaves:\n",
      "            subFactory = leaves[leaf]\n",
      "            predicate = (subFactory.events[:,feature] > cut)\n",
      "            new_leaves[leaf+\"1\"],new_leaves[leaf+\"0\"] = subFactory.split_by(predicate)\n",
      "\n",
      "        leaves = new_leaves    \n",
      "        criteria.append(criterion)\n",
      "        if verbose:\n",
      "            print 's:',[leaves[i].events.shape[0] for i in leaves]\n",
      "            print 'w:',[sum(leaves[i].weights) for i in leaves]\n",
      "    return criteria"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 208
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get them...\n",
      "thresholds_active = thresholds[thresholds[:,2]>100]\n",
      "print len(thresholds_active)\n",
      "sFactory= DataFactory(Xts,Yts,np.ones(len(Yts)))\n",
      "criteria = select_criteria(sFactory,thresholds_active,3,True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "190\n",
        "s:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [60644L, 61856L]\n",
        "w: [60644.0, 61856.0]\n",
        "s:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [26927L, 33717L, 25494L, 36362L]\n",
        "w: [26927.0, 33717.0, 25494.0, 36362.0]\n",
        "s:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [25875L, 10487L, 12550L, 12944L, 10371L, 16556L, 17256L, 16461L]\n",
        "w: [25875.0, 10487.0, 12550.0, 12944.0, 10371.0, 16556.0, 17256.0, 16461.0]\n"
       ]
      }
     ],
     "prompt_number": 271
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "criteria"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 210,
       "text": [
        "[array([  13.        ,   26.71350098,  124.        ]),\n",
        " array([   7.        ,    2.72149992,  121.        ]),\n",
        " array([   8.        ,    4.71249962,  158.        ])]"
       ]
      }
     ],
     "prompt_number": 210
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def split_upper(factory,criteria,returnIndices = False):\n",
      "    \"\"\"\n",
      "    I split the data into the leaves of the upper level ODT given it's criterea\n",
      "    \"\"\"\n",
      "    split = {'':factory}\n",
      "    indices = {'':np.arange(factory.n_events)}\n",
      "    for criterion in criteria:\n",
      "        feature,cut,_= criterion\n",
      "        split_new = {}\n",
      "        indices_new = {}\n",
      "        for splt in split:\n",
      "            dichotomy = split[splt].features[:,feature][:split[splt].n_events]> cut\n",
      "            split_new[splt+'1'],split_new[splt+'0'] = split[splt].split_by(dichotomy)\n",
      "            if returnIndices:\n",
      "                indices_new[splt+'1'] = indices[splt][dichotomy]\n",
      "                indices_new[splt+'0'] = indices[splt][dichotomy == False]\n",
      "        split = split_new\n",
      "        indices = indices_new\n",
      "    return ((split, indices ) if returnIndices else split)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 246
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "split = split_upper(trainFactory,criteria)\n",
      "print [split[i].events.shape[0] for i in split]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[7034L, 10630L, 16105L, 9247L, 19240L, 12781L, 16723L, 35740L]\n"
       ]
      }
     ],
     "prompt_number": 247
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def train_splitted_boosts( trees,\n",
      "                           factory,\n",
      "                           criteria,\n",
      "                           loss,\n",
      "                           learning_rate,\n",
      "                           breadth,\n",
      "                           nTrees_leaf,\n",
      "                           trees_sample_size,\n",
      "                           verbose = True,\n",
      "                           learning_rate_decay = 1.,\n",
      "                           trees_sample_increase = 0):\n",
      "    \"\"\"\n",
      "    make greedy prune for every leaf in split\n",
      "    \"\"\"\n",
      "    factories = split_upper(trainFactory,criteria)\n",
      "    leaves = factories.keys()\n",
      "    \n",
      "    classis = []\n",
      "    itr = 1\n",
      "    for leaf in leaves:\n",
      "        if verbose:\n",
      "            print \"\\n\\nNow training leaf \",leaf, itr,\"/\",len(leaves)\n",
      "            print \"n_ samples at leaf = \", factories[leaf].n_events\n",
      "            itr +=1\n",
      "        classis.append(greed_up_features_bfs(\n",
      "                           trees,\n",
      "                           factories[leaf],\n",
      "                           loss,\n",
      "                           learning_rate,\n",
      "                           breadth,\n",
      "                           nTrees_leaf,\n",
      "                           trees_sample_size,\n",
      "                           verbose,\n",
      "                           learning_rate_decay,\n",
      "                           trees_sample_increase\n",
      "                           ))\n",
      "    #same stuff in JL\n",
      "    #tasks = [joblib.delayed(\n",
      "    #                       trees,\n",
      "    #                       factories[leaf],\n",
      "    #                       loss,\n",
      "    #                       learning_rate,\n",
      "    #                       breadth,\n",
      "    #                       nTrees_leaf,\n",
      "    #                       trees_sample_size,\n",
      "    #                       verbose,\n",
      "    #                       learning_rate_decay,\n",
      "    #                       trees_sample_increase\n",
      "    #                       )for leaf in leaves]\n",
      "    #classis = joblib.Parallel(n_jobs = -1)(tasks)\n",
      "\n",
      "    return {leaves[i]:classis[i] for i in range(len(leaves))}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 237
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trees_splitted = train_splitted_boosts(trees, trainFactory,criteria[:2],LogLoss,0.1,1,100,500,True,0.99)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def predict_splitted(factory,criteria,trees):\n",
      "    factories, indices =  split_upper(factory,criteria,True)\n",
      "    y_pred = np.zeros(factory.n_events)\n",
      "    for leaf in factories.keys():\n",
      "        y_pred[indices[leaf]] = factories[leaf].predict(trees[leaf])\n",
      "    return y_pred"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 279
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_pred_splitted = predict_splitted(testFactory,criteria[:2],trees_splitted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 282
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(y_pred_splitted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 283,
       "text": [
        "(array([  1.18193000e+05,   2.51600000e+03,   1.12300000e+03,\n",
        "          1.76000000e+02,   3.73000000e+02,   6.00000000e+01,\n",
        "          4.00000000e+01,   9.00000000e+00,   9.00000000e+00,\n",
        "          1.00000000e+00]),\n",
        " array([-1.47748852, -1.2769949 , -1.07650128, -0.87600765, -0.67551403,\n",
        "        -0.47502041, -0.27452679, -0.07403317,  0.12646045,  0.32695407,\n",
        "         0.52744769]),\n",
        " <a list of 10 Patch objects>)"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEACAYAAACgS0HpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x2987d278>"
       ]
      }
     ],
     "prompt_number": 283
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print metrics.roc_auc_score(testFactory.labels,y_pred_splitted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.923137623013\n"
       ]
      }
     ],
     "prompt_number": 287
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot ROC curve\n",
      "plt.figure()\n",
      "fpr, tpr, _ = metrics.roc_curve(Yts, y_pred_full,sample_weight=testFactory.weights)\n",
      "plt.plot(fpr, tpr,\n",
      "         label='Full boost classi 10k trees')\n",
      "fpr, tpr, _ = metrics.roc_curve(Yts, y_pred_stupid,sample_weight=testFactory.weights)\n",
      "plt.plot(fpr, tpr,\n",
      "         label='First 100 classi')\n",
      "fpr, tpr, _ = metrics.roc_curve(Yts, y_pred_greedy,sample_weight=testFactory.weights)\n",
      "plt.plot(fpr, tpr,\n",
      "         label='Greedy prune classi 100 trees')\n",
      "fpr, tpr, _ = metrics.roc_curve(Yts, y_pred_splitted,sample_weight=testFactory.weights)\n",
      "#plt.plot(fpr, tpr,\n",
      "#         label='Split-prune classi with 8 leafs')\n",
      "\n",
      "\n",
      "plt.plot([0, 1], [0, 1], 'k--')\n",
      "plt.xlim([0.0, 1.0])\n",
      "plt.ylim([0.0, 1.05])\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
      "plt.legend(loc=\"lower right\")\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAEZCAYAAABICyhRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxvOeAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x22c10390>"
       ]
      }
     ],
     "prompt_number": 289
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "joblib.dump([criteria,trees_splitted],\"splitted 100 trees\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 65,
       "text": [
        "['splitted 100 trees',\n",
        " 'splitted 100 trees_01.npy',\n",
        " 'splitted 100 trees_02.npy',\n",
        " 'splitted 100 trees_03.npy',\n",
        " 'splitted 100 trees_04.npy',\n",
        " 'splitted 100 trees_05.npy',\n",
        " 'splitted 100 trees_06.npy',\n",
        " 'splitted 100 trees_07.npy',\n",
        " 'splitted 100 trees_08.npy',\n",
        " 'splitted 100 trees_09.npy',\n",
        " 'splitted 100 trees_10.npy',\n",
        " 'splitted 100 trees_11.npy',\n",
        " 'splitted 100 trees_12.npy',\n",
        " 'splitted 100 trees_13.npy',\n",
        " 'splitted 100 trees_14.npy',\n",
        " 'splitted 100 trees_15.npy',\n",
        " 'splitted 100 trees_16.npy',\n",
        " 'splitted 100 trees_17.npy',\n",
        " 'splitted 100 trees_18.npy',\n",
        " 'splitted 100 trees_19.npy',\n",
        " 'splitted 100 trees_20.npy',\n",
        " 'splitted 100 trees_21.npy',\n",
        " 'splitted 100 trees_22.npy',\n",
        " 'splitted 100 trees_23.npy',\n",
        " 'splitted 100 trees_24.npy',\n",
        " 'splitted 100 trees_25.npy',\n",
        " 'splitted 100 trees_26.npy',\n",
        " 'splitted 100 trees_27.npy',\n",
        " 'splitted 100 trees_28.npy',\n",
        " 'splitted 100 trees_29.npy',\n",
        " 'splitted 100 trees_30.npy',\n",
        " 'splitted 100 trees_31.npy',\n",
        " 'splitted 100 trees_32.npy',\n",
        " 'splitted 100 trees_33.npy',\n",
        " 'splitted 100 trees_34.npy',\n",
        " 'splitted 100 trees_35.npy',\n",
        " 'splitted 100 trees_36.npy',\n",
        " 'splitted 100 trees_37.npy',\n",
        " 'splitted 100 trees_38.npy',\n",
        " 'splitted 100 trees_39.npy',\n",
        " 'splitted 100 trees_40.npy',\n",
        " 'splitted 100 trees_41.npy',\n",
        " 'splitted 100 trees_42.npy',\n",
        " 'splitted 100 trees_43.npy',\n",
        " 'splitted 100 trees_44.npy',\n",
        " 'splitted 100 trees_45.npy',\n",
        " 'splitted 100 trees_46.npy',\n",
        " 'splitted 100 trees_47.npy',\n",
        " 'splitted 100 trees_48.npy',\n",
        " 'splitted 100 trees_49.npy',\n",
        " 'splitted 100 trees_50.npy',\n",
        " 'splitted 100 trees_51.npy',\n",
        " 'splitted 100 trees_52.npy',\n",
        " 'splitted 100 trees_53.npy',\n",
        " 'splitted 100 trees_54.npy',\n",
        " 'splitted 100 trees_55.npy',\n",
        " 'splitted 100 trees_56.npy',\n",
        " 'splitted 100 trees_57.npy',\n",
        " 'splitted 100 trees_58.npy',\n",
        " 'splitted 100 trees_59.npy',\n",
        " 'splitted 100 trees_60.npy',\n",
        " 'splitted 100 trees_61.npy',\n",
        " 'splitted 100 trees_62.npy',\n",
        " 'splitted 100 trees_63.npy',\n",
        " 'splitted 100 trees_64.npy',\n",
        " 'splitted 100 trees_65.npy',\n",
        " 'splitted 100 trees_66.npy',\n",
        " 'splitted 100 trees_67.npy',\n",
        " 'splitted 100 trees_68.npy',\n",
        " 'splitted 100 trees_69.npy',\n",
        " 'splitted 100 trees_70.npy',\n",
        " 'splitted 100 trees_71.npy',\n",
        " 'splitted 100 trees_72.npy',\n",
        " 'splitted 100 trees_73.npy',\n",
        " 'splitted 100 trees_74.npy',\n",
        " 'splitted 100 trees_75.npy',\n",
        " 'splitted 100 trees_76.npy',\n",
        " 'splitted 100 trees_77.npy',\n",
        " 'splitted 100 trees_78.npy',\n",
        " 'splitted 100 trees_79.npy',\n",
        " 'splitted 100 trees_80.npy',\n",
        " 'splitted 100 trees_81.npy',\n",
        " 'splitted 100 trees_82.npy',\n",
        " 'splitted 100 trees_83.npy',\n",
        " 'splitted 100 trees_84.npy',\n",
        " 'splitted 100 trees_85.npy',\n",
        " 'splitted 100 trees_86.npy',\n",
        " 'splitted 100 trees_87.npy',\n",
        " 'splitted 100 trees_88.npy',\n",
        " 'splitted 100 trees_89.npy',\n",
        " 'splitted 100 trees_90.npy',\n",
        " 'splitted 100 trees_91.npy',\n",
        " 'splitted 100 trees_92.npy',\n",
        " 'splitted 100 trees_93.npy',\n",
        " 'splitted 100 trees_94.npy',\n",
        " 'splitted 100 trees_95.npy',\n",
        " 'splitted 100 trees_96.npy',\n",
        " 'splitted 100 trees_97.npy',\n",
        " 'splitted 100 trees_98.npy',\n",
        " 'splitted 100 trees_99.npy',\n",
        " 'splitted 100 trees_100.npy',\n",
        " 'splitted 100 trees_101.npy',\n",
        " 'splitted 100 trees_102.npy',\n",
        " 'splitted 100 trees_103.npy',\n",
        " 'splitted 100 trees_104.npy',\n",
        " 'splitted 100 trees_105.npy',\n",
        " 'splitted 100 trees_106.npy',\n",
        " 'splitted 100 trees_107.npy',\n",
        " 'splitted 100 trees_108.npy',\n",
        " 'splitted 100 trees_109.npy',\n",
        " 'splitted 100 trees_110.npy',\n",
        " 'splitted 100 trees_111.npy',\n",
        " 'splitted 100 trees_112.npy',\n",
        " 'splitted 100 trees_113.npy',\n",
        " 'splitted 100 trees_114.npy',\n",
        " 'splitted 100 trees_115.npy',\n",
        " 'splitted 100 trees_116.npy',\n",
        " 'splitted 100 trees_117.npy',\n",
        " 'splitted 100 trees_118.npy',\n",
        " 'splitted 100 trees_119.npy',\n",
        " 'splitted 100 trees_120.npy',\n",
        " 'splitted 100 trees_121.npy',\n",
        " 'splitted 100 trees_122.npy',\n",
        " 'splitted 100 trees_123.npy',\n",
        " 'splitted 100 trees_124.npy',\n",
        " 'splitted 100 trees_125.npy',\n",
        " 'splitted 100 trees_126.npy',\n",
        " 'splitted 100 trees_127.npy',\n",
        " 'splitted 100 trees_128.npy',\n",
        " 'splitted 100 trees_129.npy',\n",
        " 'splitted 100 trees_130.npy',\n",
        " 'splitted 100 trees_131.npy',\n",
        " 'splitted 100 trees_132.npy',\n",
        " 'splitted 100 trees_133.npy',\n",
        " 'splitted 100 trees_134.npy',\n",
        " 'splitted 100 trees_135.npy',\n",
        " 'splitted 100 trees_136.npy',\n",
        " 'splitted 100 trees_137.npy',\n",
        " 'splitted 100 trees_138.npy',\n",
        " 'splitted 100 trees_139.npy',\n",
        " 'splitted 100 trees_140.npy',\n",
        " 'splitted 100 trees_141.npy',\n",
        " 'splitted 100 trees_142.npy',\n",
        " 'splitted 100 trees_143.npy',\n",
        " 'splitted 100 trees_144.npy',\n",
        " 'splitted 100 trees_145.npy',\n",
        " 'splitted 100 trees_146.npy',\n",
        " 'splitted 100 trees_147.npy',\n",
        " 'splitted 100 trees_148.npy',\n",
        " 'splitted 100 trees_149.npy',\n",
        " 'splitted 100 trees_150.npy',\n",
        " 'splitted 100 trees_151.npy',\n",
        " 'splitted 100 trees_152.npy',\n",
        " 'splitted 100 trees_153.npy',\n",
        " 'splitted 100 trees_154.npy',\n",
        " 'splitted 100 trees_155.npy',\n",
        " 'splitted 100 trees_156.npy',\n",
        " 'splitted 100 trees_157.npy',\n",
        " 'splitted 100 trees_158.npy',\n",
        " 'splitted 100 trees_159.npy',\n",
        " 'splitted 100 trees_160.npy',\n",
        " 'splitted 100 trees_161.npy',\n",
        " 'splitted 100 trees_162.npy',\n",
        " 'splitted 100 trees_163.npy',\n",
        " 'splitted 100 trees_164.npy',\n",
        " 'splitted 100 trees_165.npy',\n",
        " 'splitted 100 trees_166.npy',\n",
        " 'splitted 100 trees_167.npy',\n",
        " 'splitted 100 trees_168.npy',\n",
        " 'splitted 100 trees_169.npy',\n",
        " 'splitted 100 trees_170.npy',\n",
        " 'splitted 100 trees_171.npy',\n",
        " 'splitted 100 trees_172.npy',\n",
        " 'splitted 100 trees_173.npy',\n",
        " 'splitted 100 trees_174.npy',\n",
        " 'splitted 100 trees_175.npy',\n",
        " 'splitted 100 trees_176.npy',\n",
        " 'splitted 100 trees_177.npy',\n",
        " 'splitted 100 trees_178.npy',\n",
        " 'splitted 100 trees_179.npy',\n",
        " 'splitted 100 trees_180.npy',\n",
        " 'splitted 100 trees_181.npy',\n",
        " 'splitted 100 trees_182.npy',\n",
        " 'splitted 100 trees_183.npy',\n",
        " 'splitted 100 trees_184.npy',\n",
        " 'splitted 100 trees_185.npy',\n",
        " 'splitted 100 trees_186.npy',\n",
        " 'splitted 100 trees_187.npy',\n",
        " 'splitted 100 trees_188.npy',\n",
        " 'splitted 100 trees_189.npy',\n",
        " 'splitted 100 trees_190.npy',\n",
        " 'splitted 100 trees_191.npy',\n",
        " 'splitted 100 trees_192.npy',\n",
        " 'splitted 100 trees_193.npy',\n",
        " 'splitted 100 trees_194.npy',\n",
        " 'splitted 100 trees_195.npy',\n",
        " 'splitted 100 trees_196.npy',\n",
        " 'splitted 100 trees_197.npy',\n",
        " 'splitted 100 trees_198.npy',\n",
        " 'splitted 100 trees_199.npy',\n",
        " 'splitted 100 trees_200.npy',\n",
        " 'splitted 100 trees_201.npy',\n",
        " 'splitted 100 trees_202.npy',\n",
        " 'splitted 100 trees_203.npy',\n",
        " 'splitted 100 trees_204.npy',\n",
        " 'splitted 100 trees_205.npy',\n",
        " 'splitted 100 trees_206.npy',\n",
        " 'splitted 100 trees_207.npy',\n",
        " 'splitted 100 trees_208.npy',\n",
        " 'splitted 100 trees_209.npy',\n",
        " 'splitted 100 trees_210.npy',\n",
        " 'splitted 100 trees_211.npy',\n",
        " 'splitted 100 trees_212.npy',\n",
        " 'splitted 100 trees_213.npy',\n",
        " 'splitted 100 trees_214.npy',\n",
        " 'splitted 100 trees_215.npy',\n",
        " 'splitted 100 trees_216.npy',\n",
        " 'splitted 100 trees_217.npy',\n",
        " 'splitted 100 trees_218.npy',\n",
        " 'splitted 100 trees_219.npy',\n",
        " 'splitted 100 trees_220.npy',\n",
        " 'splitted 100 trees_221.npy',\n",
        " 'splitted 100 trees_222.npy',\n",
        " 'splitted 100 trees_223.npy',\n",
        " 'splitted 100 trees_224.npy',\n",
        " 'splitted 100 trees_225.npy',\n",
        " 'splitted 100 trees_226.npy',\n",
        " 'splitted 100 trees_227.npy',\n",
        " 'splitted 100 trees_228.npy',\n",
        " 'splitted 100 trees_229.npy',\n",
        " 'splitted 100 trees_230.npy',\n",
        " 'splitted 100 trees_231.npy',\n",
        " 'splitted 100 trees_232.npy',\n",
        " 'splitted 100 trees_233.npy',\n",
        " 'splitted 100 trees_234.npy',\n",
        " 'splitted 100 trees_235.npy',\n",
        " 'splitted 100 trees_236.npy',\n",
        " 'splitted 100 trees_237.npy',\n",
        " 'splitted 100 trees_238.npy',\n",
        " 'splitted 100 trees_239.npy',\n",
        " 'splitted 100 trees_240.npy',\n",
        " 'splitted 100 trees_241.npy',\n",
        " 'splitted 100 trees_242.npy',\n",
        " 'splitted 100 trees_243.npy']"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}