{
 "metadata": {
  "name": "",
  "signature": "sha256:93d3a4053ce633c7ceba42089fda9581ed96c6ba11c154ac0de8fa181a5dd8df"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# I explore the cuts of the features\n",
      "%matplotlib inline\n",
      "#\u0442\u0430\u043a \u0442\u043e\u0436\u0435 \u043c\u043e\u0436\u043d\u043e \u0440\u0435\u0448\u0438\u0442\u044c \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u0443 \u0438\u043d\u043b\u0430\u0439\u043b\u0430 \u043f\u043b\u043e\u0442\u043e\u0432\n",
      "\n",
      "import _matrixnetapplier as mnet\n",
      "import numpy as numpy\n",
      "np = numpy\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.patches as mpatches\n",
      "from sklearn import metrics"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Extracting the trained model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#extract ODT\n",
      "fstream = open('formula.mx','rb')\n",
      "classi = mnet.MatrixnetClassifier(fstream)\n",
      "fstream.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Get all the trees from .mx\n",
      "def get_trees(classi):\n",
      "    itr = classi.iterate_trees().next()\n",
      "    return itr, [tree for tree in itr[2]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "itr,trees = get_trees(classi)\n",
      "n_features = len(classi.features)\n",
      "print itr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(6, 10000, <generator object _iterate_over_trees_with_fixed_depth at 0x000000000ACD3B88>)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Loading dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#load training set\n",
      "def load_data(path):\n",
      "    print 'Loading training data.'\n",
      "    data = np.loadtxt(path, \\\n",
      "            delimiter=',', \\\n",
      "            skiprows=1, \\\n",
      "            converters={32: lambda x:int(x=='s'.encode('utf-8'))})\n",
      "\n",
      "    X = data[:,1:31]\n",
      "    Y = data[:,32]\n",
      "    W = data[:,31]\n",
      "    return X,Y,W"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X,Y,W = load_data(\"../data/training.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading training data.\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "Xtr,Xts,Ytr,Yts,Wtr,Wts = train_test_split(X,Y,W, test_size = 0.2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# greedy pruning for the whole data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#in the ideal world, i would have merged em with the top line imports, but luckily, i'm in real world\n",
      "import copy\n",
      "import sklearn.metrics as metrics\n",
      "import scipy as sp\n",
      "import random\n",
      "#and some of these...\n",
      "import math\n",
      "import pandas as pd\n",
      "from sklearn.externals import joblib\n",
      "steve = joblib\n",
      "from sklearn.cross_validation import *\n",
      "from sklearn.decomposition import *\n",
      "from sklearn.ensemble import *\n",
      "from sklearn.feature_selection import *\n",
      "from sklearn.grid_search import *\n",
      "from sklearn.linear_model import *\n",
      "from sklearn.metrics import *\n",
      "from sklearn.preprocessing import *\n",
      "from sklearn.pipeline import *\n",
      "from sklearn.svm import *\n",
      "from sklearn.tree import *\n",
      "from sklearn.ensemble.gradient_boosting import *\n",
      "from sklearn.utils import check_arrays\n",
      "from sklearn.ensemble._gradient_boosting import predict_stages\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#predict with the trees boost\n",
      "def predict(trees, X):\n",
      "    '''\n",
      "    make real-value predictions using sklearn gradient_boosting.predict_stages\n",
      "    '''\n",
      "    if len(trees) ==0:\n",
      "        return np.zeros(X.shape[0])\n",
      "    #i don't think that i can write as effectively with my time bounds. Copypaste\n",
      "    def apply_separately(events,bias = 0):\n",
      "        \"\"\"\n",
      "        :param events: numpy.array (or DataFrame) of shape [n_samples, n_features]\n",
      "        :return: each time yields numpy.array predictions of shape [n_samples]\n",
      "            which is output of a particular tree\n",
      "        \"\"\"\n",
      "        # result of first iteration\n",
      "        yield numpy.zeros(len(events), dtype=float) + bias\n",
      "\n",
      "        # extending the data so the number of events is divisible by 8\n",
      "        n_events = len(events)\n",
      "        n_extended64 = (n_events + 7) // 8\n",
      "        n_extended = n_extended64 * 8\n",
      "\n",
      "        # using Fortran order (surprisingly doesn't seem to influence speed much)\n",
      "        features = numpy.zeros([n_extended, events.shape[1]], dtype='float32', order='F')\n",
      "        features[:n_events, :] = events\n",
      "\n",
      "        tree_depth = len(trees[0][0])\n",
      "        nf_count = len(trees)\n",
      "        for tree_features, tree_cuts, leaf_values in trees:\n",
      "            leaf_indices = numpy.zeros(n_extended64, dtype='int64')\n",
      "            for tree_level, (feature, cut) in enumerate(zip(tree_features, tree_cuts)):\n",
      "                leaf_indices |= (features[:, feature] > cut).view('int64') << tree_level\n",
      "            yield leaf_values[leaf_indices.view('int8')[:n_events]]\n",
      "    \n",
      "    \n",
      "    events = X\n",
      "    result = numpy.zeros(len(events), dtype=float)\n",
      "    for stage_predictions in apply_separately(events):\n",
      "        result += stage_predictions\n",
      "    return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def logloss(actual, pred):\n",
      "    \"\"\"\n",
      "    i know it isn't\n",
      "    \"\"\"\n",
      "    return actual - sp.special.expit(pred.reshape(pred.shape[0]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def update_leaves(X,residual,tree,lrate):\n",
      "    '''\n",
      "    update leaf values via... placing the residual there...\n",
      "    '''\n",
      "    \n",
      "    events = X\n",
      "    tree_features, tree_cuts, leaf_values = tree\n",
      "    tree_depth = len(tree[0])\n",
      "    n_events = len(events)\n",
      "    n_extended64 = (n_events + 7) // 8\n",
      "    n_extended = n_extended64 * 8\n",
      "    \n",
      "    # using Fortran order (surprisingly doesn't seem to influence speed much)\n",
      "    features = numpy.zeros([n_extended, events.shape[1]], dtype='float32', order='F')\n",
      "    features[:n_events, :] = events\n",
      "    \n",
      "    leaf_indices = numpy.zeros(n_extended64, dtype='int64')\n",
      "    for tree_level, (feature, cut) in enumerate(zip(tree_features, tree_cuts)):\n",
      "        leaf_indices |= (features[:, feature] > cut).view('int64') << tree_level\n",
      "    \n",
      "    \n",
      "    leaf_values = tree[2]*0\n",
      "    \n",
      "    leaf_indices =leaf_indices.view('int8')[:n_events]\n",
      "\n",
      "    \n",
      "    \n",
      "    for i in xrange(leaf_indices.shape[0]):\n",
      "        leaf_ind = leaf_indices[i]\n",
      "        leaf_values[leaf_ind] += residual[i]\n",
      "    \n",
      "    #alarma! i aint entirely mathematical\n",
      "    leaf_values /= X.shape[0]\n",
      "    \n",
      "    newtree = tuple([copy.copy(i) for i in tree[:2]] + [leaf_values*lrate])\n",
      "\n",
      "    return newtree"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def inthread_try_add(bunchMembers,tree,loss,X,residual,y,y_pred,learning_rate):\n",
      "        newTree = update_leaves(X,residual,tree,learning_rate)\n",
      "        newPred = y_pred + predict([newTree],X).reshape(y_pred.shape)\n",
      "        return sum(abs(loss(y,newPred)))/y.shape[0],newTree\n",
      "#mb use sklearn metrics-compatible lossfun?\n",
      "\n",
      "def try_add1_bfs(bunchMembers, remainingTrees,X,y,learning_rate,loss,breadth):\n",
      "    '''\n",
      "    select best tree to add (1 step)\n",
      "    '''\n",
      "    X = array2d(X, dtype=DTYPE, order=\"C\")\n",
      "\n",
      "    y_pred = predict(bunchMembers,X).reshape(len(y),1)\n",
      "    \n",
      "\n",
      "    residual = loss(y,y_pred)\n",
      "    \n",
      "    pairs = [\n",
      "                    inthread_try_add(bunchMembers,remainingTrees[t],loss,X,residual,y,y_pred,learning_rate)\n",
      "                    for t in xrange(remainingTrees.shape[0])]   \n",
      "   \n",
      "    pairs.sort(key = lambda el: el[0])\n",
      "    \n",
      "    bunches = []\n",
      "    for pair in pairs[:breadth]:\n",
      "        tree = pair[1]\n",
      "        bunch = bunchMembers+[tree]\n",
      "        bunches.append(bunch)\n",
      "\n",
      "    return bunches,[pair[1] for pair in pairs[:breadth]],[pair[0] for pair in pairs[:breadth]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def greed_up_features_bfs (trees,\n",
      "                           X,y,\n",
      "                           learning_rate,\n",
      "                           loss,\n",
      "                           breadth,\n",
      "                           nTrees,\n",
      "                           trees_sample_size,\n",
      "                           verbose = True,\n",
      "                           learning_rate_decay = 1.,\n",
      "                           trees_sample_increase = 0):\n",
      "    \"\"\"\n",
      "    Iterative BFS over best ADD-1 results for [nTrees] iterations\n",
      "    \"\"\"\n",
      "    #compatibility stuff\n",
      "    if 0 not in y:\n",
      "        return (key,1)\n",
      "    if 1 not in y:\n",
      "        return (key,0)\n",
      "    alltrees = copy.copy(trees)\n",
      "    \n",
      "    trees_sample = np.array(random.sample(alltrees,trees_sample_size))\n",
      "    bunches,additions,losses = try_add1_bfs([],trees_sample,X,y,learning_rate,loss,breadth)\n",
      "    \n",
      "    bestScore = min(losses)\n",
      "    \n",
      "    if verbose:\n",
      "        print \"\\niteration #\",0,\" ntrees = \", len(bunches[0]),\"\\nbest loss = \",bestScore\n",
      "        print \"learning_rate = \", learning_rate\n",
      "        print \"sample_size\", trees_sample_size\n",
      "\n",
      "    \n",
      "    itr = 0\n",
      "    while len(bunches[0]) <nTrees:\n",
      "        itr+=1\n",
      "        newBunches = []    \n",
      "        newScores = []\n",
      "        #for shared memo:\n",
      "        #triples = steve.Parallel(njobs = nthreads)(\n",
      "        #        steve.delayed([try_add1_bfs(bunch,alltrees,X,y,GB,breadth)\n",
      "        #                            for bunch in bunches])\n",
      "        for bunch in bunches:\n",
      "            trees_sample = np.array(random.sample(alltrees,trees_sample_size))\n",
      "            bunches,additions,losses = try_add1_bfs(bunch,trees_sample,X,y,learning_rate,loss,breadth)\n",
      "            #DELIBERATELY not excluding from remainingTrees the trees that are in batch\n",
      "            #because we are adjusting leaves anyway and one trees may be used  multiple\n",
      "            #times with different leaf adjustments.\n",
      "            newBunches+=bunches\n",
      "            newScores += losses\n",
      "            \n",
      "        learning_rate *= learning_rate_decay\n",
      "        trees_sample_size = min(len(alltrees),trees_sample_size + trees_sample_increase)\n",
      "            \n",
      "        pairs = [(newScores[i],newBunches[i]) for i in xrange(len(newBunches))]\n",
      "        pairs.sort(key = lambda el: el[0])\n",
      "        bunches = [pair[1] for pair in pairs[:breadth]]\n",
      "        \n",
      "        \n",
      "        newBestScore = min(newScores)\n",
      "        if newBestScore > bestScore:\n",
      "            bunches = [bnch[:-1] for bnch in bunches]\n",
      "            learning_rate /=2.\n",
      "            if learning_rate < 0.00001:\n",
      "                break\n",
      "        else: bestScore = newBestScore\n",
      "        \n",
      "        \n",
      "        if verbose:\n",
      "            print \"\\niteration #\",itr,\" ntrees = \", len(bunches[0]),\"\\nbest loss = \", bestScore,\"\\nlast loss = \",newBestScore\n",
      "\n",
      "            print \"learning_rate = \", learning_rate\n",
      "            print \"sample_size\", trees_sample_size\n",
      "            \n",
      "    return bunches[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res_greedy = greed_up_features_bfs(trees,Xtr,Ytr,100.,logloss,1,10,100,True,0.95,0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration # 0  ntrees =  1 \n",
        "best loss =  0.297735914958\n",
        "learning_rate =  100.0\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1  ntrees =  2 \n",
        "best loss =  0.267214831846 \n",
        "last loss =  0.267214831846\n",
        "learning_rate =  95.0\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2  ntrees =  3 \n",
        "best loss =  0.265755040253 \n",
        "last loss =  0.265755040253\n",
        "learning_rate =  90.25\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3  ntrees =  3 \n",
        "best loss =  0.265755040253 \n",
        "last loss =  0.266150148162\n",
        "learning_rate =  42.86875\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4  ntrees =  4 \n",
        "best loss =  0.265044661146 \n",
        "last loss =  0.265044661146\n",
        "learning_rate =  40.7253125\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5  ntrees =  5 \n",
        "best loss =  0.262921990914 \n",
        "last loss =  0.262921990914\n",
        "learning_rate =  38.689046875\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6  ntrees =  6 \n",
        "best loss =  0.260273437094 \n",
        "last loss =  0.260273437094\n",
        "learning_rate =  36.7545945312\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7  ntrees =  7 \n",
        "best loss =  0.258928411175 \n",
        "last loss =  0.258928411175\n",
        "learning_rate =  34.9168648047\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8  ntrees =  8 \n",
        "best loss =  0.257681426685 \n",
        "last loss =  0.257681426685\n",
        "learning_rate =  33.1710215645\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9  ntrees =  9 \n",
        "best loss =  0.256541509809 \n",
        "last loss =  0.256541509809\n",
        "learning_rate =  31.5124704862\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10  ntrees =  10 \n",
        "best loss =  0.254798250827 \n",
        "last loss =  0.254798250827\n",
        "learning_rate =  29.9368469619\n",
        "sample_size 100\n"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_pred_greedy = predict(res_greedy,Xts)\n",
      "y_pred_stupid = predict(trees[:10],Xts)\n",
      "y_pred_full = predict(trees,Xts)\n",
      "print metrics.roc_auc_score(Yts,y_pred_greedy),metrics.roc_auc_score(Yts,y_pred_stupid),metrics.roc_auc_score(Yts,y_pred_full)\n",
      "print \"well...\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.848066648344 0.839377842342 0.913492924984\n",
        "well...\n"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The roc curves are at the bottom"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Upper level thresholds extraction"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#thresholds extraction\n",
      "cuts = lambda feature: reduce(np.append,[tree[1][tree[0] == feature] for tree in  trees])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_inclusion(feature,tolerance=0.):\n",
      "    \"\"\"\n",
      "    Get the inclusion counts of thresholds\n",
      "    \"\"\"\n",
      "    thresholds = cuts(feature)\n",
      "    tolerance *= np.var(thresholds)\n",
      "    thrs = { threshold: len(filter(\n",
      "                                lambda thr: abs(thr - threshold) <= tolerance,\n",
      "                                thresholds)\n",
      "                           )\n",
      "            for threshold in set(thresholds)}\n",
      "    return thrs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "best = {i:get_inclusion(i,0.001) for i in range(30)}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#usability distribution\n",
      "thresholds = reduce(np.append,[zip(np.repeat(i,len(best[i])),best[i].keys(),best[i].values()) for i in best])\n",
      "thresholds = thresholds.reshape(thresholds.shape[0]/3,3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.scatter(range(len(thresholds)),thresholds[:,2])\n",
      "print sum(thresholds[:,2] >150)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "96\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEACAYAAAC3adEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKEoMVQyKoihKjP8fJ1hkB2V48tkAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x27a4a828>"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Criteria selection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def entropy(distribution):\n",
      "    \"\"\"just some entropy\"\"\"\n",
      "    logs = np.array(map(np.log,distribution))\n",
      "    logs[distribution ==0] = 0\n",
      "    return -sum(distribution*logs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def select_criteria(X, thresholds_active,depth,verbose = True):\n",
      "    \"\"\"\n",
      "    I find the most _even_ dichotomies of a given depth among the given thresholds... greedily\n",
      "    \"\"\"\n",
      "    leaves = {\"\":X}\n",
      "    criteria = []\n",
      "\n",
      "    old_leaves = copy.copy(leaves) #backup in case you're to lazy to restore em\n",
      "\n",
      "    for i in range(depth):\n",
      "        entropies = []\n",
      "        for feature,cut,_ in thresholds_active:\n",
      "            split_distribution = []\n",
      "            for leaf in leaves:\n",
      "                subsample = leaves[leaf]\n",
      "                predicate = (subsample[:,feature] > cut)\n",
      "                trues = sum(predicate)\n",
      "\n",
      "                split_distribution.append(trues)\n",
      "                split_distribution.append(subsample.shape[0] - trues)\n",
      "            split_distribution = np.array(split_distribution)/float(X.shape[0])\n",
      "            entropies.append( entropy(split_distribution))\n",
      "\n",
      "        feature,cut,_ = criterion = thresholds_active[entropies.index(max(entropies))]\n",
      "        new_leaves = {}\n",
      "        for leaf in leaves:\n",
      "            subsample = leaves[leaf]\n",
      "            predicate = (subsample[:,feature] > cut)\n",
      "            new_leaves[leaf+\"1\"] = subsample[predicate]\n",
      "            new_leaves[leaf+\"0\"] = subsample[predicate == False]\n",
      "\n",
      "        leaves = new_leaves    \n",
      "        criteria.append(criterion)\n",
      "        if verbose:\n",
      "            print [leaves[i].shape[0] for i in leaves]\n",
      "    return criteria"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get them...\n",
      "thresholds_active = thresholds[thresholds[:,2]>100]\n",
      "print len(thresholds_active)\n",
      "criteria = select_criteria(Xtr,thresholds_active,3,True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "190\n",
        "[99438L, 100562L]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[44146L, 55292L, 41522L, 59040L]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[39121L, 19919L, 23340L, 18182L, 22549L, 21597L, 18339L, 36953L]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[2960L, 16959L, 8573L, 9609L, 18756L, 4584L, 18970L, 20151L, 17958L, 4591L, 11351L, 10246L, 10163L, 26790L, 8688L, 9651L]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "criteria = criteria[:3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def split_upper(X,Y,criterea):\n",
      "    \"\"\"\n",
      "    I split the data into the leaves of the upper level ODT given it's criterea\n",
      "    \"\"\"\n",
      "    X_split = {'':X}\n",
      "    y_split = {'':Y}\n",
      "    for criterion in criteria:\n",
      "        feature,cut= criterion[0],criterion[1]\n",
      "        X_split_new = {}\n",
      "        y_split_new = {}\n",
      "        for splt in X_split:\n",
      "            dichotomy = X_split[splt][:,feature]> cut\n",
      "            X_split_new[splt+'1'] = X_split[splt][dichotomy]\n",
      "            X_split_new[splt+'0'] = X_split[splt][dichotomy == False]\n",
      "            y_split_new[splt+'1'] = y_split[splt][dichotomy]\n",
      "            y_split_new[splt+'0'] = y_split[splt][dichotomy == False]\n",
      "        X_split = X_split_new\n",
      "        y_split = y_split_new\n",
      "    return X_split,y_split"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_split,Y_split = split_upper(Xtr,Ytr,criteria)\n",
      "print [X_split[i].shape[0] for i in X_split]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[39121L, 19919L, 23340L, 18182L, 22549L, 21597L, 18339L, 36953L]\n"
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def train_splitted_boosts( trees,\n",
      "                           X_split,Y_split,\n",
      "                           learning_rate,\n",
      "                           loss,\n",
      "                           breadth,\n",
      "                           nTrees_leaf,\n",
      "                           trees_sample_size,\n",
      "                           verbose = True,\n",
      "                           learning_rate_decay = 1.,\n",
      "                           trees_sample_increase = 0):\n",
      "    \"\"\"\n",
      "    make greedy prune for every leaf in split\n",
      "    \"\"\"\n",
      "    leaves = X_split.keys()\n",
      "    dataPairs = [(X_split[s],Y_split[s]) for s in leaves]\n",
      "    \n",
      "    classis = []\n",
      "    for i in range(len(leaves)):\n",
      "        X_,y_ = dataPairs[i]\n",
      "        if verbose:\n",
      "            print \"\\n\\nNow training leaf \",leaves[i], i+1,\"/\",len(leaves)\n",
      "            print \"n_ samples at leaf = \", X_.shape[0]\n",
      "        classis.append(greed_up_features_bfs(\n",
      "                           trees,\n",
      "                           X_,y_,\n",
      "                           learning_rate,\n",
      "                           loss,\n",
      "                           breadth,\n",
      "                           nTrees_leaf,\n",
      "                           trees_sample_size,\n",
      "                           verbose,\n",
      "                           learning_rate_decay,\n",
      "                           trees_sample_increase\n",
      "                           ))\n",
      "    #same stuff in JL\n",
      "    #tasks = [joblib.delayed(greed_up_features_bfs)(\n",
      "    #                       trees,\n",
      "    #                       X_,y_,\n",
      "    #                       learning_rate,\n",
      "    #                       loss,\n",
      "    #                       breadth,\n",
      "    #                       nTrees_leaf,\n",
      "    #                       trees_sample_size,\n",
      "    #                       verbose,\n",
      "    #                       learning_rate_decay,\n",
      "    #                       trees_sample_increase\n",
      "    #                       ) for X_,y_ in dataPairs]\n",
      "    #classis = joblib.Parallel(n_jobs = -1)(tasks)\n",
      "\n",
      "    return {leaves[i]:classis[i] for i in range(len(leaves))}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trees_splitted = train_splitted_boosts(trees, X_split,Y_split,100.,logloss,1,10,100,True,0.95)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Now training leaf  010 1 / 8\n",
        "n_ samples at leaf =  39121\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0  ntrees =  1 \n",
        "best loss =  0.0916564749517\n",
        "learning_rate =  100.0\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1  ntrees =  1 \n",
        "best loss =  0.0916564749517 \n",
        "last loss =  0.092076951676\n",
        "learning_rate =  47.5\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2  ntrees =  1 \n",
        "best loss =  0.0916564749517 \n",
        "last loss =  0.0920205657874\n",
        "learning_rate =  22.5625\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3  ntrees =  1 \n",
        "best loss =  0.0916564749517 \n",
        "last loss =  0.0918149104549\n",
        "learning_rate =  10.7171875\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4  ntrees =  1 \n",
        "best loss =  0.0916564749517 \n",
        "last loss =  0.0917320492047\n",
        "learning_rate =  5.0906640625\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5  ntrees =  1 \n",
        "best loss =  0.0916564749517 \n",
        "last loss =  0.0916822541041\n",
        "learning_rate =  2.41806542969\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6  ntrees =  1 \n",
        "best loss =  0.0916564749517 \n",
        "last loss =  0.091672482683\n",
        "learning_rate =  1.1485810791\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7  ntrees =  1 \n",
        "best loss =  0.0916564749517 \n",
        "last loss =  0.091668813148\n",
        "learning_rate =  0.545576012573\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8  ntrees =  1 \n",
        "best loss =  0.0916564749517 \n",
        "last loss =  0.091659878625\n",
        "learning_rate =  0.259148605972\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9  ntrees =  1 \n",
        "best loss =  0.0916564749517 \n",
        "last loss =  0.0916577594936\n",
        "learning_rate =  0.123095587837\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10  ntrees =  1 \n",
        "best loss =  0.0916564749517 \n",
        "last loss =  0.0916570345759\n",
        "learning_rate =  0.0584704042225\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11  ntrees =  1 \n",
        "best loss =  0.0916564749517 \n",
        "last loss =  0.0916571601286\n",
        "learning_rate =  0.0277734420057\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12  ntrees =  1 \n",
        "best loss =  0.0916564749517 \n",
        "last loss =  0.0916566465104\n",
        "learning_rate =  0.0131923849527\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13  ntrees =  1 \n",
        "best loss =  0.0916564749517 \n",
        "last loss =  0.0916565620234\n",
        "learning_rate =  0.00626638285253\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14  ntrees =  1 \n",
        "best loss =  0.0916564749517 \n",
        "last loss =  0.0916565300899\n",
        "learning_rate =  0.00297653185495\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 15  ntrees =  1 \n",
        "best loss =  0.0916564749517 \n",
        "last loss =  0.0916564975992\n",
        "learning_rate =  0.0014138526311\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 16  ntrees =  1 \n",
        "best loss =  0.0916564749517 \n",
        "last loss =  0.0916564872366\n",
        "learning_rate =  0.000671579999774\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 17  ntrees =  1 \n",
        "best loss =  0.0916564749517 \n",
        "last loss =  0.0916564781442\n",
        "learning_rate =  0.000319000499893\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 18  ntrees =  1 \n",
        "best loss =  0.0916564749517 \n",
        "last loss =  0.0916564765902\n",
        "learning_rate =  0.000151525237449\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 19  ntrees =  1 \n",
        "best loss =  0.0916564749517 \n",
        "last loss =  0.0916564763851\n",
        "learning_rate =  7.19744877883e-05\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 20  ntrees =  1 \n",
        "best loss =  0.0916564749517 \n",
        "last loss =  0.0916564755428\n",
        "learning_rate =  3.41878816994e-05\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 21  ntrees =  1 \n",
        "best loss =  0.0916564749517 \n",
        "last loss =  0.0916564751776\n",
        "learning_rate =  1.62392438072e-05\n",
        "sample_size 100\n",
        "\n",
        "\n",
        "Now training leaf "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 011 2 / 8\n",
        "n_ samples at leaf =  19919\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0  ntrees =  1 \n",
        "best loss =  0.139434264718\n",
        "learning_rate =  100.0\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1  ntrees =  1 \n",
        "best loss =  0.139434264718 \n",
        "last loss =  0.143936553443\n",
        "learning_rate =  47.5\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2  ntrees =  1 \n",
        "best loss =  0.139434264718 \n",
        "last loss =  0.140374924093\n",
        "learning_rate =  22.5625\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3  ntrees =  1 \n",
        "best loss =  0.139434264718 \n",
        "last loss =  0.140076637268\n",
        "learning_rate =  10.7171875\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4  ntrees =  1 \n",
        "best loss =  0.139434264718 \n",
        "last loss =  0.139810314542\n",
        "learning_rate =  5.0906640625\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5  ntrees =  1 \n",
        "best loss =  0.139434264718 \n",
        "last loss =  0.139572177873\n",
        "learning_rate =  2.41806542969\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6  ntrees =  1 \n",
        "best loss =  0.139434264718 \n",
        "last loss =  0.139490043386\n",
        "learning_rate =  1.1485810791\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7  ntrees =  1 \n",
        "best loss =  0.139434264718 \n",
        "last loss =  0.139466130339\n",
        "learning_rate =  0.545576012573\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8  ntrees =  1 \n",
        "best loss =  0.139434264718 \n",
        "last loss =  0.139450808934\n",
        "learning_rate =  0.259148605972\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9  ntrees =  1 \n",
        "best loss =  0.139434264718 \n",
        "last loss =  0.139442768821\n",
        "learning_rate =  0.123095587837\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10  ntrees =  1 \n",
        "best loss =  0.139434264718 \n",
        "last loss =  0.139436720851\n",
        "learning_rate =  0.0584704042225\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11  ntrees =  1 \n",
        "best loss =  0.139434264718 \n",
        "last loss =  0.139435986454\n",
        "learning_rate =  0.0277734420057\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12  ntrees =  1 \n",
        "best loss =  0.139434264718 \n",
        "last loss =  0.139434748144\n",
        "learning_rate =  0.0131923849527\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13  ntrees =  1 \n",
        "best loss =  0.139434264718 \n",
        "last loss =  0.139434668346\n",
        "learning_rate =  0.00626638285253\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14  ntrees =  1 \n",
        "best loss =  0.139434264718 \n",
        "last loss =  0.139434433099\n",
        "learning_rate =  0.00297653185495\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 15  ntrees =  1 \n",
        "best loss =  0.139434264718 \n",
        "last loss =  0.139434302269\n",
        "learning_rate =  0.0014138526311\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 16  ntrees =  1 \n",
        "best loss =  0.139434264718 \n",
        "last loss =  0.139434289326\n",
        "learning_rate =  0.000671579999774\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 17  ntrees =  1 \n",
        "best loss =  0.139434264718 \n",
        "last loss =  0.139434284287\n",
        "learning_rate =  0.000319000499893\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 18  ntrees =  1 \n",
        "best loss =  0.139434264718 \n",
        "last loss =  0.139434272921\n",
        "learning_rate =  0.000151525237449\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 19  ntrees =  1 \n",
        "best loss =  0.139434264718 \n",
        "last loss =  0.139434268764\n",
        "learning_rate =  7.19744877883e-05\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 20  ntrees =  1 \n",
        "best loss =  0.139434264718 \n",
        "last loss =  0.139434266919\n",
        "learning_rate =  3.41878816994e-05\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 21  ntrees =  1 \n",
        "best loss =  0.139434264718 \n",
        "last loss =  0.139434265518\n",
        "learning_rate =  1.62392438072e-05\n",
        "sample_size 100\n",
        "\n",
        "\n",
        "Now training leaf "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 001 3 / 8\n",
        "n_ samples at leaf =  23340\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0  ntrees =  1 \n",
        "best loss =  0.234873201291\n",
        "learning_rate =  100.0\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1  ntrees =  1 \n",
        "best loss =  0.234873201291 \n",
        "last loss =  0.240372620469\n",
        "learning_rate =  47.5\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2  ntrees =  1 \n",
        "best loss =  0.234873201291 \n",
        "last loss =  0.23582179759\n",
        "learning_rate =  22.5625\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3  ntrees =  1 \n",
        "best loss =  0.234873201291 \n",
        "last loss =  0.235815227185\n",
        "learning_rate =  10.7171875\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4  ntrees =  1 \n",
        "best loss =  0.234873201291 \n",
        "last loss =  0.234921632496\n",
        "learning_rate =  5.0906640625\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5  ntrees =  1 \n",
        "best loss =  0.234873201291 \n",
        "last loss =  0.234926486102\n",
        "learning_rate =  2.41806542969\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6  ntrees =  1 \n",
        "best loss =  0.234873201291 \n",
        "last loss =  0.234898463685\n",
        "learning_rate =  1.1485810791\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7  ntrees =  2 \n",
        "best loss =  0.234844515213 \n",
        "last loss =  0.234844515213\n",
        "learning_rate =  1.09115202515\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8  ntrees =  2 \n",
        "best loss =  0.234844515213 \n",
        "last loss =  0.234858034328\n",
        "learning_rate =  0.518297211945\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9  ntrees =  2 \n",
        "best loss =  0.234844515213 \n",
        "last loss =  0.234845067743\n",
        "learning_rate =  0.246191175674\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10  ntrees =  2 \n",
        "best loss =  0.234844515213 \n",
        "last loss =  0.234847855769\n",
        "learning_rate =  0.116940808445\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11  ntrees =  3 \n",
        "best loss =  0.234842178646 \n",
        "last loss =  0.234842178646\n",
        "learning_rate =  0.111093768023\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12  ntrees =  3 \n",
        "best loss =  0.234842178646 \n",
        "last loss =  0.234843296945\n",
        "learning_rate =  0.0527695398108\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13  ntrees =  3 \n",
        "best loss =  0.234842178646 \n",
        "last loss =  0.234842181482\n",
        "learning_rate =  0.0250655314101\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14  ntrees =  3 \n",
        "best loss =  0.234842178646 \n",
        "last loss =  0.234842683947\n",
        "learning_rate =  0.0119061274198\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 15  ntrees =  3 \n",
        "best loss =  0.234842178646 \n",
        "last loss =  0.234842461184\n",
        "learning_rate =  0.00565541052441\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 16  ntrees =  3 \n",
        "best loss =  0.234842178646 \n",
        "last loss =  0.234842197041\n",
        "learning_rate =  0.0026863199991\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 17  ntrees =  4 \n",
        "best loss =  0.234842129755 \n",
        "last loss =  0.234842129755\n",
        "learning_rate =  0.00255200399914\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 18  ntrees =  4 \n",
        "best loss =  0.234842129755 \n",
        "last loss =  0.234842187587\n",
        "learning_rate =  0.00121220189959\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 19  ntrees =  4 \n",
        "best loss =  0.234842129755 \n",
        "last loss =  0.234842147505\n",
        "learning_rate =  0.000575795902306\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 20  ntrees =  4 \n",
        "best loss =  0.234842129755 \n",
        "last loss =  0.234842133929\n",
        "learning_rate =  0.000273503053595\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 21  ntrees =  5 \n",
        "best loss =  0.234842122815 \n",
        "last loss =  0.234842122815\n",
        "learning_rate =  0.000259827900916\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 22  ntrees =  6 \n",
        "best loss =  0.234842121814 \n",
        "last loss =  0.234842121814\n",
        "learning_rate =  0.00024683650587\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 23  ntrees =  7 \n",
        "best loss =  0.234842117322 \n",
        "last loss =  0.234842117322\n",
        "learning_rate =  0.000234494680576\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 24  ntrees =  7 \n",
        "best loss =  0.234842117322 \n",
        "last loss =  0.234842121424\n",
        "learning_rate =  0.000111384973274\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 25  ntrees =  7 \n",
        "best loss =  0.234842117322 \n",
        "last loss =  0.234842120748\n",
        "learning_rate =  5.2907862305e-05\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 26  ntrees =  7 \n",
        "best loss =  0.234842117322 \n",
        "last loss =  0.234842117762\n",
        "learning_rate =  2.51312345949e-05\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 27  ntrees =  7 \n",
        "best loss =  0.234842117322 \n",
        "last loss =  0.23484211778\n",
        "learning_rate =  1.19373364326e-05\n",
        "sample_size 100\n",
        "\n",
        "\n",
        "Now training leaf "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 000 4 / 8\n",
        "n_ samples at leaf =  18182\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0  ntrees =  1 \n",
        "best loss =  0.320606218154\n",
        "learning_rate =  100.0\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1  ntrees =  2 \n",
        "best loss =  0.312595408836 \n",
        "last loss =  0.312595408836\n",
        "learning_rate =  95.0\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2  ntrees =  3 \n",
        "best loss =  0.309975986429 \n",
        "last loss =  0.309975986429\n",
        "learning_rate =  90.25\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3  ntrees =  4 \n",
        "best loss =  0.309506497622 \n",
        "last loss =  0.309506497622\n",
        "learning_rate =  85.7375\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4  ntrees =  4 \n",
        "best loss =  0.309506497622 \n",
        "last loss =  0.309789235576\n",
        "learning_rate =  40.7253125\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5  ntrees =  5 \n",
        "best loss =  0.307991190145 \n",
        "last loss =  0.307991190145\n",
        "learning_rate =  38.689046875\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6  ntrees =  5 \n",
        "best loss =  0.307991190145 \n",
        "last loss =  0.308438649366\n",
        "learning_rate =  18.3772972656\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7  ntrees =  5 \n",
        "best loss =  0.307991190145 \n",
        "last loss =  0.308338185706\n",
        "learning_rate =  8.72921620117\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8  ntrees =  6 \n",
        "best loss =  0.307907098632 \n",
        "last loss =  0.307907098632\n",
        "learning_rate =  8.29275539111\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9  ntrees =  6 \n",
        "best loss =  0.307907098632 \n",
        "last loss =  0.307959888908\n",
        "learning_rate =  3.93905881078\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10  ntrees =  6 \n",
        "best loss =  0.307907098632 \n",
        "last loss =  0.307937628872\n",
        "learning_rate =  1.87105293512\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11  ntrees =  6 \n",
        "best loss =  0.307907098632 \n",
        "last loss =  0.307940923546\n",
        "learning_rate =  0.888750144182\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12  ntrees =  6 \n",
        "best loss =  0.307907098632 \n",
        "last loss =  0.307924072526\n",
        "learning_rate =  0.422156318486\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13  ntrees =  6 \n",
        "best loss =  0.307907098632 \n",
        "last loss =  0.307911068193\n",
        "learning_rate =  0.200524251281\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14  ntrees =  6 \n",
        "best loss =  0.307907098632 \n",
        "last loss =  0.307910053178\n",
        "learning_rate =  0.0952490193585\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 15  ntrees =  6 \n",
        "best loss =  0.307907098632 \n",
        "last loss =  0.307908822627\n",
        "learning_rate =  0.0452432841953\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 16  ntrees =  6 \n",
        "best loss =  0.307907098632 \n",
        "last loss =  0.307907680574\n",
        "learning_rate =  0.0214905599928\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 17  ntrees =  6 \n",
        "best loss =  0.307907098632 \n",
        "last loss =  0.307907528229\n",
        "learning_rate =  0.0102080159966\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 18  ntrees =  6 \n",
        "best loss =  0.307907098632 \n",
        "last loss =  0.30790717464\n",
        "learning_rate =  0.00484880759837\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 19  ntrees =  6 \n",
        "best loss =  0.307907098632 \n",
        "last loss =  0.307907130811\n",
        "learning_rate =  0.00230318360922\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 20  ntrees =  6 \n",
        "best loss =  0.307907098632 \n",
        "last loss =  0.307907114267\n",
        "learning_rate =  0.00109401221438\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 21  ntrees =  6 \n",
        "best loss =  0.307907098632 \n",
        "last loss =  0.307907104809\n",
        "learning_rate =  0.000519655801831\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 22  ntrees =  6 \n",
        "best loss =  0.307907098632 \n",
        "last loss =  0.307907104463\n",
        "learning_rate =  0.00024683650587\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 23  ntrees =  6 \n",
        "best loss =  0.307907098632 \n",
        "last loss =  0.307907099945\n",
        "learning_rate =  0.000117247340288\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 24  ntrees =  6 \n",
        "best loss =  0.307907098632 \n",
        "last loss =  0.307907099037\n",
        "learning_rate =  5.56924866369e-05\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 25  ntrees =  6 \n",
        "best loss =  0.307907098632 \n",
        "last loss =  0.307907098964\n",
        "learning_rate =  2.64539311525e-05\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 26  ntrees =  6 \n",
        "best loss =  0.307907098632 \n",
        "last loss =  0.307907099118\n",
        "learning_rate =  1.25656172974e-05\n",
        "sample_size 100\n",
        "\n",
        "\n",
        "Now training leaf "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 111 5 / 8\n",
        "n_ samples at leaf =  22549\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0  ntrees =  1 \n",
        "best loss =  0.259697217863\n",
        "learning_rate =  100.0\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1  ntrees =  2 \n",
        "best loss =  0.255121484762 \n",
        "last loss =  0.255121484762\n",
        "learning_rate =  95.0\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2  ntrees =  3 \n",
        "best loss =  0.251855306025 \n",
        "last loss =  0.251855306025\n",
        "learning_rate =  90.25\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3  ntrees =  4 \n",
        "best loss =  0.249737039441 \n",
        "last loss =  0.249737039441\n",
        "learning_rate =  85.7375\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4  ntrees =  5 \n",
        "best loss =  0.246663415405 \n",
        "last loss =  0.246663415405\n",
        "learning_rate =  81.450625\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5  ntrees =  6 \n",
        "best loss =  0.244355178575 \n",
        "last loss =  0.244355178575\n",
        "learning_rate =  77.37809375\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6  ntrees =  7 \n",
        "best loss =  0.241207983661 \n",
        "last loss =  0.241207983661\n",
        "learning_rate =  73.5091890625\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7  ntrees =  8 \n",
        "best loss =  0.238317743221 \n",
        "last loss =  0.238317743221\n",
        "learning_rate =  69.8337296094\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8  ntrees =  9 \n",
        "best loss =  0.236386216287 \n",
        "last loss =  0.236386216287\n",
        "learning_rate =  66.3420431289\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9  ntrees =  10 \n",
        "best loss =  0.235429722833 \n",
        "last loss =  0.235429722833\n",
        "learning_rate =  63.0249409725\n",
        "sample_size 100\n",
        "\n",
        "\n",
        "Now training leaf  110 6 / 8\n",
        "n_ samples at leaf =  21597\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0  ntrees =  1 \n",
        "best loss =  0.2000468022\n",
        "learning_rate =  100.0\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1  ntrees =  1 \n",
        "best loss =  0.2000468022 \n",
        "last loss =  0.200807337444\n",
        "learning_rate =  47.5\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2  ntrees =  1 \n",
        "best loss =  0.2000468022 \n",
        "last loss =  0.200103406962\n",
        "learning_rate =  22.5625\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3  ntrees =  1 \n",
        "best loss =  0.2000468022 \n",
        "last loss =  0.200156144707\n",
        "learning_rate =  10.7171875\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4  ntrees =  1 \n",
        "best loss =  0.2000468022 \n",
        "last loss =  0.200065127841\n",
        "learning_rate =  5.0906640625\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5  ntrees =  1 \n",
        "best loss =  0.2000468022 \n",
        "last loss =  0.200063236184\n",
        "learning_rate =  2.41806542969\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6  ntrees =  1 \n",
        "best loss =  0.2000468022 \n",
        "last loss =  0.200050555702\n",
        "learning_rate =  1.1485810791\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7  ntrees =  2 \n",
        "best loss =  0.200046787578 \n",
        "last loss =  0.200046787578\n",
        "learning_rate =  1.09115202515\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8  ntrees =  2 \n",
        "best loss =  0.200046787578 \n",
        "last loss =  0.200049713809\n",
        "learning_rate =  0.518297211945\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9  ntrees =  2 \n",
        "best loss =  0.200046787578 \n",
        "last loss =  0.200049125054\n",
        "learning_rate =  0.246191175674\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10  ntrees =  2 \n",
        "best loss =  0.200046787578 \n",
        "last loss =  0.200047254229\n",
        "learning_rate =  0.116940808445\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11  ntrees =  2 \n",
        "best loss =  0.200046787578 \n",
        "last loss =  0.200047092698\n",
        "learning_rate =  0.0555468840114\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12  ntrees =  2 \n",
        "best loss =  0.200046787578 \n",
        "last loss =  0.200046891042\n",
        "learning_rate =  0.0263847699054\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13  ntrees =  2 \n",
        "best loss =  0.200046787578 \n",
        "last loss =  0.200046884008\n",
        "learning_rate =  0.0125327657051\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14  ntrees =  2 \n",
        "best loss =  0.200046787578 \n",
        "last loss =  0.200046878093\n",
        "learning_rate =  0.00595306370991\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 15  ntrees =  2 \n",
        "best loss =  0.200046787578 \n",
        "last loss =  0.200046795033\n",
        "learning_rate =  0.00282770526221\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 16  ntrees =  2 \n",
        "best loss =  0.200046787578 \n",
        "last loss =  0.200046799295\n",
        "learning_rate =  0.00134315999955\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 17  ntrees =  2 \n",
        "best loss =  0.200046787578 \n",
        "last loss =  0.200046788549\n",
        "learning_rate =  0.000638000999785\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 18  ntrees =  2 \n",
        "best loss =  0.200046787578 \n",
        "last loss =  0.200046787691\n",
        "learning_rate =  0.000303050474898\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 19  ntrees =  2 \n",
        "best loss =  0.200046787578 \n",
        "last loss =  0.200046788003\n",
        "learning_rate =  0.000143948975577\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 20  ntrees =  2 \n",
        "best loss =  0.200046787578 \n",
        "last loss =  0.20004678898\n",
        "learning_rate =  6.83757633988e-05\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 21  ntrees =  2 \n",
        "best loss =  0.200046787578 \n",
        "last loss =  0.200046787758\n",
        "learning_rate =  3.24784876145e-05\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 22  ntrees =  3 \n",
        "best loss =  0.200046787577 \n",
        "last loss =  0.200046787577\n",
        "learning_rate =  3.08545632337e-05\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 23  ntrees =  3 \n",
        "best loss =  0.200046787577 \n",
        "last loss =  0.20004678761\n",
        "learning_rate =  1.4655917536e-05\n",
        "sample_size 100\n",
        "\n",
        "\n",
        "Now training leaf "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100 7 / 8\n",
        "n_ samples at leaf =  18339\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0  ntrees =  1 \n",
        "best loss =  0.286552990961\n",
        "learning_rate =  100.0\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1  ntrees =  2 \n",
        "best loss =  0.28295644065 \n",
        "last loss =  0.28295644065\n",
        "learning_rate =  95.0\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2  ntrees =  2 \n",
        "best loss =  0.28295644065 \n",
        "last loss =  0.284009524822\n",
        "learning_rate =  45.125\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3  ntrees =  2 \n",
        "best loss =  0.28295644065 \n",
        "last loss =  0.283101738876\n",
        "learning_rate =  21.434375\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4  ntrees =  3 \n",
        "best loss =  0.282864607247 \n",
        "last loss =  0.282864607247\n",
        "learning_rate =  20.36265625\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5  ntrees =  3 \n",
        "best loss =  0.282864607247 \n",
        "last loss =  0.282900368697\n",
        "learning_rate =  9.67226171875\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6  ntrees =  3 \n",
        "best loss =  0.282864607247 \n",
        "last loss =  0.282888809057\n",
        "learning_rate =  4.59432431641\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7  ntrees =  3 \n",
        "best loss =  0.282864607247 \n",
        "last loss =  0.282864896198\n",
        "learning_rate =  2.18230405029\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8  ntrees =  4 \n",
        "best loss =  0.282858681444 \n",
        "last loss =  0.282858681444\n",
        "learning_rate =  2.07318884778\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9  ntrees =  4 \n",
        "best loss =  0.282858681444 \n",
        "last loss =  0.282876280504\n",
        "learning_rate =  0.984764702695\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10  ntrees =  4 \n",
        "best loss =  0.282858681444 \n",
        "last loss =  0.282862854894\n",
        "learning_rate =  0.46776323378\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11  ntrees =  5 \n",
        "best loss =  0.282858479799 \n",
        "last loss =  0.282858479799\n",
        "learning_rate =  0.444375072091\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12  ntrees =  5 \n",
        "best loss =  0.282858479799 \n",
        "last loss =  0.282860745867\n",
        "learning_rate =  0.211078159243\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13  ntrees =  5 \n",
        "best loss =  0.282858479799 \n",
        "last loss =  0.282858903854\n",
        "learning_rate =  0.100262125641\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14  ntrees =  5 \n",
        "best loss =  0.282858479799 \n",
        "last loss =  0.282858979762\n",
        "learning_rate =  0.0476245096793\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 15  ntrees =  6 \n",
        "best loss =  0.282858160546 \n",
        "last loss =  0.282858160546\n",
        "learning_rate =  0.0452432841953\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 16  ntrees =  7 \n",
        "best loss =  0.282857909355 \n",
        "last loss =  0.282857909355\n",
        "learning_rate =  0.0429811199855\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 17  ntrees =  8 \n",
        "best loss =  0.282857399681 \n",
        "last loss =  0.282857399681\n",
        "learning_rate =  0.0408320639862\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 18  ntrees =  9 \n",
        "best loss =  0.282857333574 \n",
        "last loss =  0.282857333574\n",
        "learning_rate =  0.0387904607869\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 19  ntrees =  10 \n",
        "best loss =  0.282857123028 \n",
        "last loss =  0.282857123028\n",
        "learning_rate =  0.0368509377476\n",
        "sample_size 100\n",
        "\n",
        "\n",
        "Now training leaf  101 8 / 8\n",
        "n_ samples at leaf =  36953\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0  ntrees =  1 \n",
        "best loss =  0.239493146838\n",
        "learning_rate =  100.0\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1  ntrees =  1 \n",
        "best loss =  0.239493146838 \n",
        "last loss =  0.239521650642\n",
        "learning_rate =  47.5\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2  ntrees =  2 \n",
        "best loss =  0.238838732644 \n",
        "last loss =  0.238838732644\n",
        "learning_rate =  45.125\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3  ntrees =  2 \n",
        "best loss =  0.238838732644 \n",
        "last loss =  0.240129650567\n",
        "learning_rate =  21.434375\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4  ntrees =  3 \n",
        "best loss =  0.238552878377 \n",
        "last loss =  0.238552878377\n",
        "learning_rate =  20.36265625\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5  ntrees =  4 \n",
        "best loss =  0.238426600344 \n",
        "last loss =  0.238426600344\n",
        "learning_rate =  19.3445234375\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6  ntrees =  4 \n",
        "best loss =  0.238426600344 \n",
        "last loss =  0.2390129219\n",
        "learning_rate =  9.18864863281\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7  ntrees =  4 \n",
        "best loss =  0.238426600344 \n",
        "last loss =  0.238709757645\n",
        "learning_rate =  4.36460810059\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8  ntrees =  4 \n",
        "best loss =  0.238426600344 \n",
        "last loss =  0.238547106597\n",
        "learning_rate =  2.07318884778\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9  ntrees =  5 \n",
        "best loss =  0.238383140459 \n",
        "last loss =  0.238383140459\n",
        "learning_rate =  1.96952940539\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10  ntrees =  5 \n",
        "best loss =  0.238383140459 \n",
        "last loss =  0.238410897581\n",
        "learning_rate =  0.93552646756\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11  ntrees =  6 \n",
        "best loss =  0.238379839558 \n",
        "last loss =  0.238379839558\n",
        "learning_rate =  0.888750144182\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12  ntrees =  6 \n",
        "best loss =  0.238379839558 \n",
        "last loss =  0.238405671105\n",
        "learning_rate =  0.422156318486\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13  ntrees =  6 \n",
        "best loss =  0.238379839558 \n",
        "last loss =  0.238386719287\n",
        "learning_rate =  0.200524251281\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14  ntrees =  6 \n",
        "best loss =  0.238379839558 \n",
        "last loss =  0.238387755864\n",
        "learning_rate =  0.0952490193585\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 15  ntrees =  6 \n",
        "best loss =  0.238379839558 \n",
        "last loss =  0.238382703309\n",
        "learning_rate =  0.0452432841953\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 16  ntrees =  6 \n",
        "best loss =  0.238379839558 \n",
        "last loss =  0.238380859447\n",
        "learning_rate =  0.0214905599928\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 17  ntrees =  6 \n",
        "best loss =  0.238379839558 \n",
        "last loss =  0.23838069001\n",
        "learning_rate =  0.0102080159966\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 18  ntrees =  6 \n",
        "best loss =  0.238379839558 \n",
        "last loss =  0.238380269906\n",
        "learning_rate =  0.00484880759837\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 19  ntrees =  6 \n",
        "best loss =  0.238379839558 \n",
        "last loss =  0.238379915497\n",
        "learning_rate =  0.00230318360922\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 20  ntrees =  6 \n",
        "best loss =  0.238379839558 \n",
        "last loss =  0.238379918584\n",
        "learning_rate =  0.00109401221438\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 21  ntrees =  6 \n",
        "best loss =  0.238379839558 \n",
        "last loss =  0.238379851309\n",
        "learning_rate =  0.000519655801831\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 22  ntrees =  6 \n",
        "best loss =  0.238379839558 \n",
        "last loss =  0.238379857423\n",
        "learning_rate =  0.00024683650587\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 23  ntrees =  6 \n",
        "best loss =  0.238379839558 \n",
        "last loss =  0.23837984587\n",
        "learning_rate =  0.000117247340288\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 24  ntrees =  6 \n",
        "best loss =  0.238379839558 \n",
        "last loss =  0.238379842314\n",
        "learning_rate =  5.56924866369e-05\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 25  ntrees =  6 \n",
        "best loss =  0.238379839558 \n",
        "last loss =  0.238379840769\n",
        "learning_rate =  2.64539311525e-05\n",
        "sample_size 100\n",
        "\n",
        "iteration #"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 26  ntrees =  6 \n",
        "best loss =  0.238379839558 \n",
        "last loss =  0.238379840564\n",
        "learning_rate =  1.25656172974e-05\n",
        "sample_size 100\n"
       ]
      }
     ],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def predict_splitted(X,criteria,trees):\n",
      "    X_split, indices =  split_upper(X, np.arange(X.shape[0]),criteria)\n",
      "    y_pred = np.zeros(X.shape[0])\n",
      "    for leaf in X_split.keys():\n",
      "        y_pred[indices[leaf]] = predict(trees[leaf],X_split[leaf])\n",
      "    return y_pred"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_pred_splitted = predict_splitted(Xts,criteria,trees_splitted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(y_pred_splitted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 103,
       "text": [
        "(array([ 7715.,  8601.,     0.,  2776.,  3345.,  9538.,  6415.,  5075.,\n",
        "         4447.,  2088.]),\n",
        " array([-33.93445975, -28.5966504 , -23.25884104, -17.92103168,\n",
        "        -12.58322233,  -7.24541297,  -1.90760361,   3.43020574,\n",
        "          8.7680151 ,  14.10582445,  19.44363381]),\n",
        " <a list of 10 Patch objects>)"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrQAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x26772470>"
       ]
      }
     ],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print metrics.roc_auc_score(Yts,y_pred_splitted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.852724123868\n"
       ]
      }
     ],
     "prompt_number": 132
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot ROC curve\n",
      "plt.figure()\n",
      "fpr, tpr, _ = roc_curve(Yts, y_pred_full)\n",
      "plt.plot(fpr, tpr,\n",
      "         label='Full boost classi')\n",
      "fpr, tpr, _ = roc_curve(Yts, y_pred_stupid)\n",
      "plt.plot(fpr, tpr,\n",
      "         label='First 10 classi')\n",
      "fpr, tpr, _ = roc_curve(Yts, y_pred_greedy)\n",
      "plt.plot(fpr, tpr,\n",
      "         label='Greedy prune classi')\n",
      "fpr, tpr, _ = roc_curve(Yts, y_pred_splitted)\n",
      "plt.plot(fpr, tpr,\n",
      "         label='Split-prune classi with 8 leafs')\n",
      "\n",
      "\n",
      "plt.plot([0, 1], [0, 1], 'k--')\n",
      "plt.xlim([0.0, 1.0])\n",
      "plt.ylim([0.0, 1.05])\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
      "plt.legend(loc=\"lower right\")\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAEZCAYAAABICyhRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noVAoTI4yPgqFQqEwOcr4KBQKhcLk/D/cOMXEKqA4/QAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x2101f080>"
       ]
      }
     ],
     "prompt_number": 133
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}