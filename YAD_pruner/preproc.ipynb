{
 "metadata": {
  "name": "",
  "signature": "sha256:1826e035dc2bbbd7183584d48d681efaaf10fd99cde15207e02d94aa3b834e42"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I can open your data (training.csv from kaggle higgs challenge), \n",
      "transform it and save the transformed data. I also learn one GBDT\n",
      "model and save it. Run me before e'thing else"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#params\n",
      "wdir= \"F:\\\\data\\\\higgs\" #\u0440\u0430\u0431\u043e\u0447\u0430\u044f \u043f\u0430\u043f\u043a\u0430\n",
      "resultname = \"gbt5000-8depth\" #\u0438\u043c\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u043d\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u0438\n",
      "#tweak model parameters at where it's trained."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# import all the libs... ever\n",
      "import csv\n",
      "import math\n",
      "import os\n",
      "os.chdir(wdir) #i am a working directory\n",
      "os.system('taskset -p 0xffffffff %d' % os.getpid())\n",
      "import random\n",
      "from sklearn.externals import joblib\n",
      "import numpy as np\n",
      "from sklearn.cross_validation import *\n",
      "from sklearn.decomposition import *\n",
      "from sklearn.ensemble import *\n",
      "from sklearn.feature_selection import *\n",
      "from sklearn.grid_search import *\n",
      "from sklearn.linear_model import *\n",
      "from sklearn.metrics import *\n",
      "from sklearn.preprocessing import *\n",
      "from sklearn.pipeline import *\n",
      "from sklearn.svm import *\n",
      "from sklearn.tree import *\n",
      "import sklearn.metrics as metr\n",
      "import sklearn.svm as svm\n",
      "import matplotlib.pyplot as plt\n",
      "import  sklearn.ensemble as ens\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Loading training data.'\n",
      "data = np.loadtxt('training.csv', \\\n",
      "        delimiter=',', \\\n",
      "        skiprows=1, \\\n",
      "        converters={32: lambda x:int(x=='s'.encode('utf-8'))})\n",
      "\n",
      "X = data[:,1:31]\n",
      "Y = data[:,32]\n",
      "W = data[:,31]\n",
      "\n",
      "#magic used to be here\n",
      "Xtr,Xts,Ytr,Yts = train_test_split(X,Y, test_size = 0.3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading training data.\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"saving data split\"\n",
      "joblib.dump(Xtr,\"Xtr\")\n",
      "joblib.dump(Xts,\"Xts\")\n",
      "joblib.dump(Ytr,\"Ytr\")\n",
      "joblib.dump(Yts,\"Yts_\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "saving data split\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "['Yts_', 'Yts__01.npy']"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Training model...\"\n",
      "\n",
      "classi =    GradientBoostingClassifier(\n",
      "            n_estimators = 5000,\n",
      "            learning_rate = 0.05,\n",
      "            max_depth = 8,\n",
      "            min_samples_leaf = 100,\n",
      "            min_samples_split = 100,\n",
      "            verbose = 1,\n",
      "            ).fit(Xtr,Ytr)\n",
      "print \"Saving it...\"\n",
      "joblib.dump(classi, resultname )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training model...\n",
        "      Iter       Train Loss   Remaining Time "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         1           1.2413           38.24s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         2           1.2024           26.89s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         3           1.1672           17.70s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         4           1.1353            8.70s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         5           1.1061            0.00s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Saving it...\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "['gbt5000-8depth',\n",
        " 'gbt5000-8depth_01.npy',\n",
        " 'gbt5000-8depth_02.npy',\n",
        " 'gbt5000-8depth_03.npy']"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#plot ROC for kicks\n",
      "plt.plot([0, 1], [0, 1], 'k--')\n",
      "plt.xlim([0.0, 1.0])\n",
      "plt.ylim([0.0, 1.05])\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "\n",
      "pred = classi.predict_proba(Xts)[:,0]\n",
      "tpr, fpr,_ = metr.roc_curve(Yts, pred)\n",
      "auc = metr.roc_auc_score(Yts,pred)\n",
      "plt.plot(fpr, tpr, label='ROC curve with {0} trees (Lasso) (area = {1:0.2f})'\n",
      "                                   ''.format(classi.n_estimators, auc))\n",
      "\n",
      "plt.legend(loc=\"lower right\")\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    }
   ],
   "metadata": {}
  }
 ]
}